{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conversations = pd.read_csv('../../datasets/AWS-CSV-Exports/conversations.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations = df_conversations.loc[df_conversations['Messages'] != '[]']['Messages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = conversations.iloc[0:int(len(conversations) * 0.2)]\n",
    "train = conversations.iloc[int(len(conversations) * 0.2):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_data = ''\n",
    "for conversation in train:\n",
    "    conv = json.loads(conversation)\n",
    "    for index in range(1,len(conv)):\n",
    "        message = conv[index-1]['message']\n",
    "        reply = conv[index]['message']\n",
    "        export_data += 'text:'+message+'\\tlabels:'+reply\n",
    "        if index==(len(conv)-1):\n",
    "            export_data += '\\tepisode_done:True\\n'\n",
    "        else:\n",
    "            export_data += '\\n'\n",
    "\n",
    "with open(\"blenderbot_processed_data_train.txt\", \"w\") as text_file:\n",
    "    text_file.write(export_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_data = ''\n",
    "for conversation in test:\n",
    "    conv = json.loads(conversation)\n",
    "    for index in range(1,len(conv)):\n",
    "        message = conv[index-1]['message']\n",
    "        reply = conv[index]['message']\n",
    "        export_data += 'text:'+message+'\\tlabels:'+reply\n",
    "        if index==(len(conv)-1):\n",
    "            export_data += '\\tepisode_done:True\\n'\n",
    "        else:\n",
    "            export_data += '\\n'\n",
    "\n",
    "with open(\"blenderbot_processed_data_test.txt\", \"w\") as text_file:\n",
    "    text_file.write(export_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code for setting up data into task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = 'blenderbot_processed_data_train.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(datafile, \"r\") as text_file:\n",
    "    lines = text_file.readlines()\n",
    "    episode_check = True\n",
    "#     check_list = []\n",
    "    for line in lines:\n",
    "        splits = line.split('\\n')[0].split('\\t')\n",
    "        text = splits[0].split('text:')[1]\n",
    "        label = splits[1].split('labels:')[1]\n",
    "        # Comment the line below and uncomment the one after that before using into the Google Colab\n",
    "        sentence = f'yield ({text},{label}), {episode_check}'\n",
    "        # yield (text, label), episode_check\n",
    "#         print(sentence)\n",
    "#         check_list.append(sentence)\n",
    "        episode_check = False\n",
    "        if len(splits) == 3:\n",
    "            episode_check = True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
