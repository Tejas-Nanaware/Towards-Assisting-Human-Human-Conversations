{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Blenderbot Transfer Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0ORlOPM2fX5"
      },
      "source": [
        "# BlenderBot Transfer Learning\n",
        "\n",
        "In this file the BlenderBot model was used for the transfer learning using the data gathered during the research study."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfc3bYqm3GDY"
      },
      "source": [
        "Making necessary connections for reading data from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-nvQ3EGaK5R"
      },
      "source": [
        "# Authentication for loading data from Google Drive\n",
        "# Import packages\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from google.colab import drive\n",
        "from os import path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIOS3quQaK12"
      },
      "source": [
        "# Authenticate User\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "auth_drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhK74ivIaKyQ",
        "outputId": "012ff5e1-09c2-462b-ebae-d37366f7ddc0"
      },
      "source": [
        "DRIVE_PATH = '/content/drive'\n",
        "drive.mount(DRIVE_PATH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4tYB0JjaKum"
      },
      "source": [
        "DATA_PATH = path.join(DRIVE_PATH, 'My Drive', 'Master\\'s Thesis', 'Blenderbot Transfer Learning')\n",
        "OUTPUT_PATH = path.join(DRIVE_PATH, 'My Drive', 'Master\\'s Thesis', 'Blenderbot Transfer Learning')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-_etBpd3Jxl"
      },
      "source": [
        "Ensure that the runtime supports GPU acceleration for model execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nr3yekWbbUhZ",
        "outputId": "6cc6cb7a-cf37-4b42-e999-af094da10e63"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Apr 17 04:28:58 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzNRJn1Q3WTU"
      },
      "source": [
        "Install the parlai package for BlenderBot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJnbNtRMb0pB",
        "outputId": "b0a39304-a670-4675-a6a1-2b340c11a754"
      },
      "source": [
        "!pip install -q parlai"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.4MB 18.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 10.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 245kB 53.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 7.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 9.2MB 56.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 122kB 58.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 8.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 8.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3MB 51.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 215kB 60.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 56.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 58.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 7.4MB 46.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 52.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 7.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 40kB 6.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 163kB 58.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 56.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 8.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 10.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 10.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 52.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 92kB 11.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 17.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 10.9MB/s \n",
            "\u001b[?25h  Building wheel for docformatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for websocket-server (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for untokenize (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: myst-parser 0.12.10 has requirement sphinx<4,>=2, but you'll have sphinx 1.8.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: sphinx-rtd-theme 0.5.2 has requirement docutils<0.17, but you'll have docutils 0.17 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: omegaconf 2.0.6 has requirement PyYAML>=5.1.*, but you'll have pyyaml 3.13 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: sphinx-autodoc-typehints 1.12.0 has requirement Sphinx>=3.0, but you'll have sphinx 1.8.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fvcore 0.1.5.post20210415 has requirement pyyaml>=5.1, but you'll have pyyaml 3.13 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8mAiYJH3uuE"
      },
      "source": [
        "# For importing and interacting with baseline BlenderBot model\n",
        "from parlai.scripts.interactive import Interactive\n",
        "# For creating custom \"Teacher\" or dataset used for transfer learning\n",
        "from parlai.scripts.display_data import DisplayData\n",
        "from parlai.core.teachers import register_teacher, DialogTeacher\n",
        "# For training or transfer learning\n",
        "from parlai.scripts.train_model import TrainModel\n",
        "# For generating the response from the model\n",
        "from parlai.scripts.display_model import DisplayModel\n",
        "# Testing model evaluation\n",
        "from parlai.scripts.eval_model import EvalModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzOIu0_83eHZ"
      },
      "source": [
        "Test the BlenderBot model with sample text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CYGnDqHYHHS",
        "outputId": "1cd49477-6581-4eb5-b6d5-d03407dc8e7b"
      },
      "source": [
        "Interactive.main(model_file='zoo:blender/blender_90M/model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "                                 /@&%###%&&@@#\n",
            "                      .,*/((((##@@@&%%#%%&&@@@&%%#/*.\n",
            "             #@@&&&%%%%##(((///*****//(((###%%%&&&@@@@@&&%#%%#.\n",
            "         .%&@@@@@&&&%%%####((((////((((####%%%&&&@@@@@&&%%#%%####,\n",
            "           ./,,#(//**,,.....,,,,***////((((########%%%%%%%%###(((\n",
            "              /*(//**,,,....,,,,***////((((########%%%%%%%%###(#%*\n",
            "               (*,...      ...,,,***//////((((((///////(/*...,/#@@@(\n",
            "               **,,..         ...,,,,,,,,,,........,,*///*...*(#@@@@&&*\n",
            "               ./,,..          ...,,,,,,,,,........,,*//*,...*#/,,,,,/%#\n",
            "                (*,..          ...,,,,,,,,,........,,*//*,..,/(      .,#(\n",
            "                **,..          ...,,,,,,,,,.........,*//*,..,((       .,(#\n",
            "                 /*,..          ....,,,,,,,.....  ..,***,,,,(#         ..#&\n",
            "                 **,..          ....,,,,,,,....   ..,***,,,*#.         .,%@\n",
            "                 ./,...       B l e n d e r B o t ...***,,,*#          .*%@\n",
            "                  /*,..          ...,,,,,,,....    .,**,,,,/#         ..(%/\n",
            "                  /*,,..         ...,,,,,,,...    ..,*,,,,,(.         ..#&\n",
            "                  ,/*,..         ...,,,,,,,...    ..,*,,,,*#         ..*%(\n",
            "                   /*,..         ...,,,,,.....    ..,*,*,,/(         ..#&\n",
            "                   /**,..        ...,,,,.....    ...,***,*(.       ,,(%.\n",
            "                    (/*,,..      ....,,.....     ...,****(&@@@&&&#,\n",
            "                     (/*,,...   .....,,......     ..,****#@,\n",
            "                     *(/*,,/....*(###%(,(%%##(*.  ./,,**(\n",
            "                      ,//**(,........,/((#.........*,**(\n",
            "                      .(#//*,,,,,,.*.,/((%/,,.....,,*/@\n",
            "                    ((######//****,/.,/(#%#***,***(&@@@@@(\n",
            "                   *&%%#####%%%%%%%#//(#%&%%&&@@@@@@@@@@@@*\n",
            "                   &&%%%###((((((####%%%%&&&&&@@@@@@@@@@&&@.\n",
            "                  *##%%%##(((((((####%%%%%&&&&@@@@@@@@@&#/*,\n",
            "                 .(##%#/,  .,*((##%%%&&&&%%%#####%&&@&&%#(/*.\n",
            "                 /(###(,   .,*/(##%%%&&&&%%%######%&&&&%#(/*,\n",
            "                */((((*.  ..,//((##%%%%%%%%#######%&&&&%%#(/*,\n",
            "               .//(((/,   .,*//((###%%%%%%########%%&&&%%#((/,.\n",
            "              .&####(((((((((######%%%%%%%%&&&&&&&@@@@@@@@@@@@@#\n",
            "               *&#.   .*/((((#######%%%%%%&&&&&&&@@@@@#/.   (&/\n",
            "02:38:59 | building data: /usr/local/lib/python3.7/dist-packages/data/models/blender/blender_90M/BST0B.tgz\n",
            "02:38:59 | Downloading http://parl.ai/downloads/_models/blender/BST0B.tgz to /usr/local/lib/python3.7/dist-packages/data/models/blender/blender_90M/BST0B.tgz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading BST0B.tgz: 100%|██████████| 161M/161M [00:08<00:00, 19.5MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "02:39:10 | \u001b[33mOverriding opt[\"model_file\"] to /usr/local/lib/python3.7/dist-packages/data/models/blender/blender_90M/model (previously: /checkpoint/edinan/20200210/baseline_BST_retnref/lr=7.5e-06_attention-dropout=0.0_relu-dropout=0.0/model)\u001b[0m\n",
            "02:39:10 | \u001b[33mLoading model with `--beam-block-full-context false`\u001b[0m\n",
            "02:39:10 | Using CUDA\n",
            "02:39:10 | loading dictionary from /usr/local/lib/python3.7/dist-packages/data/models/blender/blender_90M/model.dict\n",
            "02:39:10 | num words = 54944\n",
            "02:39:10 | TransformerGenerator: full interactive mode on.\n",
            "02:39:11 | \u001b[33mDEPRECATED: XLM should only be used for backwards compatibility, as it involves a less-stable layernorm operation.\u001b[0m\n",
            "02:39:22 | Total parameters: 87,508,992 (87,508,992 trainable)\n",
            "02:39:22 | Loading existing model params from /usr/local/lib/python3.7/dist-packages/data/models/blender/blender_90M/model\n",
            "02:39:22 | Opt:\n",
            "02:39:22 |     activation: gelu\n",
            "02:39:22 |     adafactor_eps: '[1e-30, 0.001]'\n",
            "02:39:22 |     adam_eps: 1e-08\n",
            "02:39:22 |     add_p1_after_newln: False\n",
            "02:39:22 |     aggregate_micro: False\n",
            "02:39:22 |     allow_missing_init_opts: False\n",
            "02:39:22 |     attention_dropout: 0.0\n",
            "02:39:22 |     batchsize: 16\n",
            "02:39:22 |     beam_block_full_context: False\n",
            "02:39:22 |     beam_block_list_filename: None\n",
            "02:39:22 |     beam_block_ngram: 3\n",
            "02:39:23 |     beam_context_block_ngram: 3\n",
            "02:39:23 |     beam_delay: 30\n",
            "02:39:23 |     beam_length_penalty: 0.65\n",
            "02:39:23 |     beam_min_length: 20\n",
            "02:39:23 |     beam_size: 10\n",
            "02:39:23 |     betas: '[0.9, 0.999]'\n",
            "02:39:23 |     bpe_add_prefix_space: None\n",
            "02:39:23 |     bpe_debug: False\n",
            "02:39:23 |     bpe_dropout: None\n",
            "02:39:23 |     bpe_merge: None\n",
            "02:39:23 |     bpe_vocab: None\n",
            "02:39:23 |     compute_tokenized_bleu: False\n",
            "02:39:23 |     datapath: /usr/local/lib/python3.7/dist-packages/data\n",
            "02:39:23 |     datatype: train\n",
            "02:39:23 |     delimiter: '\\n'\n",
            "02:39:23 |     dict_class: parlai.core.dict:DictionaryAgent\n",
            "02:39:23 |     dict_endtoken: __end__\n",
            "02:39:23 |     dict_file: /usr/local/lib/python3.7/dist-packages/data/models/blender/blender_90M/model.dict\n",
            "02:39:23 |     dict_include_test: False\n",
            "02:39:23 |     dict_include_valid: False\n",
            "02:39:23 |     dict_initpath: None\n",
            "02:39:23 |     dict_language: english\n",
            "02:39:23 |     dict_loaded: True\n",
            "02:39:23 |     dict_lower: True\n",
            "02:39:23 |     dict_max_ngram_size: -1\n",
            "02:39:23 |     dict_maxexs: -1\n",
            "02:39:23 |     dict_maxtokens: -1\n",
            "02:39:23 |     dict_minfreq: 0\n",
            "02:39:23 |     dict_nulltoken: __null__\n",
            "02:39:23 |     dict_starttoken: __start__\n",
            "02:39:23 |     dict_textfields: text,labels\n",
            "02:39:23 |     dict_tokenizer: bpe\n",
            "02:39:23 |     dict_unktoken: __unk__\n",
            "02:39:23 |     display_add_fields: \n",
            "02:39:23 |     display_examples: False\n",
            "02:39:23 |     display_prettify: False\n",
            "02:39:23 |     download_path: None\n",
            "02:39:23 |     dropout: 0.1\n",
            "02:39:23 |     dynamic_batching: None\n",
            "02:39:23 |     embedding_projection: random\n",
            "02:39:23 |     embedding_size: 512\n",
            "02:39:23 |     embedding_type: random\n",
            "02:39:23 |     embeddings_scale: True\n",
            "02:39:23 |     eval_batchsize: None\n",
            "02:39:23 |     evaltask: None\n",
            "02:39:23 |     ffn_size: 2048\n",
            "02:39:23 |     force_fp16_tokens: True\n",
            "02:39:23 |     fp16: True\n",
            "02:39:23 |     fp16_impl: safe\n",
            "02:39:23 |     gpu: -1\n",
            "02:39:23 |     gradient_clip: 0.1\n",
            "02:39:23 |     hide_labels: False\n",
            "02:39:23 |     history_add_global_end_token: None\n",
            "02:39:23 |     history_reversed: False\n",
            "02:39:23 |     history_size: -1\n",
            "02:39:23 |     image_cropsize: 224\n",
            "02:39:23 |     image_mode: raw\n",
            "02:39:23 |     image_size: 256\n",
            "02:39:23 |     include_checked_sentence: True\n",
            "02:39:23 |     include_knowledge: True\n",
            "02:39:23 |     include_knowledge_separator: False\n",
            "02:39:23 |     inference: beam\n",
            "02:39:23 |     init_model: /checkpoint/parlai/zoo/new_reddit/newreddit_trained20190909_usedfordodeca/model\n",
            "02:39:23 |     init_opt: None\n",
            "02:39:23 |     interactive_mode: True\n",
            "02:39:23 |     interactive_task: True\n",
            "02:39:23 |     invsqrt_lr_decay_gamma: -1\n",
            "02:39:23 |     label_truncate: 128\n",
            "02:39:23 |     label_type: response\n",
            "02:39:23 |     learn_positional_embeddings: True\n",
            "02:39:23 |     learningrate: 7.5e-06\n",
            "02:39:23 |     local_human_candidates_file: None\n",
            "02:39:23 |     log_every_n_secs: 2\n",
            "02:39:23 |     log_keep_fields: all\n",
            "02:39:23 |     loglevel: info\n",
            "02:39:23 |     lr_scheduler: reduceonplateau\n",
            "02:39:23 |     lr_scheduler_decay: 0.5\n",
            "02:39:23 |     lr_scheduler_patience: 3\n",
            "02:39:23 |     max_lr_steps: -1\n",
            "02:39:23 |     max_train_time: -1\n",
            "02:39:23 |     metrics: default\n",
            "02:39:23 |     model: transformer/generator\n",
            "02:39:23 |     model_file: /usr/local/lib/python3.7/dist-packages/data/models/blender/blender_90M/model\n",
            "02:39:23 |     model_parallel: False\n",
            "02:39:23 |     momentum: 0\n",
            "02:39:23 |     multitask_weights: '[1.0, 3.0, 3.0, 3.0]'\n",
            "02:39:23 |     n_decoder_layers: -1\n",
            "02:39:23 |     n_encoder_layers: -1\n",
            "02:39:23 |     n_heads: 16\n",
            "02:39:23 |     n_layers: 8\n",
            "02:39:23 |     n_positions: 512\n",
            "02:39:23 |     n_segments: 0\n",
            "02:39:23 |     nesterov: True\n",
            "02:39:23 |     no_cuda: False\n",
            "02:39:23 |     num_epochs: -1\n",
            "02:39:23 |     num_topics: 5\n",
            "02:39:23 |     numthreads: 1\n",
            "02:39:23 |     nus: [0.7]\n",
            "02:39:23 |     optimizer: adamax\n",
            "02:39:23 |     outfile: \n",
            "02:39:23 |     output_scaling: 1.0\n",
            "02:39:23 |     override: \"{'model_file': '/usr/local/lib/python3.7/dist-packages/data/models/blender/blender_90M/model'}\"\n",
            "02:39:23 |     parlai_home: /private/home/edinan/ParlAI\n",
            "02:39:23 |     person_tokens: False\n",
            "02:39:23 |     rank_candidates: False\n",
            "02:39:23 |     relu_dropout: 0.0\n",
            "02:39:23 |     save_after_valid: True\n",
            "02:39:23 |     save_every_n_secs: 60.0\n",
            "02:39:23 |     save_format: conversations\n",
            "02:39:23 |     share_word_embeddings: True\n",
            "02:39:23 |     short_final_eval: False\n",
            "02:39:23 |     show_advanced_args: False\n",
            "02:39:23 |     single_turn: False\n",
            "02:39:23 |     skip_generation: False\n",
            "02:39:23 |     special_tok_lst: None\n",
            "02:39:23 |     split_lines: False\n",
            "02:39:23 |     starttime: Feb10_07-25\n",
            "02:39:23 |     task: internal:blended_skill_talk,wizard_of_wikipedia,convai2,empathetic_dialogues\n",
            "02:39:23 |     temperature: 1.0\n",
            "02:39:23 |     tensorboard_log: False\n",
            "02:39:23 |     text_truncate: 512\n",
            "02:39:23 |     topk: 10\n",
            "02:39:23 |     topp: 0.9\n",
            "02:39:23 |     train_experiencer_only: False\n",
            "02:39:23 |     truncate: -1\n",
            "02:39:23 |     update_freq: 1\n",
            "02:39:23 |     use_reply: label\n",
            "02:39:23 |     validation_cutoff: 1.0\n",
            "02:39:23 |     validation_every_n_epochs: 0.25\n",
            "02:39:23 |     validation_every_n_secs: -1\n",
            "02:39:23 |     validation_max_exs: 20000\n",
            "02:39:23 |     validation_metric: ppl\n",
            "02:39:23 |     validation_metric_mode: min\n",
            "02:39:23 |     validation_patience: 15\n",
            "02:39:23 |     validation_share_agent: False\n",
            "02:39:23 |     variant: xlm\n",
            "02:39:23 |     verbose: False\n",
            "02:39:23 |     warmup_rate: 0.0001\n",
            "02:39:23 |     warmup_updates: -1\n",
            "02:39:23 |     weight_decay: None\n",
            "\u001b[1;31mEnter [DONE] if you want to end the episode, [EXIT] to quit.\u001b[0;0m\n",
            "02:39:23 | creating task(s): interactive\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m [EXIT]\n",
            "CHAT DONE \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "62tzefDg4jQ5",
        "outputId": "24edbc03-1490-4f62-977c-c47d11fc3403"
      },
      "source": [
        "DisplayData.main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: ipykernel_launcher.py [-h] [--helpall] [-o INIT_OPT]\n",
            "                             [--allow-missing-init-opts ALLOW_MISSING_INIT_OPTS]\n",
            "                             [-t TASK] [-dt DATATYPE] [-bs BATCHSIZE]\n",
            "                             [-dynb {full,batchsort,None}] [-v] [-dp DATAPATH]\n",
            "                             [-m MODEL] [-mf MODEL_FILE] [-im INIT_MODEL]\n",
            "                             [-n NUM_EXAMPLES] [-mdl MAX_DISPLAY_LEN]\n",
            "                             [--display-add-fields DISPLAY_ADD_FIELDS]\n",
            "                             [--ignore-agent-reply IGNORE_AGENT_REPLY]\n",
            "\n",
            "Display data from a task\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help\n",
            "        show this help message and exit\n",
            "  --helpall\n",
            "        Show usage, including advanced arguments.\n",
            "  -n, -ne, --num-examples NUM_EXAMPLES\n",
            "  -mdl, --max-display-len MAX_DISPLAY_LEN\n",
            "  --display-add-fields DISPLAY_ADD_FIELDS\n",
            "        Display these fields when verbose is off (e.g., \"--display-add-fields\n",
            "        label_candidates,beam_texts\") (default: )\n",
            "  --ignore-agent-reply IGNORE_AGENT_REPLY\n",
            "\n",
            "Main ParlAI Arguments:\n",
            "  -o, --init-opt INIT_OPT\n",
            "        Path to json file of options. Note: Further Command-line arguments\n",
            "        override file-based options. (default: None)\n",
            "  --allow-missing-init-opts ALLOW_MISSING_INIT_OPTS\n",
            "        Warn instead of raising if an argument passed in with --init-opt is\n",
            "        not in the target opt. (default: False)\n",
            "  -t, --task TASK\n",
            "        ParlAI task(s), e.g. \"babi:Task1\" or \"babi,cbt\" (default: None)\n",
            "  -dt, --datatype DATATYPE\n",
            "        choose from: train, train:ordered, valid, test. to stream data add\n",
            "        \":stream\" to any option (e.g., train:stream). by default train is\n",
            "        random with replacement, valid is ordered, test is ordered. (default:\n",
            "        train:ordered)\n",
            "  -bs, --batchsize BATCHSIZE\n",
            "        batch size for minibatch training schemes (default: 1)\n",
            "  -dynb, --dynamic-batching {full,batchsort,None}\n",
            "        Use dynamic batching (default: None)\n",
            "  -v, --verbose\n",
            "        Print all messages\n",
            "  -dp, --datapath DATAPATH\n",
            "        path to datasets, defaults to {parlai_dir}/data (default: None)\n",
            "\n",
            "ParlAI Model Arguments:\n",
            "  -m, --model MODEL\n",
            "        the model class name. can match parlai/agents/<model> for agents in\n",
            "        that directory, or can provide a fully specified module for `from X\n",
            "        import Y` via `-m X:Y` (e.g. `-m\n",
            "        parlai.agents.seq2seq.seq2seq:Seq2SeqAgent`) (default: None)\n",
            "  -mf, --model-file MODEL_FILE\n",
            "        model file name for loading and saving models (default: None)\n",
            "  -im, --init-model INIT_MODEL\n",
            "        Initialize model weights and dict from this file (default: None)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Parse Error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-f9afc37e-ea94-47a2-a73f-395c17f445af.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uf4oX2_03lCH"
      },
      "source": [
        "Create the task for transfer learning process for BlenderBot.  \n",
        "Two tasks have been created for training and testing purposes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1ZEWTMHZAtY",
        "outputId": "75600495-cb38-49f6-d954-118296e31a63"
      },
      "source": [
        "@register_teacher(\"custom_train\")\n",
        "class MyTeacher(DialogTeacher):\n",
        "    def __init__(self, opt, shared=None):\n",
        "        # opt is the command line arguments.\n",
        "        \n",
        "        # What is this shared thing?\n",
        "        # We make many copies of a teacher, one-per-batchsize. Shared lets us store \n",
        "        \n",
        "        # We just need to set the \"datafile\".  This is boilerplate, but differs in many teachers.\n",
        "        # The \"datafile\" is the filename where we will load the data from. In this case, we'll set it to\n",
        "        # the fold name (train/valid/test) + \".txt\"\n",
        "        opt['datafile'] = 'blenderbot_processed_data_train.txt'\n",
        "        super().__init__(opt, shared)\n",
        "    \n",
        "    def setup_data(self, datafile):\n",
        "        # filename tells us where to load from.\n",
        "        # We'll just use some hardcoded data, but show how you could read the filename here:\n",
        "        print(f\" ~~ Loading from {datafile} ~~ \")\n",
        "        \n",
        "        # setup_data should yield tuples of ((text, label), new_episode)\n",
        "        # That is ((str, str), bool)\n",
        "        \n",
        "        # first episode\n",
        "        # notice how we have call, response, and then True? The True indicates this is a first message\n",
        "        # in a conversation\n",
        "        # yield ('Hello', 'Hi'), True\n",
        "        # # Next we have the second turn. This time, the last element is False, indicating we're still going\n",
        "        # yield ('How are you', 'I am fine'), False\n",
        "        # yield (\"Let's say goodbye\", 'Goodbye!'), False\n",
        "        \n",
        "        # # second episode. We need to have True again!\n",
        "        # yield (\"Hey\", \"hi there\"), True\n",
        "        # yield (\"Deja vu?\", \"Deja vu!\"), False\n",
        "        # yield (\"Last chance\", \"This is it\"), False\n",
        "\n",
        "        # Read the file\n",
        "        with open(path.join(DATA_PATH, datafile), 'r') as text_file:\n",
        "          lines = text_file.readlines()\n",
        "          episode_check = True # For checking the end of the episode\n",
        "          for line in lines:\n",
        "            splits = line.split('\\n')[0].split('\\t')\n",
        "            text = splits[0].split('text:')[1]\n",
        "            label = splits[1].split('labels:')[1]\n",
        "            yield (text,label), episode_check # Add the text, label and end of episode boolean for each message\n",
        "            episode_check = False # Creates an episode even for a single message\n",
        "\n",
        "            # Check the end of the episode and reset boolean value if the episode is ended\n",
        "            if len(splits) == 3:\n",
        "              episode_check = True\n",
        "\n",
        "# Calling the function for registering the Teacher for transfer learning\n",
        "DisplayData.main(task='custom_train', dp=DATA_PATH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "04:29:57 | Opt:\n",
            "04:29:57 |     allow_missing_init_opts: False\n",
            "04:29:57 |     batchsize: 1\n",
            "04:29:57 |     datapath: \"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning\"\n",
            "04:29:57 |     datatype: train:ordered\n",
            "04:29:57 |     dict_class: None\n",
            "04:29:57 |     display_add_fields: \n",
            "04:29:57 |     download_path: None\n",
            "04:29:57 |     dynamic_batching: None\n",
            "04:29:57 |     hide_labels: False\n",
            "04:29:57 |     ignore_agent_reply: True\n",
            "04:29:57 |     image_cropsize: 224\n",
            "04:29:57 |     image_mode: raw\n",
            "04:29:57 |     image_size: 256\n",
            "04:29:57 |     init_model: None\n",
            "04:29:57 |     init_opt: None\n",
            "04:29:57 |     loglevel: info\n",
            "04:29:57 |     max_display_len: 1000\n",
            "04:29:57 |     model: None\n",
            "04:29:57 |     model_file: None\n",
            "04:29:57 |     multitask_weights: [1]\n",
            "04:29:57 |     mutators: None\n",
            "04:29:57 |     num_examples: 10\n",
            "04:29:57 |     override: '{\\'task\\': \\'custom_train\\', \\'datapath\\': \"/content/drive/My Drive/Master\\'s Thesis/Blenderbot Transfer Learning\"}'\n",
            "04:29:57 |     parlai_home: /usr/local/lib/python3.7/dist-packages\n",
            "04:29:57 |     starttime: Apr17_04-29\n",
            "04:29:57 |     task: custom_train\n",
            "04:29:57 |     verbose: False\n",
            "04:29:57 | creating task(s): custom_train\n",
            " ~~ Loading from blenderbot_processed_data_train.txt ~~ \n",
            "\u001b[1;31m- - - NEW EPISODE: custom_train - - -\u001b[0;0m\n",
            "\u001b[0mTest\u001b[0;0m\n",
            "   \u001b[1;94mi have a test tomorrow that i am going to test. it is a test to see if my test is good or not.\u001b[0;0m\n",
            "\u001b[0mi have a test tomorrow that i am going to test. it is a test to see if my test is good or not.\u001b[0;0m\n",
            "   \u001b[1;94mwhat kind of test are you going to take? i'm sure you'll do great!\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: custom_train - - -\u001b[0;0m\n",
            "\u001b[0mTest\u001b[0;0m\n",
            "   \u001b[1;94mi have a test tomorrow that i am going to test. it is a test to see if my test is good or not.\u001b[0;0m\n",
            "\u001b[0mi have a test tomorrow that i am going to test. it is a test to see if my test is good or not.\u001b[0;0m\n",
            "   \u001b[1;94mwhat kind of test are you going to take? i'm sure you'll do great!\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: custom_train - - -\u001b[0;0m\n",
            "\u001b[0mHello friends\u001b[0;0m\n",
            "   \u001b[1;94mHi there\u001b[0;0m\n",
            "\u001b[0mHi there\u001b[0;0m\n",
            "   \u001b[1;94mChai pilo\u001b[0;0m\n",
            "\u001b[0mChai pilo\u001b[0;0m\n",
            "   \u001b[1;94mHiya!\u001b[0;0m\n",
            "\u001b[0mHiya!\u001b[0;0m\n",
            "   \u001b[1;94mhello, how are you today? i just got back from a long day at the office.\u001b[0;0m\n",
            "\u001b[0mhello, how are you today? i just got back from a long day at the office.\u001b[0;0m\n",
            "   \u001b[1;94mi'm doing well. i just got back from a long day at work as well.\u001b[0;0m\n",
            "\u001b[0mi'm doing well. i just got back from a long day at work as well.\u001b[0;0m\n",
            "   \u001b[1;94mGood to hear.\u001b[0;0m\n",
            "04:29:58 | loaded 29 episodes with a total of 359 examples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ou8k3j4vqrSb",
        "outputId": "653b39a4-47ed-4a35-a3fb-4dd190669ff2"
      },
      "source": [
        "@register_teacher(\"custom_test\")\n",
        "class MyTeacher(DialogTeacher):\n",
        "    def __init__(self, opt, shared=None):\n",
        "        # opt is the command line arguments.\n",
        "        \n",
        "        # What is this shared thing?\n",
        "        # We make many copies of a teacher, one-per-batchsize. Shared lets us store \n",
        "        \n",
        "        # We just need to set the \"datafile\".  This is boilerplate, but differs in many teachers.\n",
        "        # The \"datafile\" is the filename where we will load the data from. In this case, we'll set it to\n",
        "        # the fold name (train/valid/test) + \".txt\"\n",
        "        opt['datafile'] = 'blenderbot_processed_data_test.txt'\n",
        "        super().__init__(opt, shared)\n",
        "    \n",
        "    def setup_data(self, datafile):\n",
        "        # filename tells us where to load from.\n",
        "        # We'll just use some hardcoded data, but show how you could read the filename here:\n",
        "        print(f\" ~~ Loading from {datafile} ~~ \")\n",
        "        \n",
        "        # setup_data should yield tuples of ((text, label), new_episode)\n",
        "        # That is ((str, str), bool)\n",
        "        \n",
        "        # first episode\n",
        "        # notice how we have call, response, and then True? The True indicates this is a first message\n",
        "        # in a conversation\n",
        "        # yield ('Hello', 'Hi'), True\n",
        "        # # Next we have the second turn. This time, the last element is False, indicating we're still going\n",
        "        # yield ('How are you', 'I am fine'), False\n",
        "        # yield (\"Let's say goodbye\", 'Goodbye!'), False\n",
        "        \n",
        "        # # second episode. We need to have True again!\n",
        "        # yield (\"Hey\", \"hi there\"), True\n",
        "        # yield (\"Deja vu?\", \"Deja vu!\"), False\n",
        "        # yield (\"Last chance\", \"This is it\"), False\n",
        "\n",
        "        # Read the file\n",
        "        with open(path.join(DATA_PATH, datafile), 'r') as text_file:\n",
        "          lines = text_file.readlines()\n",
        "          episode_check = True # For checking the end of the episode\n",
        "          for line in lines:\n",
        "            splits = line.split('\\n')[0].split('\\t')\n",
        "            text = splits[0].split('text:')[1]\n",
        "            label = splits[1].split('labels:')[1]\n",
        "            yield (text,label), episode_check # Add the text, label and end of episode boolean for each message\n",
        "            episode_check = False # Creates an episode even for a single message\n",
        "\n",
        "            # Check the end of the episode and reset boolean value if the episode is ended\n",
        "            if len(splits) == 3:\n",
        "              episode_check = True\n",
        "\n",
        "# Calling the function for registering the Teacher for transfer learning\n",
        "DisplayData.main(task='custom_test', dp=DATA_PATH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "04:30:00 | Opt:\n",
            "04:30:00 |     allow_missing_init_opts: False\n",
            "04:30:00 |     batchsize: 1\n",
            "04:30:00 |     datapath: \"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning\"\n",
            "04:30:00 |     datatype: train:ordered\n",
            "04:30:00 |     dict_class: None\n",
            "04:30:00 |     display_add_fields: \n",
            "04:30:00 |     download_path: None\n",
            "04:30:00 |     dynamic_batching: None\n",
            "04:30:00 |     hide_labels: False\n",
            "04:30:00 |     ignore_agent_reply: True\n",
            "04:30:00 |     image_cropsize: 224\n",
            "04:30:00 |     image_mode: raw\n",
            "04:30:00 |     image_size: 256\n",
            "04:30:00 |     init_model: None\n",
            "04:30:00 |     init_opt: None\n",
            "04:30:00 |     loglevel: info\n",
            "04:30:00 |     max_display_len: 1000\n",
            "04:30:00 |     model: None\n",
            "04:30:00 |     model_file: None\n",
            "04:30:00 |     multitask_weights: [1]\n",
            "04:30:00 |     mutators: None\n",
            "04:30:00 |     num_examples: 10\n",
            "04:30:00 |     override: '{\\'task\\': \\'custom_test\\', \\'datapath\\': \"/content/drive/My Drive/Master\\'s Thesis/Blenderbot Transfer Learning\"}'\n",
            "04:30:00 |     parlai_home: /usr/local/lib/python3.7/dist-packages\n",
            "04:30:00 |     starttime: Apr17_04-30\n",
            "04:30:00 |     task: custom_test\n",
            "04:30:00 |     verbose: False\n",
            "04:30:00 | creating task(s): custom_test\n",
            " ~~ Loading from blenderbot_processed_data_test.txt ~~ \n",
            "\u001b[1;31m- - - NEW EPISODE: custom_test - - -\u001b[0;0m\n",
            "\u001b[0mHello\u001b[0;0m\n",
            "   \u001b[1;94mhello, how are you today? i just got back from a long day at the office.\u001b[0;0m\n",
            "\u001b[0mhello, how are you today? i just got back from a long day at the office.\u001b[0;0m\n",
            "   \u001b[1;94mI'm doing well, thanks for asking.\u001b[0;0m\n",
            "\u001b[0mI'm doing well, thanks for asking.\u001b[0;0m\n",
            "   \u001b[1;94mthat's good to hear. i'm glad you're having a good day.\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: custom_test - - -\u001b[0;0m\n",
            "\u001b[0mHello\u001b[0;0m\n",
            "   \u001b[1;94mhello, how are you today? i just got back from a long day at the office.\u001b[0;0m\n",
            "\u001b[0mhello, how are you today? i just got back from a long day at the office.\u001b[0;0m\n",
            "   \u001b[1;94mI'm doing well, thanks for asking.\u001b[0;0m\n",
            "\u001b[0mI'm doing well, thanks for asking.\u001b[0;0m\n",
            "   \u001b[1;94mthat's good to hear. i'm glad you're having a good day.\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: custom_test - - -\u001b[0;0m\n",
            "\u001b[0mHello there\u001b[0;0m\n",
            "   \u001b[1;94mHello Kitty\u001b[0;0m\n",
            "\u001b[0mHello Kitty\u001b[0;0m\n",
            "   \u001b[1;94mi love kitty kitty! she's my favorite cat. do you have a favorite cat?\u001b[0;0m\n",
            "\u001b[0mi love kitty kitty! she's my favorite cat. do you have a favorite cat?\u001b[0;0m\n",
            "   \u001b[1;94mBut i like dogs\u001b[0;0m\n",
            "\u001b[0mBut i like dogs\u001b[0;0m\n",
            "   \u001b[1;94mwhat kind of dogs do you like? there are so many different kinds of dogs out there.\u001b[0;0m\n",
            "04:30:00 | loaded 8 episodes with a total of 30 examples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cc6tQCpB6IAm"
      },
      "source": [
        "## Transfer Learning\n",
        "Beginning the transfer learning process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yn8qLogR20Ba",
        "outputId": "3bef31ca-17a2-4036-8140-562bb483e972"
      },
      "source": [
        "# View the available options for transfer learning\n",
        "TrainModel.main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: ipykernel_launcher.py [-h] [--helpall] [-o INIT_OPT]\n",
            "                             [--allow-missing-init-opts ALLOW_MISSING_INIT_OPTS]\n",
            "                             [-t TASK] [-dt DATATYPE] [-bs BATCHSIZE]\n",
            "                             [-dynb {full,batchsort,None}] [-v] [-dp DATAPATH]\n",
            "                             [-m MODEL] [-mf MODEL_FILE] [-im INIT_MODEL]\n",
            "                             [-et EVALTASK]\n",
            "                             [--eval-dynamic-batching {full,batchsort,None,off}]\n",
            "                             [-eps NUM_EPOCHS] [-ttim MAX_TRAIN_TIME]\n",
            "                             [-vtim VALIDATION_EVERY_N_SECS]\n",
            "                             [-stim SAVE_EVERY_N_SECS]\n",
            "                             [-sval SAVE_AFTER_VALID]\n",
            "                             [-veps VALIDATION_EVERY_N_EPOCHS]\n",
            "                             [-vp VALIDATION_PATIENCE]\n",
            "                             [-vmt VALIDATION_METRIC] [-vmm {max,min}]\n",
            "                             [-mcs METRICS] [-micro AGGREGATE_MICRO]\n",
            "                             [-tblog TENSORBOARD_LOG]\n",
            "                             [-tblogdir TENSORBOARD_LOGDIR] [-wblog WANDB_LOG]\n",
            "                             [--wandb-project WANDB_PROJECT]\n",
            "                             [--bpe-vocab BPE_VOCAB] [--bpe-merge BPE_MERGE]\n",
            "                             [--bpe-dropout BPE_DROPOUT]\n",
            "\n",
            "Train a model\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help\n",
            "        show this help message and exit\n",
            "  --helpall\n",
            "        Show usage, including advanced arguments.\n",
            "\n",
            "Main ParlAI Arguments:\n",
            "  -o, --init-opt INIT_OPT\n",
            "        Path to json file of options. Note: Further Command-line arguments\n",
            "        override file-based options. (default: None)\n",
            "  --allow-missing-init-opts ALLOW_MISSING_INIT_OPTS\n",
            "        Warn instead of raising if an argument passed in with --init-opt is\n",
            "        not in the target opt. (default: False)\n",
            "  -t, --task TASK\n",
            "        ParlAI task(s), e.g. \"babi:Task1\" or \"babi,cbt\" (default: None)\n",
            "  -dt, --datatype DATATYPE\n",
            "        choose from: train, train:ordered, valid, test. to stream data add\n",
            "        \":stream\" to any option (e.g., train:stream). by default train is\n",
            "        random with replacement, valid is ordered, test is ordered. (default:\n",
            "        train)\n",
            "  -bs, --batchsize BATCHSIZE\n",
            "        batch size for minibatch training schemes (default: 1)\n",
            "  -dynb, --dynamic-batching {full,batchsort,None}\n",
            "        Use dynamic batching (default: None)\n",
            "  -v, --verbose\n",
            "        Print all messages\n",
            "  -dp, --datapath DATAPATH\n",
            "        path to datasets, defaults to {parlai_dir}/data (default: None)\n",
            "\n",
            "ParlAI Model Arguments:\n",
            "  -m, --model MODEL\n",
            "        the model class name. can match parlai/agents/<model> for agents in\n",
            "        that directory, or can provide a fully specified module for `from X\n",
            "        import Y` via `-m X:Y` (e.g. `-m\n",
            "        parlai.agents.seq2seq.seq2seq:Seq2SeqAgent`) (default: None)\n",
            "  -mf, --model-file MODEL_FILE\n",
            "        model file name for loading and saving models (default: None)\n",
            "  -im, --init-model INIT_MODEL\n",
            "        Initialize model weights and dict from this file (default: None)\n",
            "\n",
            "Training Loop Arguments:\n",
            "  -et, --evaltask EVALTASK\n",
            "        task to use for valid/test (defaults to the one used for training)\n",
            "        (default: None)\n",
            "  --eval-dynamic-batching {full,batchsort,None,off}\n",
            "        Set dynamic batching at evaluation time. Set to off for train-only\n",
            "        dynamic batching. Set to none (default) to use same setting as\n",
            "        --dynamic-batching. (default: None)\n",
            "  -eps, --num-epochs NUM_EPOCHS\n",
            "  -ttim, --max-train-time MAX_TRAIN_TIME\n",
            "  -vtim, --validation-every-n-secs VALIDATION_EVERY_N_SECS\n",
            "        Validate every n seconds. Saves model to model_file (if set) whenever\n",
            "        best val metric is found (default: -1)\n",
            "  -stim, --save-every-n-secs SAVE_EVERY_N_SECS\n",
            "        Saves the model to model_file.checkpoint after every n seconds\n",
            "        (default -1, never). (default: -1)\n",
            "  -sval, --save-after-valid SAVE_AFTER_VALID\n",
            "        Saves the model to model_file.checkpoint after every validation\n",
            "        (default False).\n",
            "  -veps, --validation-every-n-epochs VALIDATION_EVERY_N_EPOCHS\n",
            "        Validate every n epochs. Saves model to model_file (if set) whenever\n",
            "        best val metric is found (default: -1)\n",
            "  -vp, --validation-patience VALIDATION_PATIENCE\n",
            "        number of iterations of validation where result does not improve\n",
            "        before we stop training (default: 10)\n",
            "  -vmt, --validation-metric VALIDATION_METRIC\n",
            "        key into report table for selecting best validation (default:\n",
            "        accuracy)\n",
            "  -vmm, --validation-metric-mode {max,min}\n",
            "        how to optimize validation metric (max or min) (default: None)\n",
            "  -mcs, --metrics METRICS\n",
            "        list of metrics to show/compute, e.g. all, default,or give a list\n",
            "        split by , like ppl,f1,accuracy,hits@1,rouge,bleuthe rouge metrics\n",
            "        will be computed as rouge-1, rouge-2 and rouge-l (default: default)\n",
            "  -micro, --aggregate-micro AGGREGATE_MICRO\n",
            "        Report micro-averaged metrics instead of macro averaged metrics.\n",
            "        (default: False)\n",
            "\n",
            "Tensorboard Arguments:\n",
            "  -tblog, --tensorboard-log TENSORBOARD_LOG\n",
            "        Tensorboard logging of metrics (default: False)\n",
            "  -tblogdir, --tensorboard-logdir TENSORBOARD_LOGDIR\n",
            "        Tensorboard logging directory, defaults to model_file.tensorboard\n",
            "        (default: None)\n",
            "\n",
            "WandB Arguments:\n",
            "  -wblog, --wandb-log WANDB_LOG\n",
            "        Enable W&B logging of metrics (default: False)\n",
            "  --wandb-project WANDB_PROJECT\n",
            "        W&B project name. Defaults to timestamp. Usually the name of the\n",
            "        sweep. (default: None)\n",
            "\n",
            "BPEHelper Arguments:\n",
            "  --bpe-vocab BPE_VOCAB\n",
            "        path to pre-trained tokenizer vocab (default: None)\n",
            "  --bpe-merge BPE_MERGE\n",
            "        path to pre-trained tokenizer merge (default: None)\n",
            "  --bpe-dropout BPE_DROPOUT\n",
            "        Use BPE dropout during training. (default: None)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Parse Error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-f9afc37e-ea94-47a2-a73f-395c17f445af.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXBEo6rybdEG",
        "outputId": "a1875dab-e6ad-4a1a-9a64-58288c70af27"
      },
      "source": [
        "# The files are stored into the temporary storage of Google Drive so make sure that the \"from_pretrained\" folder is copied\n",
        "\n",
        "!rm -rf from_pretrained\n",
        "!mkdir -p from_pretrained\n",
        "\n",
        "\n",
        "TrainModel.main(\n",
        "    # change path\n",
        "    dp=DATA_PATH,\n",
        "    # similar to before\n",
        "    task='custom_train', \n",
        "    model='transformer/generator',\n",
        "    model_file='from_pretrained/model',\n",
        "    \n",
        "    # initialize with a pretrained model\n",
        "    init_model='zoo:blender/blender_90M/model',\n",
        "    \n",
        "    # arguments we get from the pretrained model.\n",
        "    # Unfortunately, these must be looked up separately for each model.\n",
        "    n_heads=16, n_layers=8, n_positions=512, text_truncate=512,\n",
        "    label_truncate=128, ffn_size=2048, embedding_size=512,\n",
        "    activation='gelu', variant='xlm',\n",
        "    dict_lower=True, dict_tokenizer='bpe',\n",
        "    dict_file='zoo:blender/blender_90M/model.dict',\n",
        "    learn_positional_embeddings=True,\n",
        "    \n",
        "    # some training arguments, specific to this fine-tuning\n",
        "    # use a small learning rate with ADAM optimizer\n",
        "    lr=1e-5, optimizer='adam',\n",
        "    warmup_updates=100,\n",
        "    # early stopping on perplexity\n",
        "    validation_metric='ppl',\n",
        "    # train at most 10 minutes, and validate every 0.25 epochs\n",
        "    max_train_time=1200, validation_every_n_epochs=0.25,\n",
        "    \n",
        "    # depend on your gpu. If you have a V100, this is good\n",
        "    batchsize=12, fp16=True, fp16_impl='mem_efficient',\n",
        "    \n",
        "    # speeds up validation but it produces limited metrics\n",
        "    skip_generation=True,\n",
        "\n",
        "    # metrics to compute like ppl,f1,accuracy,hits@1,rouge,bleu\n",
        "    # metrics=['ppl', 'bleu-4'],\n",
        "    \n",
        "    # helps us cram more examples into our gpu at a time\n",
        "    dynamic_batching='full',\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "02:44:13 | building dictionary first...\n",
            "02:44:13 | No model with opt yet at: from_pretrained/model(.opt)\n",
            "02:44:13 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,download_path: None,loglevel: info,dynamic_batching: full,verbose: False,datapath: /content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning,eval_dynamic_batching: None,load_from_checkpoint: True,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,mutators: None,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,beam_block_full_context: True,beam_delay: 30,beam_block_list_filename: None,temperature: 1.0,interactive_mode: False,history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None\u001b[0m\n",
            "02:44:13 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n",
            "--show-advanced-args False --task internal:blended_skill_talk,wizard_of_wikipedia,convai2,empathetic_dialogues --numthreads 1 --multitask-weights 1.0,3.0,3.0,3.0 --batchsize 16 --max-train-time -1 --save-every-n-secs 60.0 --save-after-valid True --validation-max-exs 20000 --validation-patience 15 --validation-metric-mode min --log-every-n-secs 2 --label-type response --include-knowledge True --include-checked-sentence True --include-knowledge-separator False --num-topics 5 --train-experiencer-only False --dropout 0.1 --beam-size 10 --beam-min-length 20 --beam-context-block-ngram 3 --beam-block-ngram 3 --skip-generation False --inference beam --fp16-impl apex --optimizer adamax --learningrate 7.5e-06 --warmup-updates -1 --parlai-home /private/home/edinan/ParlAI\u001b[0m\n",
            "02:44:13 | Using CUDA\n",
            "02:44:13 | loading dictionary from /content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/models/blender/blender_90M/model.dict\n",
            "02:44:13 | num words = 54944\n",
            "02:44:15 | Total parameters: 87,508,992 (87,508,992 trainable)\n",
            "02:44:15 | Loading existing model params from /content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/models/blender/blender_90M/model\n",
            "02:44:20 | Opt:\n",
            "02:44:20 |     activation: gelu\n",
            "02:44:20 |     adafactor_eps: '(1e-30, 0.001)'\n",
            "02:44:20 |     adam_eps: 1e-08\n",
            "02:44:20 |     add_p1_after_newln: False\n",
            "02:44:20 |     aggregate_micro: False\n",
            "02:44:20 |     allow_missing_init_opts: False\n",
            "02:44:20 |     attention_dropout: 0.0\n",
            "02:44:20 |     batchsize: 12\n",
            "02:44:20 |     beam_block_full_context: True\n",
            "02:44:20 |     beam_block_list_filename: None\n",
            "02:44:20 |     beam_block_ngram: -1\n",
            "02:44:20 |     beam_context_block_ngram: -1\n",
            "02:44:20 |     beam_delay: 30\n",
            "02:44:20 |     beam_length_penalty: 0.65\n",
            "02:44:20 |     beam_min_length: 1\n",
            "02:44:20 |     beam_size: 1\n",
            "02:44:20 |     betas: '(0.9, 0.999)'\n",
            "02:44:20 |     bpe_add_prefix_space: None\n",
            "02:44:20 |     bpe_debug: False\n",
            "02:44:20 |     bpe_dropout: None\n",
            "02:44:20 |     bpe_merge: None\n",
            "02:44:20 |     bpe_vocab: None\n",
            "02:44:20 |     compute_tokenized_bleu: False\n",
            "02:44:20 |     datapath: \"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning\"\n",
            "02:44:20 |     datatype: train\n",
            "02:44:20 |     delimiter: '\\n'\n",
            "02:44:20 |     dict_class: parlai.core.dict:DictionaryAgent\n",
            "02:44:20 |     dict_endtoken: __end__\n",
            "02:44:20 |     dict_file: \"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/models/blender/blender_90M/model.dict\"\n",
            "02:44:20 |     dict_include_test: False\n",
            "02:44:20 |     dict_include_valid: False\n",
            "02:44:20 |     dict_initpath: None\n",
            "02:44:20 |     dict_language: english\n",
            "02:44:20 |     dict_loaded: True\n",
            "02:44:20 |     dict_lower: True\n",
            "02:44:20 |     dict_max_ngram_size: -1\n",
            "02:44:20 |     dict_maxexs: -1\n",
            "02:44:20 |     dict_maxtokens: -1\n",
            "02:44:20 |     dict_minfreq: 0\n",
            "02:44:20 |     dict_nulltoken: __null__\n",
            "02:44:20 |     dict_starttoken: __start__\n",
            "02:44:20 |     dict_textfields: text,labels\n",
            "02:44:20 |     dict_tokenizer: bpe\n",
            "02:44:20 |     dict_unktoken: __unk__\n",
            "02:44:20 |     display_examples: False\n",
            "02:44:20 |     download_path: None\n",
            "02:44:20 |     dropout: 0.0\n",
            "02:44:20 |     dynamic_batching: full\n",
            "02:44:20 |     embedding_projection: random\n",
            "02:44:20 |     embedding_size: 512\n",
            "02:44:20 |     embedding_type: random\n",
            "02:44:20 |     embeddings_scale: True\n",
            "02:44:20 |     eval_batchsize: None\n",
            "02:44:20 |     eval_dynamic_batching: None\n",
            "02:44:20 |     evaltask: None\n",
            "02:44:20 |     ffn_size: 2048\n",
            "02:44:20 |     force_fp16_tokens: False\n",
            "02:44:20 |     fp16: True\n",
            "02:44:20 |     fp16_impl: mem_efficient\n",
            "02:44:20 |     gpu: -1\n",
            "02:44:20 |     gradient_clip: 0.1\n",
            "02:44:20 |     hide_labels: False\n",
            "02:44:20 |     history_add_global_end_token: None\n",
            "02:44:20 |     history_reversed: False\n",
            "02:44:20 |     history_size: -1\n",
            "02:44:20 |     image_cropsize: 224\n",
            "02:44:20 |     image_mode: raw\n",
            "02:44:20 |     image_size: 256\n",
            "02:44:20 |     inference: greedy\n",
            "02:44:20 |     init_model: \"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/models/blender/blender_90M/model\"\n",
            "02:44:20 |     init_opt: None\n",
            "02:44:20 |     interactive_mode: False\n",
            "02:44:20 |     invsqrt_lr_decay_gamma: -1\n",
            "02:44:20 |     label_truncate: 128\n",
            "02:44:20 |     learn_positional_embeddings: True\n",
            "02:44:20 |     learningrate: 1e-05\n",
            "02:44:20 |     load_from_checkpoint: True\n",
            "02:44:20 |     log_every_n_secs: 10\n",
            "02:44:20 |     loglevel: info\n",
            "02:44:20 |     lr_scheduler: reduceonplateau\n",
            "02:44:20 |     lr_scheduler_decay: 0.5\n",
            "02:44:20 |     lr_scheduler_patience: 3\n",
            "02:44:20 |     max_lr_steps: -1\n",
            "02:44:20 |     max_train_time: 1200.0\n",
            "02:44:20 |     metrics: default\n",
            "02:44:20 |     model: transformer/generator\n",
            "02:44:20 |     model_file: from_pretrained/model\n",
            "02:44:20 |     model_parallel: False\n",
            "02:44:20 |     momentum: 0\n",
            "02:44:20 |     multitask_weights: [1]\n",
            "02:44:20 |     mutators: None\n",
            "02:44:20 |     n_decoder_layers: -1\n",
            "02:44:20 |     n_encoder_layers: -1\n",
            "02:44:20 |     n_heads: 16\n",
            "02:44:20 |     n_layers: 8\n",
            "02:44:20 |     n_positions: 512\n",
            "02:44:20 |     n_segments: 0\n",
            "02:44:20 |     nesterov: True\n",
            "02:44:20 |     no_cuda: False\n",
            "02:44:20 |     num_epochs: -1\n",
            "02:44:20 |     nus: (0.7,)\n",
            "02:44:20 |     optimizer: mem_eff_adam\n",
            "02:44:20 |     output_scaling: 1.0\n",
            "02:44:20 |     override: '{\\'datapath\\': \"/content/drive/My Drive/Master\\'s Thesis/Blenderbot Transfer Learning\", \\'task\\': \\'custom_train\\', \\'model\\': \\'transformer/generator\\', \\'model_file\\': \\'from_pretrained/model\\', \\'init_model\\': \\'zoo:blender/blender_90M/model\\', \\'n_heads\\': 16, \\'n_layers\\': 8, \\'n_positions\\': 512, \\'text_truncate\\': 512, \\'label_truncate\\': 128, \\'ffn_size\\': 2048, \\'embedding_size\\': 512, \\'activation\\': \\'gelu\\', \\'variant\\': \\'xlm\\', \\'dict_lower\\': True, \\'dict_tokenizer\\': \\'bpe\\', \\'dict_file\\': \"/content/drive/My Drive/Master\\'s Thesis/Blenderbot Transfer Learning/models/blender/blender_90M/model.dict\", \\'learn_positional_embeddings\\': True, \\'learningrate\\': 1e-05, \\'optimizer\\': \\'adam\\', \\'warmup_updates\\': 100, \\'validation_metric\\': \\'ppl\\', \\'max_train_time\\': 1200.0, \\'validation_every_n_epochs\\': 0.25, \\'batchsize\\': 12, \\'fp16\\': True, \\'fp16_impl\\': \\'mem_efficient\\', \\'skip_generation\\': True, \\'dynamic_batching\\': \\'full\\'}'\n",
            "02:44:20 |     parlai_home: /usr/local/lib/python3.7/dist-packages\n",
            "02:44:20 |     person_tokens: False\n",
            "02:44:20 |     rank_candidates: False\n",
            "02:44:20 |     relu_dropout: 0.0\n",
            "02:44:20 |     save_after_valid: False\n",
            "02:44:20 |     save_every_n_secs: -1\n",
            "02:44:20 |     share_word_embeddings: True\n",
            "02:44:20 |     short_final_eval: False\n",
            "02:44:20 |     skip_generation: True\n",
            "02:44:20 |     special_tok_lst: None\n",
            "02:44:20 |     split_lines: False\n",
            "02:44:20 |     starttime: Apr17_02-44\n",
            "02:44:20 |     task: custom_train\n",
            "02:44:20 |     temperature: 1.0\n",
            "02:44:20 |     tensorboard_log: False\n",
            "02:44:20 |     tensorboard_logdir: None\n",
            "02:44:20 |     text_truncate: 512\n",
            "02:44:20 |     topk: 10\n",
            "02:44:20 |     topp: 0.9\n",
            "02:44:20 |     truncate: -1\n",
            "02:44:20 |     update_freq: 1\n",
            "02:44:20 |     use_reply: label\n",
            "02:44:20 |     validation_cutoff: 1.0\n",
            "02:44:20 |     validation_every_n_epochs: 0.25\n",
            "02:44:20 |     validation_every_n_secs: -1\n",
            "02:44:20 |     validation_max_exs: -1\n",
            "02:44:20 |     validation_metric: ppl\n",
            "02:44:20 |     validation_metric_mode: None\n",
            "02:44:20 |     validation_patience: 10\n",
            "02:44:20 |     validation_share_agent: False\n",
            "02:44:20 |     variant: xlm\n",
            "02:44:20 |     verbose: False\n",
            "02:44:20 |     wandb_log: False\n",
            "02:44:20 |     wandb_name: None\n",
            "02:44:20 |     wandb_project: None\n",
            "02:44:20 |     warmup_rate: 0.0001\n",
            "02:44:20 |     warmup_updates: 100\n",
            "02:44:20 |     weight_decay: None\n",
            "02:44:20 | creating task(s): custom_train\n",
            " ~~ Loading from blenderbot_processed_data_train.txt ~~ \n",
            "02:44:21 | training...\n",
            "02:44:22 | Overflow: setting loss scale to 65536.0\n",
            "02:44:22 | time:1s total_exs:480 epochs:1.34\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss       lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       0   668 934.8 655.6  480             65536     -1    .2668 3.101 1.01e-07  1646  2303 22.22      .3676   \n",
            "    total_train_updates  tpb  tps   ups  \n",
            "                      1 2314 3238 1.402\n",
            "\n",
            "02:44:22 | creating task(s): custom_train\n",
            " ~~ Loading from blenderbot_processed_data_train.txt ~~ \n",
            "02:44:24 | running eval: valid\n",
            "02:44:24 | \u001b[33m--skip-generation true produces limited metrics\u001b[0m\n",
            "02:44:25 | eval completed in 1.55s\n",
            "02:44:25 | \u001b[1mvalid:\n",
            "    ctpb  ctps  exps  exs  gpu_mem  loss       lr  ltpb  ltps   ppl  token_acc  total_train_updates  tpb   tps\n",
            "    1698 47530 239.2  359   .08889 2.194 1.01e-07 82.79  2317 8.972      .5416                    1 1781 49847\n",
            "\u001b[0m\n",
            "02:44:25 | \u001b[1;32mnew best ppl: 8.972\u001b[0m\n",
            "02:44:25 | saving best valid model: from_pretrained/model\n",
            "02:44:25 | Saving dictionary to from_pretrained/model.dict\n",
            "02:44:29 | Overflow: setting loss scale to 32768.0\n",
            "02:44:29 | time:8s total_exs:960 epochs:2.67\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss       lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       0  1351  4148  1473  480             32768     -1    .3317  3.26 2.01e-07  1777  5455 26.05      .3889   \n",
            "    total_train_updates  tpb  tps  ups  \n",
            "                      2 3128 9604 3.09\n",
            "\n",
            "02:44:29 | running eval: valid\n",
            "02:44:31 | eval completed in 1.58s\n",
            "02:44:31 | \u001b[1mvalid:\n",
            "    ctpb  ctps  exps  exs  gpu_mem  loss       lr  ltpb  ltps   ppl  token_acc  total_train_updates  tpb   tps\n",
            "    1621 46833 235.7  359    .0889 2.194 2.01e-07 79.02  2283 8.972      .5416                    2 1700 49116\n",
            "\u001b[0m\n",
            "02:44:31 | \u001b[1mdid not beat best ppl: 8.9717 impatience: 1\u001b[0m\n",
            "02:44:31 | time:10s total_exs:1200 epochs:3.34\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss       lr  ltpb  ltps  ppl  token_acc  \\\n",
            "       1  2802 10846   923  240             32768   23.8    .3379 2.261 3.01e-07  2323  8952 9.59      .5794   \n",
            "    total_train_updates  tpb   tps  ups  \n",
            "                      3 5125 19838 3.89\n",
            "\n",
            "02:44:31 | running eval: valid\n",
            "02:44:33 | eval completed in 1.59s\n",
            "02:44:33 | \u001b[1mvalid:\n",
            "    ctpb  ctps  exps  exs  gpu_mem  loss       lr  ltpb  ltps   ppl  token_acc  total_train_updates  tpb   tps\n",
            "    1621 46371 233.3  359    .0889 2.194 3.01e-07 79.02  2260 8.971      .5418                    3 1700 48631\n",
            "\u001b[0m\n",
            "02:44:33 | \u001b[1;32mnew best ppl: 8.971 (previous best was 8.972)\u001b[0m\n",
            "02:44:33 | saving best valid model: from_pretrained/model\n",
            "02:44:37 | time:16s total_exs:1392 epochs:3.88\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss       lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       1  2573  7171 534.7  192             32768  17.66    .3955 1.549 4.01e-07  2026  5645 4.707      .7626   \n",
            "    total_train_updates  tpb   tps   ups  \n",
            "                      4 4599 12817 2.796\n",
            "\n",
            "02:44:37 | running eval: valid\n",
            "02:44:39 | eval completed in 1.58s\n",
            "02:44:39 | \u001b[1mvalid:\n",
            "    ctpb  ctps  exps  exs  gpu_mem  loss       lr  ltpb  ltps   ppl  token_acc  total_train_updates  tpb   tps\n",
            "    1659 46788 235.4  359   .08891 2.194 4.01e-07 80.86  2280 8.971      .5416                    4 1740 49068\n",
            "\u001b[0m\n",
            "02:44:39 | \u001b[1mdid not beat best ppl: 8.9713 impatience: 1\u001b[0m\n",
            "02:44:39 | Overflow: setting loss scale to 16384.0\n",
            "02:44:39 | time:18s total_exs:1784 epochs:4.97\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss       lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       0  1606  6784  1644  392             16384     -1    .2874 3.542 5.01e-07  1515  6397 34.52      .3908   \n",
            "    total_train_updates  tpb   tps   ups  \n",
            "                      5 3121 13184 4.254\n",
            "\n",
            "02:44:39 | running eval: valid\n",
            "02:44:41 | eval completed in 1.56s\n",
            "02:44:41 | \u001b[1mvalid:\n",
            "    ctpb  ctps  exps  exs  gpu_mem  loss       lr  ltpb  ltps   ppl  token_acc  total_train_updates  tpb   tps\n",
            "    1659 47409 238.5  359    .0889 2.194 5.01e-07 80.86  2311 8.972      .5416                    5 1740 49719\n",
            "\u001b[0m\n",
            "02:44:41 | \u001b[1mdid not beat best ppl: 8.9713 impatience: 2\u001b[0m\n",
            "02:44:41 | time:20s total_exs:1888 epochs:5.26\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss        lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       1  5050 20602 423.6  104             16384  30.11    .3094 1.843 6.009e-07  1335  5443 6.312      .6404   \n",
            "    total_train_updates  tpb   tps   ups  \n",
            "                      6 6385 26049 4.094\n",
            "\n",
            "02:44:41 | running eval: valid\n",
            "02:44:43 | eval completed in 1.53s\n",
            "02:44:43 | \u001b[1mvalid:\n",
            "    ctpb  ctps  exps  exs  gpu_mem  loss        lr  ltpb  ltps   ppl  token_acc  total_train_updates  tpb   tps\n",
            "    1698 48365 243.4  359    .0889 2.194 6.009e-07 82.79  2357 8.971      .5418                    6 1781 50723\n",
            "\u001b[0m\n",
            "02:44:43 | \u001b[1mdid not beat best ppl: 8.9713 impatience: 3\u001b[0m\n",
            "02:44:43 | time:21s total_exs:2048 epochs:5.70\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss        lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       1  4740 16019 540.1  160             16384  22.39    .3839 1.335 7.009e-07  1488  5027 3.798      .6640   \n",
            "    total_train_updates  tpb   tps   ups  \n",
            "                      7 6228 21049 3.391\n",
            "\n",
            "02:44:43 | running eval: valid\n",
            "02:44:45 | eval completed in 1.70s\n",
            "02:44:45 | \u001b[1mvalid:\n",
            "    ctpb  ctps  exps  exs  gpu_mem  loss        lr  ltpb  ltps  ppl  token_acc  total_train_updates  tpb   tps\n",
            "    1698 43375 218.3  359   .08889 2.194 7.009e-07 82.79  2114 8.97      .5418                    7 1781 45490\n",
            "\u001b[0m\n",
            "02:44:45 | \u001b[1;32mnew best ppl: 8.97 (previous best was 8.971)\u001b[0m\n",
            "02:44:45 | saving best valid model: from_pretrained/model\n",
            "02:44:55 | time:33s total_exs:2280 epochs:6.35\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss        lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       1   983  3080 726.5  232             16384  39.25    .3073 3.919 8.009e-07  1811  5674 50.36      .3158   \n",
            "    total_train_updates  tpb  tps   ups  \n",
            "                      8 2794 8756 3.148\n",
            "\n",
            "02:44:55 | running eval: valid\n",
            "02:44:56 | eval completed in 1.57s\n",
            "02:44:56 | \u001b[1mvalid:\n",
            "    ctpb  ctps  exps  exs  gpu_mem  loss        lr  ltpb  ltps  ppl  token_acc  total_train_updates  tpb   tps\n",
            "    1659 47520 239.1  359    .0889 2.194 8.009e-07 80.86  2316 8.97      .5418                    8 1740 49837\n",
            "\u001b[0m\n",
            "02:44:56 | \u001b[1mdid not beat best ppl: 8.9701 impatience: 1\u001b[0m\n",
            "02:44:57 | time:35s total_exs:2416 epochs:6.73\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss        lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       1  4587 17707 524.5  136             16384  23.09    .3402 1.912 9.009e-07  1308  5048 6.765      .5902   \n",
            "    total_train_updates  tpb   tps   ups  \n",
            "                      9 5895 22756 3.877\n",
            "\n",
            "02:44:57 | running eval: valid\n",
            "02:44:58 | eval completed in 1.63s\n",
            "02:44:58 | \u001b[1mvalid:\n",
            "    ctpb  ctps  exps  exs  gpu_mem  loss        lr  ltpb  ltps   ppl  token_acc  total_train_updates  tpb   tps\n",
            "    1659 45401 228.3  359    .0889 2.194 9.009e-07 80.86  2213 8.969      .5418                    9 1740 47614\n",
            "\u001b[0m\n",
            "02:44:58 | \u001b[1;32mnew best ppl: 8.969 (previous best was 8.97)\u001b[0m\n",
            "02:44:58 | saving best valid model: from_pretrained/model\n",
            "02:45:23 | time:61s total_exs:2576 epochs:7.18\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss        lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       1  3437  8900   414  160             16384  22.34    .3839  1.28 1.001e-06  2543  6583 3.596      .7275   \n",
            "    total_train_updates  tpb   tps   ups  \n",
            "                     10 5980 15484 2.597\n",
            "\n",
            "02:45:23 | running eval: valid\n",
            "02:45:25 | eval completed in 1.60s\n",
            "02:45:25 | \u001b[1mvalid:\n",
            "    ctpb  ctps  exps  exs  gpu_mem  loss        lr  ltpb  ltps   ppl  token_acc  total_train_updates  tpb   tps\n",
            "    1659 46458 233.8  359    .0889 2.194 1.001e-06 80.86  2264 8.968      .5416                   10 1740 48723\n",
            "\u001b[0m\n",
            "02:45:25 | \u001b[1;32mnew best ppl: 8.968 (previous best was 8.969)\u001b[0m\n",
            "02:45:25 | saving best valid model: from_pretrained/model\n",
            "02:45:51 | time:89s total_exs:2768 epochs:7.71\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss        lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       1  3395  9009 509.1  192             16384  19.48    .3955 1.692 1.101e-06  1848  4903 5.433      .6537   \n",
            "    total_train_updates  tpb   tps   ups  \n",
            "                     11 5243 13913 2.661\n",
            "\n",
            "02:45:51 | running eval: valid\n",
            "02:45:52 | eval completed in 1.56s\n",
            "02:45:52 | \u001b[1mvalid:\n",
            "    ctpb  ctps  exps  exs  gpu_mem  loss        lr  ltpb  ltps   ppl  token_acc  total_train_updates  tpb   tps\n",
            "    1698 47466 238.8  359   .08891 2.193 1.101e-06 82.79  2313 8.966      .5421                   11 1781 49780\n",
            "\u001b[0m\n",
            "02:45:52 | \u001b[1;32mnew best ppl: 8.966 (previous best was 8.968)\u001b[0m\n",
            "02:45:52 | saving best valid model: from_pretrained/model\n",
            "02:46:19 | Overflow: setting loss scale to 8192.0\n",
            "02:46:19 | time:118s total_exs:2928 epochs:8.16\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss        lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       0  2455  7629 496.8  160              8192     -1    .3457 2.469 1.201e-06  1359  4222 11.81      .5784   \n",
            "    total_train_updates  tpb   tps   ups  \n",
            "                     12 3814 11853 3.121\n",
            "\n",
            "02:46:19 | running eval: valid\n",
            "02:46:21 | eval completed in 1.60s\n",
            "02:46:21 | \u001b[1mvalid:\n",
            "    ctpb  ctps  exps  exs  gpu_mem  loss        lr  ltpb  ltps   ppl  token_acc  total_train_updates  tpb   tps\n",
            "    1621 46359 233.3  359    .0889 2.193 1.201e-06 79.02  2259 8.966      .5418                   12 1700 48619\n",
            "\u001b[0m\n",
            "02:46:21 | \u001b[1mdid not beat best ppl: 8.9658 impatience: 1\u001b[0m\n",
            "02:46:22 | time:120s total_exs:3168 epochs:8.82\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss        lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       1  5308 22203 501.7  240              8192  28.93    .2830 1.405 1.401e-06  1208  5052 4.074      .6155   \n",
            "    total_train_updates  tpb   tps   ups  \n",
            "                     14 6516 27256 4.192\n",
            "\n",
            "02:46:22 | running eval: valid\n",
            "02:46:23 | eval completed in 1.58s\n",
            "02:46:23 | \u001b[1mvalid:\n",
            "    ctpb  ctps  exps  exs  gpu_mem  loss        lr  ltpb  ltps   ppl  token_acc  total_train_updates  tpb   tps\n",
            "    1659 47010 236.5  359   .08891 2.193 1.401e-06 80.86  2291 8.963      .5416                   14 1740 49301\n",
            "\u001b[0m\n",
            "02:46:23 | \u001b[1;32mnew best ppl: 8.963 (previous best was 8.966)\u001b[0m\n",
            "02:46:23 | saving best valid model: from_pretrained/model\n",
            "02:46:47 | time:145s total_exs:3264 epochs:9.09\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss        lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       1  5732 17161 287.2   96              8192  37.88    .2621 3.044 1.501e-06  1130  3382 20.98      .4655   \n",
            "    total_train_updates  tpb   tps   ups  \n",
            "                     15 6862 20545 3.002\n",
            "\n",
            "02:46:47 | running eval: valid\n",
            "02:46:48 | eval completed in 1.64s\n",
            "02:46:48 | \u001b[1mvalid:\n",
            "    ctpb  ctps  exps  exs  gpu_mem  loss        lr  ltpb  ltps   ppl  token_acc  total_train_updates  tpb   tps\n",
            "    1585 45029 226.6  359   .08891 2.193 1.501e-06 77.27  2195 8.961      .5418                   15 1663 47224\n",
            "\u001b[0m\n",
            "02:46:48 | \u001b[1;32mnew best ppl: 8.961 (previous best was 8.963)\u001b[0m\n",
            "02:46:48 | saving best valid model: from_pretrained/model\n",
            "02:47:14 | time:173s total_exs:3456 epochs:9.63\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss        lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       1   411  1069 499.1  192              8192  20.94    .4626 1.394 1.601e-06  2887  7508 4.032      .6564   \n",
            "    total_train_updates  tpb  tps   ups  \n",
            "                     16 3298 8578 2.608\n",
            "\n",
            "02:47:14 | running eval: valid\n",
            "02:47:16 | eval completed in 1.60s\n",
            "02:47:16 | \u001b[1mvalid:\n",
            "    ctpb  ctps  exps  exs  gpu_mem  loss        lr  ltpb  ltps   ppl  token_acc  total_train_updates  tpb   tps\n",
            "    1698 46304   233  359   .08891 2.193 1.601e-06 82.79  2257 8.958      .5418                   16 1781 48561\n",
            "\u001b[0m\n",
            "02:47:16 | \u001b[1;32mnew best ppl: 8.958 (previous best was 8.961)\u001b[0m\n",
            "02:47:16 | saving best valid model: from_pretrained/model\n",
            "02:47:40 | time:198s total_exs:3612 epochs:10.06\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss        lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       1  5838 15282 204.1  156              8192  32.45    .2936  2.21 1.801e-06 904.5  2368 9.115      .6230   \n",
            "    total_train_updates  tpb   tps   ups  \n",
            "                     18 6742 17650 2.621\n",
            "\n",
            "02:47:40 | running eval: valid\n",
            "02:47:41 | eval completed in 1.61s\n",
            "02:47:41 | \u001b[1mvalid:\n",
            "    ctpb  ctps  exps  exs  gpu_mem  loss        lr  ltpb  ltps   ppl  token_acc  total_train_updates  tpb   tps\n",
            "    1585 45711   230  359   .08889 2.192 1.801e-06 77.27  2228 8.953      .5418                   18 1663 47939\n",
            "\u001b[0m\n",
            "02:47:41 | \u001b[1;32mnew best ppl: 8.953 (previous best was 8.958)\u001b[0m\n",
            "02:47:41 | saving best valid model: from_pretrained/model\n",
            "02:48:09 | time:228s total_exs:3732 epochs:10.40\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss        lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       1  4521 12658 335.7  120              8192  18.64    .3264 1.864 1.901e-06  1565  4381 6.448      .5866   \n",
            "    total_train_updates  tpb   tps   ups  \n",
            "                     19 6086 17040 2.808\n",
            "\n",
            "02:48:09 | running eval: valid\n",
            "02:48:11 | eval completed in 1.58s\n",
            "02:48:11 | \u001b[1mvalid:\n",
            "    ctpb  ctps  exps  exs  gpu_mem  loss        lr  ltpb  ltps  ppl  token_acc  total_train_updates  tpb   tps\n",
            "    1783 46918 236.1  359   .08891 2.192 1.901e-06 86.92  2287 8.95      .5418                   19 1870 49205\n",
            "\u001b[0m\n",
            "02:48:11 | \u001b[1;32mnew best ppl: 8.95 (previous best was 8.953)\u001b[0m\n",
            "02:48:11 | saving best valid model: from_pretrained/model\n",
            "02:48:38 | time:256s total_exs:3836 epochs:10.69\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss        lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       1  5229 16604 329.5  104              8192  52.78    .3094 3.786 2.001e-06  1162  3686 44.06      .4036   \n",
            "    total_train_updates  tpb   tps   ups  \n",
            "                     20 6391 20294 3.184\n",
            "\n",
            "02:48:38 | running eval: valid\n",
            "02:48:39 | eval completed in 1.61s\n",
            "02:48:39 | \u001b[1mvalid:\n",
            "    ctpb  ctps  exps  exs  gpu_mem  loss        lr  ltpb  ltps   ppl  token_acc  total_train_updates  tpb   tps\n",
            "    1621 45794 230.4  359    .0889 2.191 2.001e-06 79.02  2232 8.946      .5424                   20 1700 48026\n",
            "\u001b[0m\n",
            "02:48:39 | \u001b[1;32mnew best ppl: 8.946 (previous best was 8.95)\u001b[0m\n",
            "02:48:39 | saving best valid model: from_pretrained/model\n",
            "02:49:03 | time:281s total_exs:4004 epochs:11.15\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss        lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       1  5644 20951 311.6  168              8192  47.08    .2798 1.507 2.201e-06   979  3633 4.511      .5735   \n",
            "    total_train_updates  tpb   tps   ups  \n",
            "                     22 6624 24585 3.718\n",
            "\n",
            "02:49:03 | running eval: valid\n",
            "02:49:04 | eval completed in 1.63s\n",
            "02:49:04 | \u001b[1mvalid:\n",
            "    ctpb  ctps  exps  exs  gpu_mem  loss        lr  ltpb  ltps  ppl  token_acc  total_train_updates  tpb   tps\n",
            "    1659 45697 229.9  359   .08891 2.191 2.201e-06 80.86  2227 8.94      .5421                   22 1740 47925\n",
            "\u001b[0m\n",
            "02:49:04 | \u001b[1;32mnew best ppl: 8.94 (previous best was 8.946)\u001b[0m\n",
            "02:49:04 | saving best valid model: from_pretrained/model\n",
            "02:49:29 | time:308s total_exs:4124 epochs:11.49\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss        lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       1  2783  7832 337.5  120              8192  18.84    .3264 2.249 2.301e-06   979  2755 9.475      .5832   \n",
            "    total_train_updates  tpb   tps   ups  \n",
            "                     23 3762 10587 2.823\n",
            "\n",
            "02:49:29 | running eval: valid\n",
            "02:49:31 | eval completed in 1.68s\n",
            "02:49:31 | \u001b[1mvalid:\n",
            "    ctpb  ctps  exps  exs  gpu_mem  loss        lr  ltpb  ltps   ppl  token_acc  total_train_updates  tpb   tps\n",
            "    1585 43963 221.2  359   .08891  2.19 2.301e-06 77.27  2143 8.936      .5430                   23 1663 46107\n",
            "\u001b[0m\n",
            "02:49:31 | \u001b[1;32mnew best ppl: 8.936 (previous best was 8.94)\u001b[0m\n",
            "02:49:31 | saving best valid model: from_pretrained/model\n",
            "02:50:00 | time:338s total_exs:4320 epochs:12.03\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss        lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       1   451  1547 669.1  196              8192  37.34    .2738 3.412 2.401e-06   831  2849 30.32      .3706   \n",
            "    total_train_updates  tpb  tps   ups  \n",
            "                     24 1282 4397 3.443\n",
            "\n",
            "02:50:00 | running eval: valid\n",
            "02:50:02 | eval completed in 1.60s\n",
            "02:50:02 | \u001b[1mvalid:\n",
            "    ctpb  ctps  exps  exs  gpu_mem  loss        lr  ltpb  ltps  ppl  token_acc  total_train_updates  tpb   tps\n",
            "    1621 46152 232.2  359    .0889 2.189 2.401e-06 79.02  2249 8.93      .5424                   24 1700 48401\n",
            "\u001b[0m\n",
            "02:50:02 | \u001b[1;32mnew best ppl: 8.93 (previous best was 8.936)\u001b[0m\n",
            "02:50:02 | saving best valid model: from_pretrained/model\n",
            "02:50:26 | time:365s total_exs:4504 epochs:12.55\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss        lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       1  5200 18248 322.7  184              8192  19.32    .2953 1.366 2.601e-06  1742  6111 3.921      .6322   \n",
            "    total_train_updates  tpb   tps   ups  \n",
            "                     26 6942 24360 3.515\n",
            "\n",
            "02:50:26 | running eval: valid\n",
            "02:50:28 | eval completed in 1.61s\n",
            "02:50:28 | \u001b[1mvalid:\n",
            "    ctpb  ctps  exps  exs  gpu_mem  loss        lr  ltpb  ltps   ppl  token_acc  total_train_updates  tpb   tps\n",
            "    1698 46099   232  359    .0889 2.188 2.601e-06 82.79  2247 8.918      .5433                   26 1781 48346\n",
            "\u001b[0m\n",
            "02:50:28 | \u001b[1;32mnew best ppl: 8.918 (previous best was 8.93)\u001b[0m\n",
            "02:50:28 | saving best valid model: from_pretrained/model\n",
            "02:50:55 | time:393s total_exs:4764 epochs:13.27\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss        lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       1  3900 11729 390.8  260              8192  23.24    .4626  1.85 2.801e-06  1292  3887 6.359      .6344   \n",
            "    total_train_updates  tpb   tps   ups  \n",
            "                     28 5192 15616 3.011\n",
            "\n",
            "02:50:55 | running eval: valid\n",
            "02:50:56 | eval completed in 1.57s\n",
            "02:50:56 | \u001b[1mvalid:\n",
            "    ctpb  ctps  exps  exs  gpu_mem  loss        lr  ltpb  ltps   ppl  token_acc  total_train_updates  tpb   tps\n",
            "    1698 47231 237.7  359   .08891 2.187 2.801e-06 82.79  2302 8.904      .5433                   28 1781 49534\n",
            "\u001b[0m\n",
            "02:50:56 | \u001b[1;32mnew best ppl: 8.904 (previous best was 8.918)\u001b[0m\n",
            "02:50:56 | saving best valid model: from_pretrained/model\n",
            "02:51:22 | time:421s total_exs:4892 epochs:13.63\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss        lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       1  6306 21797 221.2  128              8192  47.91    .2599 2.354 3.001e-06 562.5  1944 10.52      .4916   \n",
            "    total_train_updates  tpb   tps   ups  \n",
            "                     30 6868 23742 3.465\n",
            "\n",
            "02:51:22 | running eval: valid\n",
            "02:51:24 | eval completed in 1.59s\n",
            "02:51:24 | \u001b[1mvalid:\n",
            "    ctpb  ctps  exps  exs  gpu_mem  loss        lr  ltpb  ltps   ppl  token_acc  total_train_updates  tpb   tps\n",
            "    1698 46473 233.8  359   .08888 2.185 3.001e-06 82.79  2265 8.888      .5430                   30 1781 48738\n",
            "\u001b[0m\n",
            "02:51:24 | \u001b[1;32mnew best ppl: 8.888 (previous best was 8.904)\u001b[0m\n",
            "02:51:24 | saving best valid model: from_pretrained/model\n",
            "02:51:51 | time:449s total_exs:5052 epochs:14.07\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss        lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       1  3479  9809 450.8  160              8192  22.97    .3634 2.112 3.101e-06  1158  3264 8.269      .5691   \n",
            "    total_train_updates  tpb   tps   ups  \n",
            "                     31 4637 13074 2.829\n",
            "\n",
            "02:51:51 | running eval: valid\n",
            "02:51:52 | eval completed in 1.60s\n",
            "02:51:52 | \u001b[1mvalid:\n",
            "    ctpb  ctps  exps  exs  gpu_mem  loss        lr  ltpb  ltps   ppl  token_acc  total_train_updates  tpb   tps\n",
            "    1621 46414 233.5  359    .0889 2.184 3.101e-06 79.02  2262 8.879      .5433                   31 1700 48676\n",
            "\u001b[0m\n",
            "02:51:52 | \u001b[1;32mnew best ppl: 8.879 (previous best was 8.888)\u001b[0m\n",
            "02:51:52 | saving best valid model: from_pretrained/model\n",
            "02:52:19 | time:477s total_exs:5200 epochs:14.48\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss        lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       1  6204 19280 229.9  148              8192  34.31    .3232 1.888 3.301e-06   631  1961 6.603      .6030   \n",
            "    total_train_updates  tpb   tps   ups  \n",
            "                     33 6835 21240 3.114\n",
            "\n",
            "02:52:19 | running eval: valid\n",
            "02:52:20 | eval completed in 1.57s\n",
            "02:52:20 | \u001b[1mvalid:\n",
            "    ctpb  ctps  exps  exs  gpu_mem  loss        lr  ltpb  ltps   ppl  token_acc  total_train_updates  tpb   tps\n",
            "    1659 47209 237.5  359   .08891 2.181 3.301e-06 80.86  2301 8.859      .5436                   33 1740 49511\n",
            "\u001b[0m\n",
            "02:52:20 | \u001b[1;32mnew best ppl: 8.859 (previous best was 8.879)\u001b[0m\n",
            "02:52:20 | saving best valid model: from_pretrained/model\n",
            "02:52:46 | time:505s total_exs:5416 epochs:15.09\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss        lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       1  5639 17333 331.8  216              8192  32.71    .3839 2.024 3.501e-06 977.5  3004 7.565      .5355   \n",
            "    total_train_updates  tpb   tps   ups  \n",
            "                     35 6616 20338 3.079\n",
            "\n",
            "02:52:46 | running eval: valid\n",
            "02:52:48 | eval completed in 1.60s\n",
            "02:52:48 | \u001b[1mvalid:\n",
            "    ctpb  ctps  exps  exs  gpu_mem  loss        lr  ltpb  ltps   ppl  token_acc  total_train_updates  tpb   tps\n",
            "    1621 46215 232.5  359   .08889 2.179 3.501e-06 79.02  2252 8.839      .5433                   35 1700 48467\n",
            "\u001b[0m\n",
            "02:52:48 | \u001b[1;32mnew best ppl: 8.839 (previous best was 8.859)\u001b[0m\n",
            "02:52:48 | saving best valid model: from_pretrained/model\n",
            "02:53:13 | time:532s total_exs:5536 epochs:15.42\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss        lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       1  6288 20061 191.3  120              8192  30.09    .3353 1.535 3.701e-06 602.5  1922 4.641      .6481   \n",
            "    total_train_updates  tpb   tps   ups  \n",
            "                     37 6890 21984 3.195\n",
            "\n",
            "02:53:13 | running eval: valid\n",
            "02:53:15 | eval completed in 1.60s\n",
            "02:53:15 | \u001b[1mvalid:\n",
            "    ctpb  ctps  exps  exs  gpu_mem  loss        lr  ltpb  ltps   ppl  token_acc  total_train_updates  tpb   tps\n",
            "    1740 46517 234.1  359    .0889 2.176 3.701e-06  84.8  2267 8.815      .5450                   37 1825 48784\n",
            "\u001b[0m\n",
            "02:53:15 | \u001b[1;32mnew best ppl: 8.815 (previous best was 8.839)\u001b[0m\n",
            "02:53:15 | saving best valid model: from_pretrained/model\n",
            "02:53:39 | time:558s total_exs:5732 epochs:15.97\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss        lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       1  4994 15741 308.8  196              8192  24.52    .3402 2.464 3.901e-06   763  2405 11.75      .5170   \n",
            "    total_train_updates  tpb   tps   ups  \n",
            "                     39 5756 18146 3.156\n",
            "\n",
            "02:53:39 | running eval: valid\n",
            "02:53:41 | eval completed in 1.60s\n",
            "02:53:41 | \u001b[1mvalid:\n",
            "    ctpb  ctps  exps  exs  gpu_mem  loss        lr  ltpb  ltps   ppl  token_acc  total_train_updates  tpb   tps\n",
            "    1698 46229 232.6  359    .0889 2.173 3.901e-06 82.79  2253 8.788      .5450                   39 1781 48482\n",
            "\u001b[0m\n",
            "02:53:41 | \u001b[1;32mnew best ppl: 8.788 (previous best was 8.815)\u001b[0m\n",
            "02:53:41 | saving best valid model: from_pretrained/model\n",
            "02:54:09 | time:588s total_exs:5836 epochs:16.26\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss        lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       1  4830 17038 366.5  104              8192   19.8    .2953 1.326 4.001e-06  1904  6714 3.767      .6786   \n",
            "    total_train_updates  tpb   tps   ups  \n",
            "                     40 6734 23754 3.538\n",
            "\n",
            "02:54:09 | running eval: valid\n",
            "02:54:11 | eval completed in 1.59s\n",
            "02:54:11 | \u001b[1mvalid:\n",
            "    ctpb  ctps  exps  exs  gpu_mem  loss        lr  ltpb  ltps   ppl  token_acc  total_train_updates  tpb   tps\n",
            "    1698 46509   234  359   .08891 2.172 4.001e-06 82.79  2267 8.774      .5456                   40 1781 48776\n",
            "\u001b[0m\n",
            "02:54:11 | \u001b[1;32mnew best ppl: 8.774 (previous best was 8.788)\u001b[0m\n",
            "02:54:11 | saving best valid model: from_pretrained/model\n",
            "02:54:34 | time:613s total_exs:5936 epochs:16.53\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss        lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       1  6586 23831 180.8  100              8192  42.75    .2748 .9673 4.201e-06   692  2504 2.631      .7803   \n",
            "    total_train_updates  tpb   tps   ups  \n",
            "                     42 7278 26336 3.624\n",
            "\n",
            "02:54:34 | running eval: valid\n",
            "02:54:36 | eval completed in 1.57s\n",
            "02:54:36 | \u001b[1mvalid:\n",
            "    ctpb  ctps  exps  exs  gpu_mem  loss        lr  ltpb  ltps   ppl  token_acc  total_train_updates  tpb   tps\n",
            "    1740 47253 237.8  359    .0889 2.169 4.201e-06  84.8  2303 8.747      .5479                   42 1825 49557\n",
            "\u001b[0m\n",
            "02:54:36 | \u001b[1;32mnew best ppl: 8.747 (previous best was 8.774)\u001b[0m\n",
            "02:54:36 | saving best valid model: from_pretrained/model\n",
            "02:55:04 | time:643s total_exs:6036 epochs:16.81\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss        lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       1  6056 19780 163.2  100              8192  27.66    .2888 1.346 4.401e-06 854.5  2791 3.841      .7262   \n",
            "    total_train_updates  tpb   tps   ups  \n",
            "                     44 6910 22571 3.271\n",
            "\n",
            "02:55:04 | running eval: valid\n",
            "02:55:06 | eval completed in 1.76s\n",
            "02:55:06 | \u001b[1mvalid:\n",
            "    ctpb  ctps  exps  exs  gpu_mem  loss        lr  ltpb  ltps   ppl  token_acc  total_train_updates  tpb   tps\n",
            "    1659 42223 212.4  359   .08889 2.166 4.401e-06 80.86  2058 8.723      .5482                   44 1740 44281\n",
            "\u001b[0m\n",
            "02:55:06 | \u001b[1;32mnew best ppl: 8.723 (previous best was 8.747)\u001b[0m\n",
            "02:55:06 | saving best valid model: from_pretrained/model\n",
            "02:55:32 | time:670s total_exs:6132 epochs:17.08\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss        lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       1  6058 20900 165.5   96              8192  41.43    .3008 1.381 4.601e-06   744  2567 3.979      .7305   \n",
            "    total_train_updates  tpb   tps   ups  \n",
            "                     46 6802 23468 3.456\n",
            "\n",
            "02:55:32 | running eval: valid\n",
            "02:55:33 | eval completed in 1.62s\n",
            "02:55:33 | \u001b[1mvalid:\n",
            "    ctpb  ctps  exps  exs  gpu_mem  loss        lr  ltpb  ltps   ppl  token_acc  total_train_updates  tpb   tps\n",
            "    1698 45760 230.2  359    .0889 2.163 4.601e-06 82.79  2230 8.697      .5490                   46 1781 47990\n",
            "\u001b[0m\n",
            "02:55:33 | \u001b[1;32mnew best ppl: 8.697 (previous best was 8.723)\u001b[0m\n",
            "02:55:33 | saving best valid model: from_pretrained/model\n",
            "02:56:03 | time:701s total_exs:6252 epochs:17.42\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss        lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       1  6758 24904 147.4  120              8192  44.22    .2567 1.692 4.901e-06 217.3 800.8 5.431      .6319   \n",
            "    total_train_updates  tpb   tps   ups  \n",
            "                     49 6975 25705 3.688\n",
            "\n",
            "02:56:03 | running eval: valid\n",
            "02:56:04 | eval completed in 1.60s\n",
            "02:56:04 | \u001b[1mvalid:\n",
            "    ctpb  ctps  exps  exs  gpu_mem  loss        lr  ltpb  ltps   ppl  token_acc  total_train_updates  tpb   tps\n",
            "    1621 46200 232.5  359    .0889 2.159 4.901e-06 79.02  2252 8.667      .5496                   49 1700 48452\n",
            "\u001b[0m\n",
            "02:56:04 | \u001b[1;32mnew best ppl: 8.667 (previous best was 8.697)\u001b[0m\n",
            "02:56:04 | saving best valid model: from_pretrained/model\n",
            "02:56:28 | time:726s total_exs:6436 epochs:17.93\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss      lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       1  4489 14063   288  184              8192  32.59    .4030 2.831 5.1e-06 808.5  2533 16.97      .4001   \n",
            "    total_train_updates  tpb   tps   ups  \n",
            "                     51 5298 16596 3.138\n",
            "\n",
            "02:56:28 | running eval: valid\n",
            "02:56:30 | eval completed in 1.58s\n",
            "02:56:30 | \u001b[1mvalid:\n",
            "    ctpb  ctps  exps  exs  gpu_mem  loss      lr  ltpb  ltps   ppl  token_acc  total_train_updates  tpb   tps\n",
            "    1659 46847 235.7  359   .08891 2.157 5.1e-06 80.86  2283 8.647      .5485                   51 1740 49131\n",
            "\u001b[0m\n",
            "02:56:30 | \u001b[1;32mnew best ppl: 8.647 (previous best was 8.667)\u001b[0m\n",
            "02:56:30 | saving best valid model: from_pretrained/model\n",
            "02:56:59 | time:757s total_exs:6712 epochs:18.70\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss      lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       1  2992  8720 402.1  276              8192  25.46    .4840 2.298 5.3e-06 905.5  2639 9.957      .5014   \n",
            "    total_train_updates  tpb   tps   ups  \n",
            "                     53 3897 11360 2.919\n",
            "\n",
            "02:56:59 | running eval: valid\n",
            "02:57:01 | eval completed in 1.59s\n",
            "02:57:01 | \u001b[1mvalid:\n",
            "    ctpb  ctps  exps  exs  gpu_mem  loss      lr  ltpb  ltps   ppl  token_acc  total_train_updates  tpb   tps\n",
            "    1659 46549 234.2  359   .08891 2.154 5.3e-06 80.86  2269 8.619      .5482                   53 1740 48818\n",
            "\u001b[0m\n",
            "02:57:01 | \u001b[1;32mnew best ppl: 8.619 (previous best was 8.647)\u001b[0m\n",
            "02:57:01 | saving best valid model: from_pretrained/model\n",
            "02:57:27 | time:785s total_exs:6904 epochs:19.23\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss      lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       1  1990  4676 450.9  192              8192  14.03    .4840 2.385 5.4e-06  1382  3247 10.85      .5876   \n",
            "    total_train_updates  tpb  tps   ups  \n",
            "                     54 3372 7924 2.356\n",
            "\n",
            "02:57:27 | running eval: valid\n",
            "02:57:28 | eval completed in 1.57s\n",
            "02:57:28 | \u001b[1mvalid:\n",
            "    ctpb  ctps  exps  exs  gpu_mem  loss      lr  ltpb  ltps  ppl  token_acc  total_train_updates  tpb   tps\n",
            "    1698 47128 237.1  359   .08889 2.152 5.4e-06 82.79  2297  8.6      .5487                   54 1781 49425\n",
            "\u001b[0m\n",
            "02:57:28 | \u001b[1;32mnew best ppl: 8.6 (previous best was 8.619)\u001b[0m\n",
            "02:57:28 | saving best valid model: from_pretrained/model\n",
            "02:57:50 | time:809s total_exs:7064 epochs:19.68\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss      lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       1  2764  7707 445.8  160              8192  16.09    .3839 2.166 5.5e-06  1328  3702 8.723      .5821   \n",
            "    total_train_updates  tpb   tps   ups  \n",
            "                     55 4092 11410 2.798\n",
            "\n",
            "02:57:50 | running eval: valid\n",
            "02:57:52 | eval completed in 1.56s\n",
            "02:57:52 | \u001b[1mvalid:\n",
            "    ctpb  ctps  exps  exs  gpu_mem  loss      lr  ltpb  ltps   ppl  token_acc  total_train_updates  tpb   tps\n",
            "    1698 47447 238.7  359   .08891 2.149 5.5e-06 82.79  2312 8.579      .5502                   55 1781 49760\n",
            "\u001b[0m\n",
            "02:57:52 | \u001b[1;32mnew best ppl: 8.579 (previous best was 8.6)\u001b[0m\n",
            "02:57:52 | saving best valid model: from_pretrained/model\n",
            "02:58:19 | time:837s total_exs:7168 epochs:19.97\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss      lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       1  4925 14838   313  104              8192  24.06    .3094 2.011 5.6e-06  1239  3732 7.469      .5819   \n",
            "    total_train_updates  tpb   tps  ups  \n",
            "                     56 6164 18571 3.02\n",
            "\n",
            "02:58:19 | running eval: valid\n",
            "02:58:20 | eval completed in 1.61s\n",
            "02:58:20 | \u001b[1mvalid:\n",
            "    ctpb  ctps  exps  exs  gpu_mem  loss      lr  ltpb  ltps   ppl  token_acc  total_train_updates  tpb   tps\n",
            "    1621 45955 231.2  359   .08891 2.146 5.6e-06 79.02  2240 8.554      .5502                   56 1700 48195\n",
            "\u001b[0m\n",
            "02:58:20 | \u001b[1;32mnew best ppl: 8.554 (previous best was 8.579)\u001b[0m\n",
            "02:58:20 | saving best valid model: from_pretrained/model\n",
            "02:58:49 | time:867s total_exs:7292 epochs:20.31\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss      lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       1  6229 22009   219  124              8192  31.15    .2830 1.393 5.8e-06 857.5  3029 4.028      .6012   \n",
            "    total_train_updates  tpb   tps   ups  \n",
            "                     58 7086 25039 3.539\n",
            "\n",
            "02:58:49 | running eval: valid\n",
            "02:58:50 | eval completed in 1.79s\n",
            "02:58:50 | \u001b[1mvalid:\n",
            "    ctpb  ctps  exps  exs  gpu_mem  loss      lr  ltpb  ltps   ppl  token_acc  total_train_updates  tpb   tps\n",
            "    1659 46865 235.8  359   .08889 2.141 5.8e-06 80.86  2284 8.506      .5508                   58 1740 49149\n",
            "\u001b[0m\n",
            "02:58:50 | \u001b[1;32mnew best ppl: 8.506 (previous best was 8.554)\u001b[0m\n",
            "02:58:50 | saving best valid model: from_pretrained/model\n",
            "02:59:17 | time:896s total_exs:7484 epochs:20.85\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss    lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       1  5465 18198 319.4  192              8192   23.8    .3264 2.129 6e-06   990  3296 8.405      .5283   \n",
            "    total_train_updates  tpb   tps   ups  \n",
            "                     60 6455 21494 3.335\n",
            "\n",
            "02:59:17 | running eval: valid\n",
            "02:59:19 | eval completed in 1.58s\n",
            "02:59:19 | \u001b[1mvalid:\n",
            "    ctpb  ctps  exps  exs  gpu_mem  loss    lr  ltpb  ltps   ppl  token_acc  total_train_updates  tpb   tps\n",
            "    1698 46776 235.4  359    .0889 2.135 6e-06 82.79  2280 8.457      .5513                   60 1781 49057\n",
            "\u001b[0m\n",
            "02:59:19 | \u001b[1;32mnew best ppl: 8.457 (previous best was 8.506)\u001b[0m\n",
            "02:59:19 | saving best valid model: from_pretrained/model\n",
            "02:59:47 | time:925s total_exs:7660 epochs:21.34\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss      lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       1  6164 22309 212.2  176              8192  47.95    .2923 2.045 6.3e-06 640.7  2319 7.727      .6191   \n",
            "    total_train_updates  tpb   tps   ups  \n",
            "                     63 6804 24628 3.623\n",
            "\n",
            "02:59:47 | running eval: valid\n",
            "02:59:48 | eval completed in 1.61s\n",
            "02:59:48 | \u001b[1mvalid:\n",
            "    ctpb  ctps  exps  exs  gpu_mem  loss      lr  ltpb  ltps   ppl  token_acc  total_train_updates  tpb   tps\n",
            "    1659 46079 231.9  359   .08891 2.126 6.3e-06 80.86  2246 8.385      .5534                   63 1740 48326\n",
            "\u001b[0m\n",
            "02:59:49 | \u001b[1;32mnew best ppl: 8.385 (previous best was 8.457)\u001b[0m\n",
            "02:59:49 | saving best valid model: from_pretrained/model\n",
            "03:00:10 | time:949s total_exs:7908 epochs:22.03\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss      lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       1  4552 15530 281.9  248              8192  28.21    .4183   1.9 6.6e-06 589.7  2012 6.685      .6116   \n",
            "    total_train_updates  tpb   tps   ups  \n",
            "                     66 5141 17542 3.416\n",
            "\n",
            "03:00:10 | running eval: valid\n",
            "03:00:12 | eval completed in 1.61s\n",
            "03:00:12 | \u001b[1mvalid:\n",
            "    ctpb  ctps  exps  exs  gpu_mem  loss      lr  ltpb  ltps   ppl  token_acc  total_train_updates  tpb   tps\n",
            "    1698 46057 231.8  359    .0889 2.119 6.6e-06 82.79  2245 8.319      .5548                   66 1781 48302\n",
            "\u001b[0m\n",
            "03:00:12 | \u001b[1;32mnew best ppl: 8.319 (previous best was 8.385)\u001b[0m\n",
            "03:00:12 | saving best valid model: from_pretrained/model\n",
            "03:00:40 | time:978s total_exs:8116 epochs:22.61\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss      lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       1  3852 12197 329.1  208              8192  34.91    .4373  2.68 6.8e-06   797  2524 14.59      .5715   \n",
            "    total_train_updates  tpb   tps   ups  \n",
            "                     68 4648 14721 3.172\n",
            "\n",
            "03:00:40 | running eval: valid\n",
            "03:00:41 | eval completed in 1.64s\n",
            "03:00:41 | \u001b[1mvalid:\n",
            "    ctpb  ctps  exps  exs  gpu_mem  loss      lr  ltpb  ltps   ppl  token_acc  total_train_updates  tpb   tps\n",
            "    1621 45286 227.9  359    .0889 2.112 6.8e-06 79.02  2207 8.264      .5551                   68 1700 47493\n",
            "\u001b[0m\n",
            "03:00:41 | \u001b[1;32mnew best ppl: 8.264 (previous best was 8.319)\u001b[0m\n",
            "03:00:41 | saving best valid model: from_pretrained/model\n",
            "03:01:07 | time:1006s total_exs:8252 epochs:22.99\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss    lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       1  5384 18558 234.3  136              8192  19.96    .2923 1.667 7e-06 631.5  2176 5.295      .7150   \n",
            "    total_train_updates  tpb   tps   ups  \n",
            "                     70 6016 20734 3.452\n",
            "\n",
            "03:01:07 | running eval: valid\n",
            "03:01:09 | eval completed in 1.55s\n",
            "03:01:09 | \u001b[1mvalid:\n",
            "    ctpb  ctps  exps  exs  gpu_mem  loss    lr  ltpb  ltps  ppl  token_acc  total_train_updates  tpb   tps\n",
            "    1783 47859 240.8  359    .0889 2.105 7e-06 86.92  2333 8.21      .5577                   70 1870 50191\n",
            "\u001b[0m\n",
            "03:01:09 | \u001b[1;32mnew best ppl: 8.21 (previous best was 8.264)\u001b[0m\n",
            "03:01:09 | saving best valid model: from_pretrained/model\n",
            "03:01:38 | time:1036s total_exs:8368 epochs:23.31\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss      lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       1  5964 20301 197.3  116              8192  37.91    .2830 2.444 7.2e-06 509.5  1734 11.52      .4907   \n",
            "    total_train_updates  tpb   tps   ups  \n",
            "                     72 6473 22036 3.409\n",
            "\n",
            "03:01:38 | running eval: valid\n",
            "03:01:39 | eval completed in 1.59s\n",
            "03:01:39 | \u001b[1mvalid:\n",
            "    ctpb  ctps  exps  exs  gpu_mem  loss      lr  ltpb  ltps   ppl  token_acc  total_train_updates  tpb   tps\n",
            "    1698 46597 234.5  359    .0889 2.099 7.2e-06 82.79  2271 8.158      .5588                   72 1781 48869\n",
            "\u001b[0m\n",
            "03:01:39 | \u001b[1;32mnew best ppl: 8.158 (previous best was 8.21)\u001b[0m\n",
            "03:01:39 | saving best valid model: from_pretrained/model\n",
            "03:02:05 | time:1064s total_exs:8496 epochs:23.67\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss      lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       1  5671 19933 224.8  128              8192  42.91    .2969 1.728 7.4e-06   903  3174 5.628      .5205   \n",
            "    total_train_updates  tpb   tps   ups  \n",
            "                     74 6574 23107 3.521\n",
            "\n",
            "03:02:05 | running eval: valid\n",
            "03:02:07 | eval completed in 1.62s\n",
            "03:02:07 | \u001b[1mvalid:\n",
            "    ctpb  ctps  exps  exs  gpu_mem  loss      lr  ltpb  ltps   ppl  token_acc  total_train_updates  tpb   tps\n",
            "    1659 45818 230.5  359    .0889 2.093 7.4e-06 80.86  2233 8.107      .5603                   74 1740 48051\n",
            "\u001b[0m\n",
            "03:02:07 | \u001b[1;32mnew best ppl: 8.107 (previous best was 8.158)\u001b[0m\n",
            "03:02:07 | saving best valid model: from_pretrained/model\n",
            "03:02:31 | time:1090s total_exs:8656 epochs:24.11\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss      lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       1  3629  8581 378.1  160              8192  11.95    .4584 1.746 7.5e-06  1340  3168 5.729      .6552   \n",
            "    total_train_updates  tpb   tps  ups  \n",
            "                     75 4969 11749 2.37\n",
            "\n",
            "03:02:31 | running eval: valid\n",
            "03:02:33 | eval completed in 1.75s\n",
            "03:02:33 | \u001b[1mvalid:\n",
            "    ctpb  ctps  exps  exs  gpu_mem  loss      lr  ltpb  ltps   ppl  token_acc  total_train_updates  tpb   tps\n",
            "    1740 46076 231.8  359   .08888 2.089 7.5e-06  84.8  2246 8.078      .5620                   75 1825 48322\n",
            "\u001b[0m\n",
            "03:02:33 | \u001b[1;32mnew best ppl: 8.078 (previous best was 8.107)\u001b[0m\n",
            "03:02:33 | saving best valid model: from_pretrained/model\n",
            "03:02:59 | time:1118s total_exs:8788 epochs:24.48\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss      lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       1  6260 21806 229.8  132              8192  38.67    .2969 2.543 7.7e-06   451  1571 12.72      .4534   \n",
            "    total_train_updates  tpb   tps   ups  \n",
            "                     77 6710 23377 3.489\n",
            "\n",
            "03:02:59 | running eval: valid\n",
            "03:03:01 | eval completed in 1.62s\n",
            "03:03:01 | \u001b[1mvalid:\n",
            "    ctpb  ctps  exps  exs  gpu_mem  loss      lr  ltpb  ltps   ppl  token_acc  total_train_updates  tpb   tps\n",
            "    1659 45534 229.1  359    .0889 2.082 7.7e-06 80.86  2219 8.024      .5654                   77 1740 47753\n",
            "\u001b[0m\n",
            "03:03:01 | \u001b[1;32mnew best ppl: 8.024 (previous best was 8.078)\u001b[0m\n",
            "03:03:01 | saving best valid model: from_pretrained/model\n",
            "03:03:29 | time:1148s total_exs:8956 epochs:24.95\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss      lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       1  5238 18095 290.1  168              8192  35.66    .3095 2.282 7.9e-06 795.5  2748 9.797      .5713   \n",
            "    total_train_updates  tpb   tps  ups  \n",
            "                     79 6034 20843 3.46\n",
            "\n",
            "03:03:29 | running eval: valid\n",
            "03:03:31 | eval completed in 1.57s\n",
            "03:03:31 | \u001b[1mvalid:\n",
            "    ctpb  ctps  exps  exs  gpu_mem  loss      lr  ltpb  ltps   ppl  token_acc  total_train_updates  tpb   tps\n",
            "    1698 47025 236.6  359    .0889 2.075 7.9e-06 82.79  2292 7.968      .5669                   79 1781 49318\n",
            "\u001b[0m\n",
            "03:03:31 | \u001b[1;32mnew best ppl: 7.968 (previous best was 8.024)\u001b[0m\n",
            "03:03:31 | saving best valid model: from_pretrained/model\n",
            "03:03:58 | time:1176s total_exs:9108 epochs:25.37\n",
            "    clip  ctpb  ctps  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  loss      lr  ltpb  ltps   ppl  token_acc  \\\n",
            "       1  4122 13628 251.2  152              8192   40.8    .3264 2.319 8.1e-06   389  1286 10.16      .5064   \n",
            "    total_train_updates  tpb   tps   ups  \n",
            "                     81 4510 14914 3.312\n",
            "\n",
            "03:03:58 | running eval: valid\n",
            "03:03:59 | eval completed in 1.63s\n",
            "03:03:59 | \u001b[1mvalid:\n",
            "    ctpb  ctps  exps  exs  gpu_mem  loss      lr  ltpb  ltps   ppl  token_acc  total_train_updates  tpb   tps\n",
            "    1621 45344 228.2  359   .08891 2.069 8.1e-06 79.02  2210 7.913      .5677                   81 1700 47554\n",
            "\u001b[0m\n",
            "03:03:59 | \u001b[1;32mnew best ppl: 7.913 (previous best was 7.968)\u001b[0m\n",
            "03:03:59 | saving best valid model: from_pretrained/model\n",
            "03:04:25 | max_train_time elapsed:1203.4096367359161s\n",
            "03:04:25 | \u001b[33mOverriding opt[\"init_model\"] to zoo:blender/blender_90M/model (previously: /content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/models/blender/blender_90M/model)\u001b[0m\n",
            "03:04:25 | \u001b[33mOverriding opt[\"optimizer\"] to adam (previously: mem_eff_adam)\u001b[0m\n",
            "03:04:25 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,loglevel: info,dynamic_batching: full,eval_dynamic_batching: None,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,mutators: None,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,beam_block_full_context: True,beam_delay: 30,beam_block_list_filename: None,temperature: 1.0,history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,dict_loaded: True,datapath: /content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning,download_path: None,verbose: False,load_from_checkpoint: True,interactive_mode: False\u001b[0m\n",
            "03:04:25 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n",
            "--show-advanced-args False --task internal:blended_skill_talk,wizard_of_wikipedia,convai2,empathetic_dialogues --numthreads 1 --multitask-weights 1.0,3.0,3.0,3.0 --batchsize 16 --max-train-time -1 --save-every-n-secs 60.0 --save-after-valid True --validation-max-exs 20000 --validation-patience 15 --validation-metric-mode min --log-every-n-secs 2 --label-type response --include-knowledge True --include-checked-sentence True --include-knowledge-separator False --num-topics 5 --train-experiencer-only False --dropout 0.1 --beam-size 10 --beam-min-length 20 --beam-context-block-ngram 3 --beam-block-ngram 3 --skip-generation False --inference beam --fp16-impl apex --force-fp16-tokens False --optimizer adamax --learningrate 7.5e-06 --warmup-updates -1 --parlai-home /private/home/edinan/ParlAI\u001b[0m\n",
            "03:04:25 | Using CUDA\n",
            "03:04:25 | loading dictionary from from_pretrained/model.dict\n",
            "03:04:25 | num words = 54944\n",
            "03:04:27 | Total parameters: 87,508,992 (87,508,992 trainable)\n",
            "03:04:27 | Loading existing model params from from_pretrained/model\n",
            "03:04:30 | creating task(s): custom_train\n",
            " ~~ Loading from blenderbot_processed_data_train.txt ~~ \n",
            "03:04:32 | running eval: valid\n",
            "03:04:33 | eval completed in 1.66s\n",
            "03:04:33 | \u001b[1mvalid:\n",
            "    ctpb  ctps  exps  exs  gpu_mem  loss      lr  ltpb  ltps   ppl  token_acc  total_train_updates  tpb   tps\n",
            "    1698 44525 223.9  359   .07771 2.069 8.1e-06 82.79  2170 7.913      .5677                   81 1781 46695\n",
            "\u001b[0m\n",
            "03:04:33 | creating task(s): custom_train\n",
            " ~~ Loading from blenderbot_processed_data_train.txt ~~ \n",
            "03:04:35 | running eval: test\n",
            "03:04:36 | eval completed in 1.56s\n",
            "03:04:36 | \u001b[1mtest:\n",
            "    ctpb  ctps  exps  exs  gpu_mem  loss      lr  ltpb  ltps   ppl  token_acc  total_train_updates  tpb   tps\n",
            "    1698 47495   239  359    .0777 2.069 8.1e-06 82.79  2315 7.913      .5677                   81 1781 49810\n",
            "\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'ctpb': GlobalAverageMetric(1698),\n",
              "  'ctps': GlobalTimerMetric(4.452e+04),\n",
              "  'exps': GlobalTimerMetric(223.9),\n",
              "  'exs': SumMetric(359),\n",
              "  'gpu_mem': GlobalAverageMetric(0.07771),\n",
              "  'loss': AverageMetric(2.069),\n",
              "  'lr': GlobalAverageMetric(8.1e-06),\n",
              "  'ltpb': GlobalAverageMetric(82.79),\n",
              "  'ltps': GlobalTimerMetric(2170),\n",
              "  'ppl': PPLMetric(7.913),\n",
              "  'token_acc': AverageMetric(0.5677),\n",
              "  'total_train_updates': GlobalFixedMetric(81),\n",
              "  'tpb': GlobalAverageMetric(1781),\n",
              "  'tps': GlobalTimerMetric(4.67e+04)},\n",
              " {'ctpb': GlobalAverageMetric(1698),\n",
              "  'ctps': GlobalTimerMetric(4.75e+04),\n",
              "  'exps': GlobalTimerMetric(239),\n",
              "  'exs': SumMetric(359),\n",
              "  'gpu_mem': GlobalAverageMetric(0.0777),\n",
              "  'loss': AverageMetric(2.069),\n",
              "  'lr': GlobalAverageMetric(8.1e-06),\n",
              "  'ltpb': GlobalAverageMetric(82.79),\n",
              "  'ltps': GlobalTimerMetric(2315),\n",
              "  'ppl': PPLMetric(7.913),\n",
              "  'token_acc': AverageMetric(0.5677),\n",
              "  'total_train_updates': GlobalFixedMetric(81),\n",
              "  'tpb': GlobalAverageMetric(1781),\n",
              "  'tps': GlobalTimerMetric(4.981e+04)})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgWaMLqK8AtM"
      },
      "source": [
        "Evaluate the model on our data to obtain the suggestions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BakCGOoQkxK5",
        "outputId": "f023ada1-a3b7-4392-d984-96250fbed798"
      },
      "source": [
        "DisplayModel.main(\n",
        "    task='custom_test',\n",
        "    model_file=path.join(DATA_PATH, 'from_pretrained', 'model'),\n",
        "    num_examples=50,\n",
        "    dp=DATA_PATH,\n",
        "    skip_generation=False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "04:30:12 | \u001b[33mOverriding opt[\"task\"] to custom_test (previously: custom_train)\u001b[0m\n",
            "04:30:12 | \u001b[33mOverriding opt[\"model_file\"] to /content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/from_pretrained/model (previously: from_pretrained/model)\u001b[0m\n",
            "04:30:12 | \u001b[33mOverriding opt[\"skip_generation\"] to False (previously: True)\u001b[0m\n",
            "04:30:13 | Using CUDA\n",
            "04:30:13 | loading dictionary from /content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/from_pretrained/model.dict\n",
            "04:30:13 | num words = 54944\n",
            "04:30:15 | \u001b[33mDEPRECATED: XLM should only be used for backwards compatibility, as it involves a less-stable layernorm operation.\u001b[0m\n",
            "04:30:26 | Total parameters: 87,508,992 (87,508,992 trainable)\n",
            "04:30:26 | Loading existing model params from /content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/from_pretrained/model\n",
            "04:30:35 | creating task(s): custom_test\n",
            " ~~ Loading from blenderbot_processed_data_test.txt ~~ \n",
            "04:30:35 | Opt:\n",
            "04:30:35 |     activation: gelu\n",
            "04:30:35 |     adafactor_eps: '[1e-30, 0.001]'\n",
            "04:30:35 |     adam_eps: 1e-08\n",
            "04:30:35 |     add_p1_after_newln: False\n",
            "04:30:35 |     aggregate_micro: False\n",
            "04:30:35 |     allow_missing_init_opts: False\n",
            "04:30:35 |     attention_dropout: 0.0\n",
            "04:30:35 |     batchsize: 12\n",
            "04:30:35 |     beam_block_full_context: True\n",
            "04:30:35 |     beam_block_list_filename: None\n",
            "04:30:35 |     beam_block_ngram: -1\n",
            "04:30:35 |     beam_context_block_ngram: -1\n",
            "04:30:35 |     beam_delay: 30\n",
            "04:30:35 |     beam_length_penalty: 0.65\n",
            "04:30:35 |     beam_min_length: 1\n",
            "04:30:35 |     beam_size: 1\n",
            "04:30:35 |     betas: '[0.9, 0.999]'\n",
            "04:30:35 |     bpe_add_prefix_space: None\n",
            "04:30:35 |     bpe_debug: False\n",
            "04:30:35 |     bpe_dropout: None\n",
            "04:30:35 |     bpe_merge: None\n",
            "04:30:35 |     bpe_vocab: None\n",
            "04:30:35 |     compute_tokenized_bleu: False\n",
            "04:30:35 |     datapath: \"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning\"\n",
            "04:30:35 |     datatype: train\n",
            "04:30:35 |     delimiter: '\\n'\n",
            "04:30:35 |     dict_class: parlai.core.dict:DictionaryAgent\n",
            "04:30:35 |     dict_endtoken: __end__\n",
            "04:30:35 |     dict_file: \"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/from_pretrained/model.dict\"\n",
            "04:30:35 |     dict_include_test: False\n",
            "04:30:35 |     dict_include_valid: False\n",
            "04:30:35 |     dict_initpath: None\n",
            "04:30:35 |     dict_language: english\n",
            "04:30:35 |     dict_loaded: True\n",
            "04:30:35 |     dict_lower: True\n",
            "04:30:35 |     dict_max_ngram_size: -1\n",
            "04:30:35 |     dict_maxexs: -1\n",
            "04:30:35 |     dict_maxtokens: -1\n",
            "04:30:35 |     dict_minfreq: 0\n",
            "04:30:35 |     dict_nulltoken: __null__\n",
            "04:30:35 |     dict_starttoken: __start__\n",
            "04:30:35 |     dict_textfields: text,labels\n",
            "04:30:35 |     dict_tokenizer: bpe\n",
            "04:30:35 |     dict_unktoken: __unk__\n",
            "04:30:35 |     display_add_fields: \n",
            "04:30:35 |     display_examples: False\n",
            "04:30:35 |     download_path: None\n",
            "04:30:35 |     dropout: 0.0\n",
            "04:30:35 |     dynamic_batching: full\n",
            "04:30:35 |     embedding_projection: random\n",
            "04:30:35 |     embedding_size: 512\n",
            "04:30:35 |     embedding_type: random\n",
            "04:30:35 |     embeddings_scale: True\n",
            "04:30:35 |     eval_batchsize: None\n",
            "04:30:35 |     eval_dynamic_batching: None\n",
            "04:30:35 |     evaltask: None\n",
            "04:30:35 |     ffn_size: 2048\n",
            "04:30:35 |     force_fp16_tokens: True\n",
            "04:30:35 |     fp16: True\n",
            "04:30:35 |     fp16_impl: mem_efficient\n",
            "04:30:35 |     gpu: -1\n",
            "04:30:35 |     gradient_clip: 0.1\n",
            "04:30:35 |     hide_labels: False\n",
            "04:30:35 |     history_add_global_end_token: None\n",
            "04:30:35 |     history_reversed: False\n",
            "04:30:35 |     history_size: -1\n",
            "04:30:35 |     image_cropsize: 224\n",
            "04:30:35 |     image_mode: raw\n",
            "04:30:35 |     image_size: 256\n",
            "04:30:35 |     inference: greedy\n",
            "04:30:35 |     init_model: \"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/models/blender/blender_90M/model\"\n",
            "04:30:35 |     init_opt: None\n",
            "04:30:35 |     interactive_mode: False\n",
            "04:30:35 |     invsqrt_lr_decay_gamma: -1\n",
            "04:30:35 |     label_truncate: 128\n",
            "04:30:35 |     learn_positional_embeddings: True\n",
            "04:30:35 |     learningrate: 1e-05\n",
            "04:30:35 |     log_every_n_secs: 10\n",
            "04:30:35 |     loglevel: info\n",
            "04:30:35 |     lr_scheduler: reduceonplateau\n",
            "04:30:35 |     lr_scheduler_decay: 0.5\n",
            "04:30:35 |     lr_scheduler_patience: 3\n",
            "04:30:35 |     max_lr_steps: -1\n",
            "04:30:35 |     max_train_time: 1200.0\n",
            "04:30:35 |     metrics: default\n",
            "04:30:35 |     model: transformer/generator\n",
            "04:30:35 |     model_file: \"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/from_pretrained/model\"\n",
            "04:30:35 |     model_parallel: False\n",
            "04:30:35 |     momentum: 0\n",
            "04:30:35 |     multitask_weights: [1]\n",
            "04:30:35 |     mutators: None\n",
            "04:30:35 |     n_decoder_layers: -1\n",
            "04:30:35 |     n_encoder_layers: -1\n",
            "04:30:35 |     n_heads: 16\n",
            "04:30:35 |     n_layers: 8\n",
            "04:30:35 |     n_positions: 512\n",
            "04:30:35 |     n_segments: 0\n",
            "04:30:35 |     nesterov: True\n",
            "04:30:35 |     no_cuda: False\n",
            "04:30:35 |     num_epochs: -1\n",
            "04:30:35 |     num_examples: 50\n",
            "04:30:35 |     nus: [0.7]\n",
            "04:30:35 |     optimizer: mem_eff_adam\n",
            "04:30:35 |     output_scaling: 1.0\n",
            "04:30:35 |     override: '{\\'task\\': \\'custom_test\\', \\'model_file\\': \"/content/drive/My Drive/Master\\'s Thesis/Blenderbot Transfer Learning/from_pretrained/model\", \\'num_examples\\': \\'50\\', \\'datapath\\': \"/content/drive/My Drive/Master\\'s Thesis/Blenderbot Transfer Learning\", \\'skip_generation\\': False}'\n",
            "04:30:35 |     parlai_home: /usr/local/lib/python3.7/dist-packages\n",
            "04:30:35 |     person_tokens: False\n",
            "04:30:35 |     rank_candidates: False\n",
            "04:30:35 |     relu_dropout: 0.0\n",
            "04:30:35 |     save_after_valid: False\n",
            "04:30:35 |     save_every_n_secs: -1\n",
            "04:30:35 |     share_word_embeddings: True\n",
            "04:30:35 |     short_final_eval: False\n",
            "04:30:35 |     skip_generation: False\n",
            "04:30:35 |     special_tok_lst: None\n",
            "04:30:35 |     split_lines: False\n",
            "04:30:35 |     starttime: Apr17_02-44\n",
            "04:30:35 |     task: custom_test\n",
            "04:30:35 |     temperature: 1.0\n",
            "04:30:35 |     tensorboard_log: False\n",
            "04:30:35 |     tensorboard_logdir: None\n",
            "04:30:35 |     text_truncate: 512\n",
            "04:30:35 |     topk: 10\n",
            "04:30:35 |     topp: 0.9\n",
            "04:30:35 |     truncate: -1\n",
            "04:30:35 |     update_freq: 1\n",
            "04:30:35 |     use_reply: label\n",
            "04:30:35 |     validation_cutoff: 1.0\n",
            "04:30:35 |     validation_every_n_epochs: 0.25\n",
            "04:30:35 |     validation_every_n_secs: -1\n",
            "04:30:35 |     validation_max_exs: -1\n",
            "04:30:35 |     validation_metric: ppl\n",
            "04:30:35 |     validation_metric_mode: None\n",
            "04:30:35 |     validation_patience: 10\n",
            "04:30:35 |     validation_share_agent: False\n",
            "04:30:35 |     variant: xlm\n",
            "04:30:35 |     verbose: False\n",
            "04:30:35 |     wandb_log: False\n",
            "04:30:35 |     wandb_name: None\n",
            "04:30:35 |     wandb_project: None\n",
            "04:30:35 |     warmup_rate: 0.0001\n",
            "04:30:35 |     warmup_updates: 100\n",
            "04:30:35 |     weight_decay: None\n",
            "\u001b[1;31m- - - NEW EPISODE: custom_test- - -\u001b[0;0m\n",
            "\u001b[0mHello\u001b[0;0m\n",
            "\u001b[1;94m    labels: hello, how are you today? i just got back from a long day at the office.\u001b[0;0m\n",
            "\u001b[0;95m     model: hello , how are you today ?\u001b[0;0m\n",
            "\u001b[0mhello, how are you today? i just got back from a long day at the office.\u001b[0;0m\n",
            "\u001b[1;94m    labels: I'm doing well, thanks for asking.\u001b[0;0m\n",
            "\u001b[0;95m     model: i ' m doing well . i ' m just getting ready to go to work .\u001b[0;0m\n",
            "\u001b[0mI'm doing well, thanks for asking.\u001b[0;0m\n",
            "\u001b[1;94m    labels: that's good to hear. i'm glad you're having a good day.\u001b[0;0m\n",
            "\u001b[0;95m     model: what do you do for a living ?\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: custom_test- - -\u001b[0;0m\n",
            "\u001b[0mHello\u001b[0;0m\n",
            "\u001b[1;94m    labels: hello, how are you today? i just got back from a long day at the office.\u001b[0;0m\n",
            "\u001b[0;95m     model: hello , how are you today ?\u001b[0;0m\n",
            "\u001b[0mhello, how are you today? i just got back from a long day at the office.\u001b[0;0m\n",
            "\u001b[1;94m    labels: I'm doing well, thanks for asking.\u001b[0;0m\n",
            "\u001b[0;95m     model: i ' m doing well . i ' m just getting ready to go to work .\u001b[0;0m\n",
            "\u001b[0mI'm doing well, thanks for asking.\u001b[0;0m\n",
            "\u001b[1;94m    labels: that's good to hear. i'm glad you're having a good day.\u001b[0;0m\n",
            "\u001b[0;95m     model: what do you do for a living ?\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: custom_test- - -\u001b[0;0m\n",
            "\u001b[0mHello there\u001b[0;0m\n",
            "\u001b[1;94m    labels: Hello Kitty\u001b[0;0m\n",
            "\u001b[0;95m     model: general kenoyim !\u001b[0;0m\n",
            "\u001b[0mHello Kitty\u001b[0;0m\n",
            "\u001b[1;94m    labels: i love kitty kitty! she's my favorite cat. do you have a favorite cat?\u001b[0;0m\n",
            "\u001b[0;95m     model: hello kitty\u001b[0;0m\n",
            "\u001b[0mi love kitty kitty! she's my favorite cat. do you have a favorite cat?\u001b[0;0m\n",
            "\u001b[1;94m    labels: But i like dogs\u001b[0;0m\n",
            "\u001b[0;95m     model: i do ! i have a cat named kitty . she ' s a little white cat .\u001b[0;0m\n",
            "\u001b[0mBut i like dogs\u001b[0;0m\n",
            "\u001b[1;94m    labels: what kind of dogs do you like? there are so many different kinds of dogs out there.\u001b[0;0m\n",
            "\u001b[0;95m     model: i like cats too\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: custom_test- - -\u001b[0;0m\n",
            "\u001b[0mHello there\u001b[0;0m\n",
            "\u001b[1;94m    labels: Hello Kitty\u001b[0;0m\n",
            "\u001b[0;95m     model: general kenoyim !\u001b[0;0m\n",
            "\u001b[0mHello Kitty\u001b[0;0m\n",
            "\u001b[1;94m    labels: i love kitty kitty! she's my favorite cat. do you have a favorite cat?\u001b[0;0m\n",
            "\u001b[0;95m     model: hello kitty\u001b[0;0m\n",
            "\u001b[0mi love kitty kitty! she's my favorite cat. do you have a favorite cat?\u001b[0;0m\n",
            "\u001b[1;94m    labels: But i like dogs\u001b[0;0m\n",
            "\u001b[0;95m     model: i do ! i have a cat named kitty . she ' s a little white cat .\u001b[0;0m\n",
            "\u001b[0mBut i like dogs\u001b[0;0m\n",
            "\u001b[1;94m    labels: what kind of dogs do you like? there are so many different kinds of dogs out there.\u001b[0;0m\n",
            "\u001b[0;95m     model: i like cats too\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: custom_test- - -\u001b[0;0m\n",
            "\u001b[0mHey\u001b[0;0m\n",
            "\u001b[1;94m    labels: Hey, how are you?\u001b[0;0m\n",
            "\u001b[0;95m     model: hey , how are you ?\u001b[0;0m\n",
            "\u001b[0mHey, how are you?\u001b[0;0m\n",
            "\u001b[1;94m    labels: i'm good. just got back from a long day at work. how are you?\u001b[0;0m\n",
            "\u001b[0;95m     model: i ' m good . just got back from a long day at work .\u001b[0;0m\n",
            "\u001b[0mi'm good. just got back from a long day at work. how are you?\u001b[0;0m\n",
            "\u001b[1;94m    labels: Good too, thanks\u001b[0;0m\n",
            "\u001b[0;95m     model: i ' m good . just got back from work . how are you ?\u001b[0;0m\n",
            "\u001b[0mGood too, thanks\u001b[0;0m\n",
            "\u001b[1;94m    labels: Do you like the tv show friends?\u001b[0;0m\n",
            "\u001b[0;95m     model: what are you doing today ?\u001b[0;0m\n",
            "\u001b[0mDo you like the tv show friends?\u001b[0;0m\n",
            "\u001b[1;94m    labels: Yes\u001b[0;0m\n",
            "\u001b[0;95m     model: yeah , i like it .\u001b[0;0m\n",
            "\u001b[0mYes\u001b[0;0m\n",
            "\u001b[1;94m    labels: Do you think ross and rachel were on a break?\u001b[0;0m\n",
            "\u001b[0;95m     model: what is your favorite show ?\u001b[0;0m\n",
            "\u001b[0mDo you think ross and rachel were on a break?\u001b[0;0m\n",
            "\u001b[1;94m    labels: i don't think so. i think it's more likely that they were together for a while.\u001b[0;0m\n",
            "\u001b[0;95m     model: i think so .\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: custom_test- - -\u001b[0;0m\n",
            "\u001b[0mHey\u001b[0;0m\n",
            "\u001b[1;94m    labels: Hey, how are you?\u001b[0;0m\n",
            "\u001b[0;95m     model: hey , how are you ?\u001b[0;0m\n",
            "\u001b[0mHey, how are you?\u001b[0;0m\n",
            "\u001b[1;94m    labels: i'm good. just got back from a long day at work. how are you?\u001b[0;0m\n",
            "\u001b[0;95m     model: i ' m good . just got back from a long day at work .\u001b[0;0m\n",
            "\u001b[0mi'm good. just got back from a long day at work. how are you?\u001b[0;0m\n",
            "\u001b[1;94m    labels: Good too, thanks\u001b[0;0m\n",
            "\u001b[0;95m     model: i ' m good . just got back from work . how are you ?\u001b[0;0m\n",
            "\u001b[0mGood too, thanks\u001b[0;0m\n",
            "\u001b[1;94m    labels: Do you like the tv show friends?\u001b[0;0m\n",
            "\u001b[0;95m     model: what are you doing today ?\u001b[0;0m\n",
            "\u001b[0mDo you like the tv show friends?\u001b[0;0m\n",
            "\u001b[1;94m    labels: Yes\u001b[0;0m\n",
            "\u001b[0;95m     model: yeah , i like it .\u001b[0;0m\n",
            "\u001b[0mYes\u001b[0;0m\n",
            "\u001b[1;94m    labels: Do you think ross and rachel were on a break?\u001b[0;0m\n",
            "\u001b[0;95m     model: what is your favorite show ?\u001b[0;0m\n",
            "\u001b[0mDo you think ross and rachel were on a break?\u001b[0;0m\n",
            "\u001b[1;94m    labels: i don't think so. i think it's more likely that they were together for a while.\u001b[0;0m\n",
            "\u001b[0;95m     model: i think so .\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: custom_test- - -\u001b[0;0m\n",
            "\u001b[0mTest\u001b[0;0m\n",
            "\u001b[1;94m    labels: i have a test tomorrow that i am going to test. it is a test to see if my test is good or not.\u001b[0;0m\n",
            "\u001b[0;95m     model: i have a test tomorrow . i am going to test my test on monday .\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: custom_test- - -\u001b[0;0m\n",
            "\u001b[0mTest\u001b[0;0m\n",
            "\u001b[1;94m    labels: i have a test tomorrow that i am going to test. it is a test to see if my test is good or not.\u001b[0;0m\n",
            "\u001b[0;95m     model: i have a test tomorrow . i am going to test my test on monday .\u001b[0;0m\n",
            "04:30:40 | epoch done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jg-iI3Cw1wjt",
        "outputId": "bf6a55cb-7688-4e0c-e485-e2995fd5f572"
      },
      "source": [
        "DisplayModel.main(\n",
        "    task='custom_train',\n",
        "    model_file=path.join(DATA_PATH, 'from_pretrained', 'model'),\n",
        "    num_examples=50,\n",
        "    dp=DATA_PATH,\n",
        "    skip_generation=False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "03:19:38 | \u001b[33mOverriding opt[\"model_file\"] to /content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/from_pretrained/model (previously: from_pretrained/model)\u001b[0m\n",
            "03:19:38 | \u001b[33mOverriding opt[\"skip_generation\"] to False (previously: True)\u001b[0m\n",
            "03:19:38 | Using CUDA\n",
            "03:19:38 | loading dictionary from /content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/from_pretrained/model.dict\n",
            "03:19:38 | num words = 54944\n",
            "03:19:39 | Total parameters: 87,508,992 (87,508,992 trainable)\n",
            "03:19:40 | Loading existing model params from /content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/from_pretrained/model\n",
            "03:19:44 | creating task(s): custom_train\n",
            " ~~ Loading from blenderbot_processed_data_train.txt ~~ \n",
            "03:19:44 | Opt:\n",
            "03:19:44 |     activation: gelu\n",
            "03:19:44 |     adafactor_eps: '[1e-30, 0.001]'\n",
            "03:19:44 |     adam_eps: 1e-08\n",
            "03:19:44 |     add_p1_after_newln: False\n",
            "03:19:44 |     aggregate_micro: False\n",
            "03:19:44 |     allow_missing_init_opts: False\n",
            "03:19:44 |     attention_dropout: 0.0\n",
            "03:19:44 |     batchsize: 12\n",
            "03:19:44 |     beam_block_full_context: True\n",
            "03:19:44 |     beam_block_list_filename: None\n",
            "03:19:44 |     beam_block_ngram: -1\n",
            "03:19:44 |     beam_context_block_ngram: -1\n",
            "03:19:44 |     beam_delay: 30\n",
            "03:19:44 |     beam_length_penalty: 0.65\n",
            "03:19:44 |     beam_min_length: 1\n",
            "03:19:44 |     beam_size: 1\n",
            "03:19:44 |     betas: '[0.9, 0.999]'\n",
            "03:19:44 |     bpe_add_prefix_space: None\n",
            "03:19:44 |     bpe_debug: False\n",
            "03:19:44 |     bpe_dropout: None\n",
            "03:19:44 |     bpe_merge: None\n",
            "03:19:44 |     bpe_vocab: None\n",
            "03:19:44 |     compute_tokenized_bleu: False\n",
            "03:19:44 |     datapath: \"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning\"\n",
            "03:19:44 |     datatype: train\n",
            "03:19:44 |     delimiter: '\\n'\n",
            "03:19:44 |     dict_class: parlai.core.dict:DictionaryAgent\n",
            "03:19:44 |     dict_endtoken: __end__\n",
            "03:19:44 |     dict_file: \"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/from_pretrained/model.dict\"\n",
            "03:19:44 |     dict_include_test: False\n",
            "03:19:44 |     dict_include_valid: False\n",
            "03:19:44 |     dict_initpath: None\n",
            "03:19:44 |     dict_language: english\n",
            "03:19:44 |     dict_loaded: True\n",
            "03:19:44 |     dict_lower: True\n",
            "03:19:44 |     dict_max_ngram_size: -1\n",
            "03:19:44 |     dict_maxexs: -1\n",
            "03:19:44 |     dict_maxtokens: -1\n",
            "03:19:44 |     dict_minfreq: 0\n",
            "03:19:44 |     dict_nulltoken: __null__\n",
            "03:19:44 |     dict_starttoken: __start__\n",
            "03:19:44 |     dict_textfields: text,labels\n",
            "03:19:44 |     dict_tokenizer: bpe\n",
            "03:19:44 |     dict_unktoken: __unk__\n",
            "03:19:44 |     display_add_fields: \n",
            "03:19:44 |     display_examples: False\n",
            "03:19:44 |     download_path: None\n",
            "03:19:44 |     dropout: 0.0\n",
            "03:19:44 |     dynamic_batching: full\n",
            "03:19:44 |     embedding_projection: random\n",
            "03:19:44 |     embedding_size: 512\n",
            "03:19:44 |     embedding_type: random\n",
            "03:19:44 |     embeddings_scale: True\n",
            "03:19:44 |     eval_batchsize: None\n",
            "03:19:44 |     eval_dynamic_batching: None\n",
            "03:19:44 |     evaltask: None\n",
            "03:19:44 |     ffn_size: 2048\n",
            "03:19:44 |     force_fp16_tokens: True\n",
            "03:19:44 |     fp16: True\n",
            "03:19:44 |     fp16_impl: mem_efficient\n",
            "03:19:44 |     gpu: -1\n",
            "03:19:44 |     gradient_clip: 0.1\n",
            "03:19:44 |     hide_labels: False\n",
            "03:19:44 |     history_add_global_end_token: None\n",
            "03:19:44 |     history_reversed: False\n",
            "03:19:44 |     history_size: -1\n",
            "03:19:44 |     image_cropsize: 224\n",
            "03:19:44 |     image_mode: raw\n",
            "03:19:44 |     image_size: 256\n",
            "03:19:44 |     inference: greedy\n",
            "03:19:44 |     init_model: \"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/models/blender/blender_90M/model\"\n",
            "03:19:44 |     init_opt: None\n",
            "03:19:44 |     interactive_mode: False\n",
            "03:19:44 |     invsqrt_lr_decay_gamma: -1\n",
            "03:19:44 |     label_truncate: 128\n",
            "03:19:44 |     learn_positional_embeddings: True\n",
            "03:19:44 |     learningrate: 1e-05\n",
            "03:19:44 |     log_every_n_secs: 10\n",
            "03:19:44 |     loglevel: info\n",
            "03:19:44 |     lr_scheduler: reduceonplateau\n",
            "03:19:44 |     lr_scheduler_decay: 0.5\n",
            "03:19:44 |     lr_scheduler_patience: 3\n",
            "03:19:44 |     max_lr_steps: -1\n",
            "03:19:44 |     max_train_time: 1200.0\n",
            "03:19:44 |     metrics: default\n",
            "03:19:44 |     model: transformer/generator\n",
            "03:19:44 |     model_file: \"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/from_pretrained/model\"\n",
            "03:19:44 |     model_parallel: False\n",
            "03:19:44 |     momentum: 0\n",
            "03:19:44 |     multitask_weights: [1]\n",
            "03:19:44 |     mutators: None\n",
            "03:19:44 |     n_decoder_layers: -1\n",
            "03:19:44 |     n_encoder_layers: -1\n",
            "03:19:44 |     n_heads: 16\n",
            "03:19:44 |     n_layers: 8\n",
            "03:19:44 |     n_positions: 512\n",
            "03:19:44 |     n_segments: 0\n",
            "03:19:44 |     nesterov: True\n",
            "03:19:44 |     no_cuda: False\n",
            "03:19:44 |     num_epochs: -1\n",
            "03:19:44 |     num_examples: 50\n",
            "03:19:44 |     nus: [0.7]\n",
            "03:19:44 |     optimizer: mem_eff_adam\n",
            "03:19:44 |     output_scaling: 1.0\n",
            "03:19:44 |     override: '{\\'task\\': \\'custom_train\\', \\'model_file\\': \"/content/drive/My Drive/Master\\'s Thesis/Blenderbot Transfer Learning/from_pretrained/model\", \\'num_examples\\': \\'50\\', \\'datapath\\': \"/content/drive/My Drive/Master\\'s Thesis/Blenderbot Transfer Learning\", \\'skip_generation\\': False}'\n",
            "03:19:44 |     parlai_home: /usr/local/lib/python3.7/dist-packages\n",
            "03:19:44 |     person_tokens: False\n",
            "03:19:44 |     rank_candidates: False\n",
            "03:19:44 |     relu_dropout: 0.0\n",
            "03:19:44 |     save_after_valid: False\n",
            "03:19:44 |     save_every_n_secs: -1\n",
            "03:19:44 |     share_word_embeddings: True\n",
            "03:19:44 |     short_final_eval: False\n",
            "03:19:44 |     skip_generation: False\n",
            "03:19:44 |     special_tok_lst: None\n",
            "03:19:44 |     split_lines: False\n",
            "03:19:44 |     starttime: Apr17_02-44\n",
            "03:19:44 |     task: custom_train\n",
            "03:19:44 |     temperature: 1.0\n",
            "03:19:44 |     tensorboard_log: False\n",
            "03:19:44 |     tensorboard_logdir: None\n",
            "03:19:44 |     text_truncate: 512\n",
            "03:19:44 |     topk: 10\n",
            "03:19:44 |     topp: 0.9\n",
            "03:19:44 |     truncate: -1\n",
            "03:19:44 |     update_freq: 1\n",
            "03:19:44 |     use_reply: label\n",
            "03:19:44 |     validation_cutoff: 1.0\n",
            "03:19:44 |     validation_every_n_epochs: 0.25\n",
            "03:19:44 |     validation_every_n_secs: -1\n",
            "03:19:44 |     validation_max_exs: -1\n",
            "03:19:44 |     validation_metric: ppl\n",
            "03:19:44 |     validation_metric_mode: None\n",
            "03:19:44 |     validation_patience: 10\n",
            "03:19:44 |     validation_share_agent: False\n",
            "03:19:44 |     variant: xlm\n",
            "03:19:44 |     verbose: False\n",
            "03:19:44 |     wandb_log: False\n",
            "03:19:44 |     wandb_name: None\n",
            "03:19:44 |     wandb_project: None\n",
            "03:19:44 |     warmup_rate: 0.0001\n",
            "03:19:44 |     warmup_updates: 100\n",
            "03:19:44 |     weight_decay: None\n",
            "\u001b[1;31m- - - NEW EPISODE: custom_train- - -\u001b[0;0m\n",
            "\u001b[0mTest\u001b[0;0m\n",
            "\u001b[1;94m    labels: i have a test tomorrow that i am going to test. it is a test to see if my test is good or not.\u001b[0;0m\n",
            "\u001b[0;95m     model: i have a test tomorrow . i am going to test my test on monday .\u001b[0;0m\n",
            "\u001b[0mi have a test tomorrow that i am going to test. it is a test to see if my test is good or not.\u001b[0;0m\n",
            "\u001b[1;94m    labels: what kind of test are you going to take? i'm sure you'll do great!\u001b[0;0m\n",
            "\u001b[0;95m     model: i hope you do well . i ' m sure you will do well .\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: custom_train- - -\u001b[0;0m\n",
            "\u001b[0mTest\u001b[0;0m\n",
            "\u001b[1;94m    labels: i have a test tomorrow that i am going to test. it is a test to see if my test is good or not.\u001b[0;0m\n",
            "\u001b[0;95m     model: i have a test tomorrow . i am going to test my test on monday .\u001b[0;0m\n",
            "\u001b[0mi have a test tomorrow that i am going to test. it is a test to see if my test is good or not.\u001b[0;0m\n",
            "\u001b[1;94m    labels: what kind of test are you going to take? i'm sure you'll do great!\u001b[0;0m\n",
            "\u001b[0;95m     model: i hope you do well . i ' m sure you will do well .\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: custom_train- - -\u001b[0;0m\n",
            "\u001b[0mHello friends\u001b[0;0m\n",
            "\u001b[1;94m    labels: Hi there\u001b[0;0m\n",
            "\u001b[0;95m     model: hello , how are you ?\u001b[0;0m\n",
            "\u001b[0mHi there\u001b[0;0m\n",
            "\u001b[1;94m    labels: Chai pilo\u001b[0;0m\n",
            "\u001b[0;95m     model: hi there\u001b[0;0m\n",
            "\u001b[0mChai pilo\u001b[0;0m\n",
            "\u001b[1;94m    labels: Hiya!\u001b[0;0m\n",
            "\u001b[0;95m     model: chai pilo is a great movie\u001b[0;0m\n",
            "\u001b[0mHiya!\u001b[0;0m\n",
            "\u001b[1;94m    labels: hello, how are you today? i just got back from a long day at the office.\u001b[0;0m\n",
            "\u001b[0;95m     model: what are you up to today ?\u001b[0;0m\n",
            "\u001b[0mhello, how are you today? i just got back from a long day at the office.\u001b[0;0m\n",
            "\u001b[1;94m    labels: i'm doing well. i just got back from a long day at work as well.\u001b[0;0m\n",
            "\u001b[0;95m     model: i ' m doing well . just got back from a long day at work .\u001b[0;0m\n",
            "\u001b[0mi'm doing well. i just got back from a long day at work as well.\u001b[0;0m\n",
            "\u001b[1;94m    labels: Good to hear.\u001b[0;0m\n",
            "\u001b[0;95m     model: what do you do for work ?\u001b[0;0m\n",
            "\u001b[0mGood to hear.\u001b[0;0m\n",
            "\u001b[1;94m    labels: Have you seen the tv show friends?\u001b[0;0m\n",
            "\u001b[0;95m     model: what do you do for a living ?\u001b[0;0m\n",
            "\u001b[0mHave you seen the tv show friends?\u001b[0;0m\n",
            "\u001b[1;94m    labels: that's good to hear. what do you do for a living, if you don't mind me asking?\u001b[0;0m\n",
            "\u001b[0;95m     model: yes , i love it .\u001b[0;0m\n",
            "\u001b[0mthat's good to hear. what do you do for a living, if you don't mind me asking?\u001b[0;0m\n",
            "\u001b[1;94m    labels: I work as on a research project for a military project\u001b[0;0m\n",
            "\u001b[0;95m     model: i work in a restaurant .\u001b[0;0m\n",
            "\u001b[0mI work as on a research project for a military project\u001b[0;0m\n",
            "\u001b[1;94m    labels: i'm a stay at home mom. it's hard work, but it pays the bills.\u001b[0;0m\n",
            "\u001b[0;95m     model: what do you do for a living ?\u001b[0;0m\n",
            "\u001b[0mi'm a stay at home mom. it's hard work, but it pays the bills.\u001b[0;0m\n",
            "\u001b[1;94m    labels: Hi\u001b[0;0m\n",
            "\u001b[0;95m     model: i ' m sure you ' re a great parent .\u001b[0;0m\n",
            "\u001b[0mHi\u001b[0;0m\n",
            "\u001b[1;94m    labels: hi\u001b[0;0m\n",
            "\u001b[0;95m     model: what do you do for a living ?\u001b[0;0m\n",
            "\u001b[0mhi\u001b[0;0m\n",
            "\u001b[1;94m    labels: hi\u001b[0;0m\n",
            "\u001b[0;95m     model: what are you up to today ?\u001b[0;0m\n",
            "\u001b[0mhi\u001b[0;0m\n",
            "\u001b[1;94m    labels: Hello\u001b[0;0m\n",
            "\u001b[0;95m     model: hi\u001b[0;0m\n",
            "\u001b[0mHello\u001b[0;0m\n",
            "\u001b[1;94m    labels: I am really depressed about job search\u001b[0;0m\n",
            "\u001b[0;95m     model: hi\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: custom_train- - -\u001b[0;0m\n",
            "\u001b[0mHello\u001b[0;0m\n",
            "\u001b[1;94m    labels: Hey partner\u001b[0;0m\n",
            "\u001b[0;95m     model: hello , how are you today ?\u001b[0;0m\n",
            "\u001b[0mHey partner\u001b[0;0m\n",
            "\u001b[1;94m    labels: hi\u001b[0;0m\n",
            "\u001b[0;95m     model: hey partner\u001b[0;0m\n",
            "\u001b[0mhi\u001b[0;0m\n",
            "\u001b[1;94m    labels: hi, how are you doing today? i just got back from a long day at work.\u001b[0;0m\n",
            "\u001b[0;95m     model: hey partner\u001b[0;0m\n",
            "\u001b[0mhi, how are you doing today? i just got back from a long day at work.\u001b[0;0m\n",
            "\u001b[1;94m    labels: Do you watch tarak mehta\u001b[0;0m\n",
            "\u001b[0;95m     model: i ' m doing well . just got back from work .\u001b[0;0m\n",
            "\u001b[0mDo you watch tarak mehta\u001b[0;0m\n",
            "\u001b[1;94m    labels: i've never heard of tarak mehta. i'll have to check it out.\u001b[0;0m\n",
            "\u001b[0;95m     model: i do not , i am not a big fan of the show .\u001b[0;0m\n",
            "\u001b[0mi've never heard of tarak mehta. i'll have to check it out.\u001b[0;0m\n",
            "\u001b[1;94m    labels: Hi\u001b[0;0m\n",
            "\u001b[0;95m     model: i ' m not sure what that is .\u001b[0;0m\n",
            "\u001b[0mHi\u001b[0;0m\n",
            "\u001b[1;94m    labels: Hiya\u001b[0;0m\n",
            "\u001b[0;95m     model: what are you doing today ?\u001b[0;0m\n",
            "\u001b[0mHiya\u001b[0;0m\n",
            "\u001b[1;94m    labels: Hello tejas\u001b[0;0m\n",
            "\u001b[0;95m     model: what are you up to today ?\u001b[0;0m\n",
            "\u001b[0mHello tejas\u001b[0;0m\n",
            "\u001b[1;94m    labels: how are you?\u001b[0;0m\n",
            "\u001b[0;95m     model: what are you doing today ?\u001b[0;0m\n",
            "\u001b[0mhow are you?\u001b[0;0m\n",
            "\u001b[1;94m    labels: i cant see your texts\u001b[0;0m\n",
            "\u001b[0;95m     model: i ' m good . just got back from work .\u001b[0;0m\n",
            "\u001b[0mi cant see your texts\u001b[0;0m\n",
            "\u001b[1;94m    labels: I'm good how are you?\u001b[0;0m\n",
            "\u001b[0;95m     model: i ' m good .\u001b[0;0m\n",
            "\u001b[0mI'm good how are you?\u001b[0;0m\n",
            "\u001b[1;94m    labels: I can see your texts\u001b[0;0m\n",
            "\u001b[0;95m     model: i ' m good thanks for asking\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: custom_train- - -\u001b[0;0m\n",
            "\u001b[0mHello\u001b[0;0m\n",
            "\u001b[1;94m    labels: Hi Eve!\u001b[0;0m\n",
            "\u001b[0;95m     model: hello , how are you today ?\u001b[0;0m\n",
            "\u001b[0mHi Eve!\u001b[0;0m\n",
            "\u001b[1;94m    labels: Hi\u001b[0;0m\n",
            "\u001b[0;95m     model: hi eve !\u001b[0;0m\n",
            "\u001b[0mHi\u001b[0;0m\n",
            "\u001b[1;94m    labels: F U\u001b[0;0m\n",
            "\u001b[0;95m     model: hi\u001b[0;0m\n",
            "\u001b[0mF U\u001b[0;0m\n",
            "\u001b[1;94m    labels: DA\u001b[0;0m\n",
            "\u001b[0;95m     model: f\u001b[0;0m\n",
            "\u001b[0mDA\u001b[0;0m\n",
            "\u001b[1;94m    labels: Go make Maggi!\u001b[0;0m\n",
            "\u001b[0;95m     model: da\u001b[0;0m\n",
            "\u001b[0mGo make Maggi!\u001b[0;0m\n",
            "\u001b[1;94m    labels: Don't spend 59893 hours on the phone\u001b[0;0m\n",
            "\u001b[0;95m     model: i ' m so hungry !\u001b[0;0m\n",
            "\u001b[0mDon't spend 59893 hours on the phone\u001b[0;0m\n",
            "\u001b[1;94m    labels: In the process\u001b[0;0m\n",
            "\u001b[0;95m     model: i ' m not sure what you mean\u001b[0;0m\n",
            "\u001b[0mIn the process\u001b[0;0m\n",
            "\u001b[1;94m    labels: what are you going to do in the process? i'm not sure what i want to do yet.\u001b[0;0m\n",
            "\u001b[0;95m     model: in the process\u001b[0;0m\n",
            "\u001b[0mwhat are you going to do in the process? i'm not sure what i want to do yet.\u001b[0;0m\n",
            "\u001b[1;94m    labels: I'm not. I'm just curious.\u001b[0;0m\n",
            "\u001b[0;95m     model: i ' m not sure what i want to do yet .\u001b[0;0m\n",
            "\u001b[0mI'm not. I'm just curious.\u001b[0;0m\n",
            "\u001b[1;94m    labels: i'm not either. i don't know what i'd do without her.\u001b[0;0m\n",
            "\u001b[0;95m     model: i ' m not . i ' m just curious .\u001b[0;0m\n",
            "\u001b[0mi'm not either. i don't know what i'd do without her.\u001b[0;0m\n",
            "\u001b[1;94m    labels: Do you like crime patrol \u001b[0;0m\n",
            "\u001b[0;95m     model: i ' m not sure what i ' d do without her .\u001b[0;0m\n",
            "\u001b[0mDo you like crime patrol \u001b[0;0m\n",
            "\u001b[1;94m    labels: I like them, but I don't like them as much as I like the police.\u001b[0;0m\n",
            "\u001b[0;95m     model: i do . i like the police .\u001b[0;0m\n",
            "\u001b[0mI like them, but I don't like them as much as I like the police.\u001b[0;0m\n",
            "\u001b[1;94m    labels: Execute order 66\u001b[0;0m\n",
            "\u001b[0;95m     model: what do you like to do for fun ?\u001b[0;0m\n",
            "\u001b[0mExecute order 66\u001b[0;0m\n",
            "\u001b[1;94m    labels: I know what you mean. I'm not sure what I'd do without her.\u001b[0;0m\n",
            "\u001b[0;95m     model: you are a bold one\u001b[0;0m\n",
            "\u001b[0mI know what you mean. I'm not sure what I'd do without her.\u001b[0;0m\n",
            "\u001b[1;94m    labels: Hello There\u001b[0;0m\n",
            "\u001b[0;95m     model: i ' m not either . i don ' t know what i ' d do without her .\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: custom_train- - -\u001b[0;0m\n",
            "\u001b[0mHey\u001b[0;0m\n",
            "\u001b[1;94m    labels: How are you?\u001b[0;0m\n",
            "\u001b[0;95m     model: hey , how are you ?\u001b[0;0m\n",
            "\u001b[0mHow are you?\u001b[0;0m\n",
            "\u001b[1;94m    labels: I am in Aus at the moment for a business trip....\u001b[0;0m\n",
            "\u001b[0;95m     model: i ' m good . just got back from a long day at work .\u001b[0;0m\n",
            "\u001b[0mI am in Aus at the moment for a business trip....\u001b[0;0m\n",
            "\u001b[1;94m    labels: that's cool. what kind of business are you going to do in austrailia?\u001b[0;0m\n",
            "\u001b[0;95m     model: i ' m in australia for a business trip . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\u001b[0;0m\n",
            "\u001b[0mthat's cool. what kind of business are you going to do in austrailia?\u001b[0;0m\n",
            "\u001b[1;94m    labels: So it's a morning for me haha\u001b[0;0m\n",
            "\u001b[0;95m     model: i ' m going to be a business owner . i ' m going to be a business owner for a few years .\u001b[0;0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxXZszkOATsq"
      },
      "source": [
        "## Model Evaluations\n",
        "Evaluate transfer learning model on our dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SM9Sw2kKltI_",
        "outputId": "bcf98193-75a0-4ae3-fda6-304a91ba855a"
      },
      "source": [
        "EvalModel.main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: ipykernel_launcher.py [-h] [--helpall] [-o INIT_OPT]\n",
            "                             [--allow-missing-init-opts ALLOW_MISSING_INIT_OPTS]\n",
            "                             [-t TASK] [-dt DATATYPE] [-bs BATCHSIZE]\n",
            "                             [-dynb {full,batchsort,None}] [-v] [-dp DATAPATH]\n",
            "                             [-m MODEL] [-mf MODEL_FILE] [-im INIT_MODEL]\n",
            "                             [-rf REPORT_FILENAME] [--world-logs WORLD_LOGS]\n",
            "                             [--save-format {conversations,parlai}]\n",
            "                             [-ne NUM_EXAMPLES] [-d DISPLAY_EXAMPLES]\n",
            "                             [-ltim LOG_EVERY_N_SECS] [-mcs METRICS]\n",
            "                             [-micro AGGREGATE_MICRO]\n",
            "                             [--log-keep-fields LOG_KEEP_FIELDS]\n",
            "                             [-tblog TENSORBOARD_LOG]\n",
            "                             [-tblogdir TENSORBOARD_LOGDIR]\n",
            "\n",
            "Evaluate a model\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help\n",
            "        show this help message and exit\n",
            "  --helpall\n",
            "        Show usage, including advanced arguments.\n",
            "  -rf, --report-filename REPORT_FILENAME\n",
            "        Saves a json file of the evaluation report either as an extension to\n",
            "        the model-file (if begins with a \".\") or a whole file path. Set to the\n",
            "        empty string to not save at all. (default: )\n",
            "  --world-logs WORLD_LOGS\n",
            "        Saves a jsonl file of the world logs.Set to the empty string to not\n",
            "        save at all. (default: )\n",
            "  --save-format {conversations,parlai}\n",
            "  -ne, --num-examples NUM_EXAMPLES\n",
            "  -d, --display-examples DISPLAY_EXAMPLES\n",
            "  -ltim, --log-every-n-secs LOG_EVERY_N_SECS\n",
            "  -mcs, --metrics METRICS\n",
            "        list of metrics to show/compute, e.g. all, default,or give a list\n",
            "        split by , like ppl,f1,accuracy,hits@1,rouge,bleuthe rouge metrics\n",
            "        will be computed as rouge-1, rouge-2 and rouge-l (default: default)\n",
            "  -micro, --aggregate-micro AGGREGATE_MICRO\n",
            "        Report micro-averaged metrics instead of macro averaged metrics.\n",
            "        (default: False)\n",
            "\n",
            "Main ParlAI Arguments:\n",
            "  -o, --init-opt INIT_OPT\n",
            "        Path to json file of options. Note: Further Command-line arguments\n",
            "        override file-based options. (default: None)\n",
            "  --allow-missing-init-opts ALLOW_MISSING_INIT_OPTS\n",
            "        Warn instead of raising if an argument passed in with --init-opt is\n",
            "        not in the target opt. (default: False)\n",
            "  -t, --task TASK\n",
            "        ParlAI task(s), e.g. \"babi:Task1\" or \"babi,cbt\" (default: None)\n",
            "  -dt, --datatype DATATYPE\n",
            "        choose from: train, train:ordered, valid, test. to stream data add\n",
            "        \":stream\" to any option (e.g., train:stream). by default train is\n",
            "        random with replacement, valid is ordered, test is ordered. (default:\n",
            "        valid)\n",
            "  -bs, --batchsize BATCHSIZE\n",
            "        batch size for minibatch training schemes (default: 1)\n",
            "  -dynb, --dynamic-batching {full,batchsort,None}\n",
            "        Use dynamic batching (default: None)\n",
            "  -v, --verbose\n",
            "        Print all messages\n",
            "  -dp, --datapath DATAPATH\n",
            "        path to datasets, defaults to {parlai_dir}/data (default: None)\n",
            "\n",
            "ParlAI Model Arguments:\n",
            "  -m, --model MODEL\n",
            "        the model class name. can match parlai/agents/<model> for agents in\n",
            "        that directory, or can provide a fully specified module for `from X\n",
            "        import Y` via `-m X:Y` (e.g. `-m\n",
            "        parlai.agents.seq2seq.seq2seq:Seq2SeqAgent`) (default: None)\n",
            "  -mf, --model-file MODEL_FILE\n",
            "        model file name for loading and saving models (default: None)\n",
            "  -im, --init-model INIT_MODEL\n",
            "        Initialize model weights and dict from this file (default: None)\n",
            "\n",
            "World Logging:\n",
            "  --log-keep-fields LOG_KEEP_FIELDS\n",
            "        Fields to keep when logging. Should be a comma separated list\n",
            "        (default: all)\n",
            "\n",
            "Tensorboard Arguments:\n",
            "  -tblog, --tensorboard-log TENSORBOARD_LOG\n",
            "        Tensorboard logging of metrics (default: False)\n",
            "  -tblogdir, --tensorboard-logdir TENSORBOARD_LOGDIR\n",
            "        Tensorboard logging directory, defaults to model_file.tensorboard\n",
            "        (default: None)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Parse Error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-f9afc37e-ea94-47a2-a73f-395c17f445af.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HD8e_czI9ODi",
        "outputId": "8e1deb54-4447-4095-a417-00b81f978df7"
      },
      "source": [
        "EvalModel.main(\n",
        "    task='custom_train',\n",
        "    mf=\"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/from_pretrained/model\",\n",
        "    rf=\"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/evaluations/transfer_learning_custom_data_train.json\",\n",
        "    metrics=['ppl', 'bleu-4'],\n",
        "    skip_generation=False,\n",
        "    batchsize=12,\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "03:20:52 | \u001b[33mOverriding opt[\"datatype\"] to valid (previously: train)\u001b[0m\n",
            "03:20:52 | \u001b[33mOverriding opt[\"model_file\"] to /content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/from_pretrained/model (previously: from_pretrained/model)\u001b[0m\n",
            "03:20:52 | \u001b[33mOverriding opt[\"metrics\"] to ppl,bleu-4 (previously: default)\u001b[0m\n",
            "03:20:52 | \u001b[33mOverriding opt[\"skip_generation\"] to False (previously: True)\u001b[0m\n",
            "03:20:52 | Using CUDA\n",
            "03:20:52 | loading dictionary from /content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/from_pretrained/model.dict\n",
            "03:20:53 | num words = 54944\n",
            "03:20:54 | Total parameters: 87,508,992 (87,508,992 trainable)\n",
            "03:20:54 | Loading existing model params from /content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/from_pretrained/model\n",
            "03:20:56 | Opt:\n",
            "03:20:56 |     activation: gelu\n",
            "03:20:56 |     adafactor_eps: '[1e-30, 0.001]'\n",
            "03:20:56 |     adam_eps: 1e-08\n",
            "03:20:56 |     add_p1_after_newln: False\n",
            "03:20:56 |     aggregate_micro: False\n",
            "03:20:56 |     allow_missing_init_opts: False\n",
            "03:20:56 |     attention_dropout: 0.0\n",
            "03:20:56 |     batchsize: 12\n",
            "03:20:56 |     beam_block_full_context: True\n",
            "03:20:56 |     beam_block_list_filename: None\n",
            "03:20:56 |     beam_block_ngram: -1\n",
            "03:20:56 |     beam_context_block_ngram: -1\n",
            "03:20:56 |     beam_delay: 30\n",
            "03:20:56 |     beam_length_penalty: 0.65\n",
            "03:20:56 |     beam_min_length: 1\n",
            "03:20:56 |     beam_size: 1\n",
            "03:20:56 |     betas: '[0.9, 0.999]'\n",
            "03:20:56 |     bpe_add_prefix_space: None\n",
            "03:20:56 |     bpe_debug: False\n",
            "03:20:56 |     bpe_dropout: None\n",
            "03:20:56 |     bpe_merge: None\n",
            "03:20:56 |     bpe_vocab: None\n",
            "03:20:56 |     compute_tokenized_bleu: False\n",
            "03:20:56 |     datapath: \"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning\"\n",
            "03:20:56 |     datatype: valid\n",
            "03:20:56 |     delimiter: '\\n'\n",
            "03:20:56 |     dict_class: parlai.core.dict:DictionaryAgent\n",
            "03:20:56 |     dict_endtoken: __end__\n",
            "03:20:56 |     dict_file: \"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/from_pretrained/model.dict\"\n",
            "03:20:56 |     dict_include_test: False\n",
            "03:20:56 |     dict_include_valid: False\n",
            "03:20:56 |     dict_initpath: None\n",
            "03:20:56 |     dict_language: english\n",
            "03:20:56 |     dict_loaded: True\n",
            "03:20:56 |     dict_lower: True\n",
            "03:20:56 |     dict_max_ngram_size: -1\n",
            "03:20:56 |     dict_maxexs: -1\n",
            "03:20:56 |     dict_maxtokens: -1\n",
            "03:20:56 |     dict_minfreq: 0\n",
            "03:20:56 |     dict_nulltoken: __null__\n",
            "03:20:56 |     dict_starttoken: __start__\n",
            "03:20:56 |     dict_textfields: text,labels\n",
            "03:20:56 |     dict_tokenizer: bpe\n",
            "03:20:56 |     dict_unktoken: __unk__\n",
            "03:20:56 |     display_examples: False\n",
            "03:20:56 |     download_path: None\n",
            "03:20:56 |     dropout: 0.0\n",
            "03:20:56 |     dynamic_batching: full\n",
            "03:20:56 |     embedding_projection: random\n",
            "03:20:56 |     embedding_size: 512\n",
            "03:20:56 |     embedding_type: random\n",
            "03:20:56 |     embeddings_scale: True\n",
            "03:20:56 |     eval_batchsize: None\n",
            "03:20:56 |     eval_dynamic_batching: None\n",
            "03:20:56 |     evaltask: None\n",
            "03:20:56 |     ffn_size: 2048\n",
            "03:20:56 |     force_fp16_tokens: True\n",
            "03:20:56 |     fp16: True\n",
            "03:20:56 |     fp16_impl: mem_efficient\n",
            "03:20:56 |     gpu: -1\n",
            "03:20:56 |     gradient_clip: 0.1\n",
            "03:20:56 |     hide_labels: False\n",
            "03:20:56 |     history_add_global_end_token: None\n",
            "03:20:56 |     history_reversed: False\n",
            "03:20:56 |     history_size: -1\n",
            "03:20:56 |     image_cropsize: 224\n",
            "03:20:56 |     image_mode: raw\n",
            "03:20:56 |     image_size: 256\n",
            "03:20:56 |     inference: greedy\n",
            "03:20:56 |     init_model: \"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/models/blender/blender_90M/model\"\n",
            "03:20:56 |     init_opt: None\n",
            "03:20:56 |     interactive_mode: False\n",
            "03:20:56 |     invsqrt_lr_decay_gamma: -1\n",
            "03:20:56 |     label_truncate: 128\n",
            "03:20:56 |     learn_positional_embeddings: True\n",
            "03:20:56 |     learningrate: 1e-05\n",
            "03:20:56 |     log_every_n_secs: 10\n",
            "03:20:56 |     log_keep_fields: all\n",
            "03:20:56 |     loglevel: info\n",
            "03:20:56 |     lr_scheduler: reduceonplateau\n",
            "03:20:56 |     lr_scheduler_decay: 0.5\n",
            "03:20:56 |     lr_scheduler_patience: 3\n",
            "03:20:56 |     max_lr_steps: -1\n",
            "03:20:56 |     max_train_time: 1200.0\n",
            "03:20:56 |     metrics: ppl,bleu-4\n",
            "03:20:56 |     model: transformer/generator\n",
            "03:20:56 |     model_file: \"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/from_pretrained/model\"\n",
            "03:20:56 |     model_parallel: False\n",
            "03:20:56 |     momentum: 0\n",
            "03:20:56 |     multitask_weights: [1]\n",
            "03:20:56 |     mutators: None\n",
            "03:20:56 |     n_decoder_layers: -1\n",
            "03:20:56 |     n_encoder_layers: -1\n",
            "03:20:56 |     n_heads: 16\n",
            "03:20:56 |     n_layers: 8\n",
            "03:20:56 |     n_positions: 512\n",
            "03:20:56 |     n_segments: 0\n",
            "03:20:57 |     nesterov: True\n",
            "03:20:57 |     no_cuda: False\n",
            "03:20:57 |     num_epochs: -1\n",
            "03:20:57 |     num_examples: -1\n",
            "03:20:57 |     nus: [0.7]\n",
            "03:20:57 |     optimizer: mem_eff_adam\n",
            "03:20:57 |     output_scaling: 1.0\n",
            "03:20:57 |     override: '{\\'datatype\\': \\'valid\\', \\'task\\': \\'custom_train\\', \\'model_file\\': \"/content/drive/My Drive/Master\\'s Thesis/Blenderbot Transfer Learning/from_pretrained/model\", \\'report_filename\\': \"/content/drive/My Drive/Master\\'s Thesis/Blenderbot Transfer Learning/evaluations/transfer_learning_custom_data_train.json\", \\'metrics\\': \\'ppl,bleu-4\\', \\'skip_generation\\': False, \\'batchsize\\': 12}'\n",
            "03:20:57 |     parlai_home: /usr/local/lib/python3.7/dist-packages\n",
            "03:20:57 |     person_tokens: False\n",
            "03:20:57 |     rank_candidates: False\n",
            "03:20:57 |     relu_dropout: 0.0\n",
            "03:20:57 |     report_filename: \"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/evaluations/transfer_learning_custom_data_train.json\"\n",
            "03:20:57 |     save_after_valid: False\n",
            "03:20:57 |     save_every_n_secs: -1\n",
            "03:20:57 |     save_format: conversations\n",
            "03:20:57 |     share_word_embeddings: True\n",
            "03:20:57 |     short_final_eval: False\n",
            "03:20:57 |     skip_generation: False\n",
            "03:20:57 |     special_tok_lst: None\n",
            "03:20:57 |     split_lines: False\n",
            "03:20:57 |     starttime: Apr17_02-44\n",
            "03:20:57 |     task: custom_train\n",
            "03:20:57 |     temperature: 1.0\n",
            "03:20:57 |     tensorboard_log: False\n",
            "03:20:57 |     tensorboard_logdir: None\n",
            "03:20:57 |     text_truncate: 512\n",
            "03:20:57 |     topk: 10\n",
            "03:20:57 |     topp: 0.9\n",
            "03:20:57 |     truncate: -1\n",
            "03:20:57 |     update_freq: 1\n",
            "03:20:57 |     use_reply: label\n",
            "03:20:57 |     validation_cutoff: 1.0\n",
            "03:20:57 |     validation_every_n_epochs: 0.25\n",
            "03:20:57 |     validation_every_n_secs: -1\n",
            "03:20:57 |     validation_max_exs: -1\n",
            "03:20:57 |     validation_metric: ppl\n",
            "03:20:57 |     validation_metric_mode: None\n",
            "03:20:57 |     validation_patience: 10\n",
            "03:20:57 |     validation_share_agent: False\n",
            "03:20:57 |     variant: xlm\n",
            "03:20:57 |     verbose: False\n",
            "03:20:57 |     wandb_log: False\n",
            "03:20:57 |     wandb_name: None\n",
            "03:20:57 |     wandb_project: None\n",
            "03:20:57 |     warmup_rate: 0.0001\n",
            "03:20:57 |     warmup_updates: 100\n",
            "03:20:57 |     weight_decay: None\n",
            "03:20:57 |     world_logs: \n",
            "03:20:57 | Evaluating task custom_train using datatype valid.\n",
            "03:20:57 | creating task(s): custom_train\n",
            " ~~ Loading from blenderbot_processed_data_train.txt ~~ \n",
            "03:21:07 | 77.4% complete (278 / 359), 0:00:10 elapsed, 0:00:03 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "     .003597  .03879  1686  3927 26.97  278 .1917    .1557 1.976 115.7 269.4 7.217      .5852 1802 4196\n",
            "03:21:11 | Finished evaluating tasks ['custom_train'] using datatype valid\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "     .002786  .03004  1621  5082 25.57  359 .1624   .04044 2.069 79.02 247.7 7.914      .5672 1700 5329\n",
            "03:21:11 | Saving model report to /content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/evaluations/transfer_learning_custom_data_train.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.002785515320334262,\n",
              " 'bleu-4': 0.03003660287686207,\n",
              " 'ctpb': 1621.2727272727273,\n",
              " 'ctps': 5081.500888976448,\n",
              " 'exps': 25.570558359066407,\n",
              " 'exs': 359,\n",
              " 'f1': 0.16239896069019613,\n",
              " 'gpu_mem': 0.040438176818775956,\n",
              " 'loss': 2.0686116537418315,\n",
              " 'ltpb': 79.02272727272727,\n",
              " 'ltps': 247.67656251796507,\n",
              " 'ppl': 7.9138283533632805,\n",
              " 'token_acc': 0.5671555939027898,\n",
              " 'tpb': 1700.2954545454545,\n",
              " 'tps': 5329.1814429993965}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXC-s1YMAxbS"
      },
      "source": [
        "Evaluate baseline model on our data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-B5VR1c9N79",
        "outputId": "d5a57438-ca58-4ba6-b6cf-aae60c5f60e3"
      },
      "source": [
        "EvalModel.main(\n",
        "    task='custom_train',\n",
        "    mf=\"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/models/blender/blender_90M/model\",\n",
        "    rf=\"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/evaluations/baseline_custom_data_train.json\",\n",
        "    metrics=['ppl', 'bleu-4'],\n",
        "    skip_generation=False,\n",
        "    batchsize=12,\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "03:21:22 | \u001b[33mOverriding opt[\"datatype\"] to valid (previously: train)\u001b[0m\n",
            "03:21:22 | \u001b[33mOverriding opt[\"task\"] to custom_train (previously: internal:blended_skill_talk,wizard_of_wikipedia,convai2,empathetic_dialogues)\u001b[0m\n",
            "03:21:22 | \u001b[33mOverriding opt[\"model_file\"] to /content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/models/blender/blender_90M/model (previously: /checkpoint/edinan/20200210/baseline_BST_retnref/lr=7.5e-06_attention-dropout=0.0_relu-dropout=0.0/model)\u001b[0m\n",
            "03:21:22 | \u001b[33mOverriding opt[\"metrics\"] to ppl,bleu-4 (previously: default)\u001b[0m\n",
            "03:21:22 | \u001b[33mOverriding opt[\"batchsize\"] to 12 (previously: 16)\u001b[0m\n",
            "03:21:22 | Using CUDA\n",
            "03:21:22 | loading dictionary from /content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/models/blender/blender_90M/model.dict\n",
            "03:21:22 | num words = 54944\n",
            "03:21:24 | Total parameters: 87,508,992 (87,508,992 trainable)\n",
            "03:21:24 | Loading existing model params from /content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/models/blender/blender_90M/model\n",
            "03:21:29 | Opt:\n",
            "03:21:29 |     activation: gelu\n",
            "03:21:29 |     adafactor_eps: '[1e-30, 0.001]'\n",
            "03:21:29 |     adam_eps: 1e-08\n",
            "03:21:29 |     add_p1_after_newln: False\n",
            "03:21:29 |     aggregate_micro: False\n",
            "03:21:29 |     allow_missing_init_opts: False\n",
            "03:21:29 |     attention_dropout: 0.0\n",
            "03:21:29 |     batchsize: 12\n",
            "03:21:29 |     beam_block_full_context: False\n",
            "03:21:29 |     beam_block_list_filename: None\n",
            "03:21:29 |     beam_block_ngram: 3\n",
            "03:21:29 |     beam_context_block_ngram: 3\n",
            "03:21:29 |     beam_delay: 30\n",
            "03:21:29 |     beam_length_penalty: 0.65\n",
            "03:21:29 |     beam_min_length: 20\n",
            "03:21:29 |     beam_size: 10\n",
            "03:21:29 |     betas: '[0.9, 0.999]'\n",
            "03:21:29 |     bpe_add_prefix_space: None\n",
            "03:21:29 |     bpe_debug: False\n",
            "03:21:29 |     bpe_dropout: None\n",
            "03:21:29 |     bpe_merge: None\n",
            "03:21:29 |     bpe_vocab: None\n",
            "03:21:29 |     compute_tokenized_bleu: False\n",
            "03:21:29 |     datapath: \"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning\"\n",
            "03:21:29 |     datatype: valid\n",
            "03:21:29 |     delimiter: '\\n'\n",
            "03:21:29 |     dict_class: parlai.core.dict:DictionaryAgent\n",
            "03:21:29 |     dict_endtoken: __end__\n",
            "03:21:29 |     dict_file: \"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/models/blender/blender_90M/model.dict\"\n",
            "03:21:29 |     dict_include_test: False\n",
            "03:21:29 |     dict_include_valid: False\n",
            "03:21:29 |     dict_initpath: None\n",
            "03:21:29 |     dict_language: english\n",
            "03:21:29 |     dict_loaded: True\n",
            "03:21:29 |     dict_lower: True\n",
            "03:21:29 |     dict_max_ngram_size: -1\n",
            "03:21:29 |     dict_maxexs: -1\n",
            "03:21:29 |     dict_maxtokens: -1\n",
            "03:21:29 |     dict_minfreq: 0\n",
            "03:21:29 |     dict_nulltoken: __null__\n",
            "03:21:29 |     dict_starttoken: __start__\n",
            "03:21:29 |     dict_textfields: text,labels\n",
            "03:21:29 |     dict_tokenizer: bpe\n",
            "03:21:29 |     dict_unktoken: __unk__\n",
            "03:21:29 |     display_examples: False\n",
            "03:21:29 |     download_path: None\n",
            "03:21:29 |     dropout: 0.1\n",
            "03:21:29 |     dynamic_batching: None\n",
            "03:21:29 |     embedding_projection: random\n",
            "03:21:29 |     embedding_size: 512\n",
            "03:21:29 |     embedding_type: random\n",
            "03:21:29 |     embeddings_scale: True\n",
            "03:21:29 |     eval_batchsize: None\n",
            "03:21:29 |     evaltask: None\n",
            "03:21:29 |     ffn_size: 2048\n",
            "03:21:29 |     force_fp16_tokens: True\n",
            "03:21:29 |     fp16: True\n",
            "03:21:29 |     fp16_impl: safe\n",
            "03:21:29 |     gpu: -1\n",
            "03:21:29 |     gradient_clip: 0.1\n",
            "03:21:29 |     hide_labels: False\n",
            "03:21:29 |     history_add_global_end_token: None\n",
            "03:21:29 |     history_reversed: False\n",
            "03:21:29 |     history_size: -1\n",
            "03:21:29 |     image_cropsize: 224\n",
            "03:21:29 |     image_mode: raw\n",
            "03:21:29 |     image_size: 256\n",
            "03:21:29 |     include_checked_sentence: True\n",
            "03:21:29 |     include_knowledge: True\n",
            "03:21:29 |     include_knowledge_separator: False\n",
            "03:21:29 |     inference: beam\n",
            "03:21:29 |     init_model: /checkpoint/parlai/zoo/new_reddit/newreddit_trained20190909_usedfordodeca/model\n",
            "03:21:29 |     init_opt: None\n",
            "03:21:29 |     interactive_mode: False\n",
            "03:21:29 |     invsqrt_lr_decay_gamma: -1\n",
            "03:21:29 |     label_truncate: 128\n",
            "03:21:29 |     label_type: response\n",
            "03:21:29 |     learn_positional_embeddings: True\n",
            "03:21:29 |     learningrate: 7.5e-06\n",
            "03:21:29 |     log_every_n_secs: 2\n",
            "03:21:29 |     log_keep_fields: all\n",
            "03:21:29 |     loglevel: info\n",
            "03:21:29 |     lr_scheduler: reduceonplateau\n",
            "03:21:29 |     lr_scheduler_decay: 0.5\n",
            "03:21:29 |     lr_scheduler_patience: 3\n",
            "03:21:29 |     max_lr_steps: -1\n",
            "03:21:29 |     max_train_time: -1\n",
            "03:21:29 |     metrics: ppl,bleu-4\n",
            "03:21:29 |     model: transformer/generator\n",
            "03:21:29 |     model_file: \"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/models/blender/blender_90M/model\"\n",
            "03:21:29 |     model_parallel: False\n",
            "03:21:29 |     momentum: 0\n",
            "03:21:29 |     multitask_weights: '[1.0, 3.0, 3.0, 3.0]'\n",
            "03:21:29 |     mutators: None\n",
            "03:21:29 |     n_decoder_layers: -1\n",
            "03:21:29 |     n_encoder_layers: -1\n",
            "03:21:29 |     n_heads: 16\n",
            "03:21:29 |     n_layers: 8\n",
            "03:21:29 |     n_positions: 512\n",
            "03:21:29 |     n_segments: 0\n",
            "03:21:29 |     nesterov: True\n",
            "03:21:29 |     no_cuda: False\n",
            "03:21:29 |     num_epochs: -1\n",
            "03:21:29 |     num_examples: -1\n",
            "03:21:29 |     num_topics: 5\n",
            "03:21:29 |     numthreads: 1\n",
            "03:21:29 |     nus: [0.7]\n",
            "03:21:29 |     optimizer: adamax\n",
            "03:21:29 |     output_scaling: 1.0\n",
            "03:21:29 |     override: '{\\'datatype\\': \\'valid\\', \\'task\\': \\'custom_train\\', \\'model_file\\': \"/content/drive/My Drive/Master\\'s Thesis/Blenderbot Transfer Learning/models/blender/blender_90M/model\", \\'report_filename\\': \"/content/drive/My Drive/Master\\'s Thesis/Blenderbot Transfer Learning/evaluations/baseline_custom_data_train.json\", \\'metrics\\': \\'ppl,bleu-4\\', \\'skip_generation\\': False, \\'batchsize\\': 12}'\n",
            "03:21:29 |     parlai_home: /private/home/edinan/ParlAI\n",
            "03:21:29 |     person_tokens: False\n",
            "03:21:29 |     rank_candidates: False\n",
            "03:21:29 |     relu_dropout: 0.0\n",
            "03:21:29 |     report_filename: \"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/evaluations/baseline_custom_data_train.json\"\n",
            "03:21:29 |     save_after_valid: True\n",
            "03:21:29 |     save_every_n_secs: 60.0\n",
            "03:21:29 |     save_format: conversations\n",
            "03:21:29 |     share_word_embeddings: True\n",
            "03:21:29 |     short_final_eval: False\n",
            "03:21:29 |     show_advanced_args: False\n",
            "03:21:29 |     skip_generation: False\n",
            "03:21:29 |     special_tok_lst: None\n",
            "03:21:29 |     split_lines: False\n",
            "03:21:29 |     starttime: Feb10_07-25\n",
            "03:21:29 |     task: custom_train\n",
            "03:21:29 |     temperature: 1.0\n",
            "03:21:29 |     tensorboard_log: False\n",
            "03:21:29 |     tensorboard_logdir: None\n",
            "03:21:29 |     text_truncate: 512\n",
            "03:21:29 |     topk: 10\n",
            "03:21:29 |     topp: 0.9\n",
            "03:21:29 |     train_experiencer_only: False\n",
            "03:21:29 |     truncate: -1\n",
            "03:21:29 |     update_freq: 1\n",
            "03:21:29 |     use_reply: label\n",
            "03:21:29 |     validation_cutoff: 1.0\n",
            "03:21:29 |     validation_every_n_epochs: 0.25\n",
            "03:21:29 |     validation_every_n_secs: -1\n",
            "03:21:29 |     validation_max_exs: 20000\n",
            "03:21:29 |     validation_metric: ppl\n",
            "03:21:29 |     validation_metric_mode: min\n",
            "03:21:29 |     validation_patience: 15\n",
            "03:21:29 |     validation_share_agent: False\n",
            "03:21:29 |     variant: xlm\n",
            "03:21:29 |     verbose: False\n",
            "03:21:29 |     warmup_rate: 0.0001\n",
            "03:21:29 |     warmup_updates: -1\n",
            "03:21:29 |     weight_decay: None\n",
            "03:21:29 |     world_logs: \n",
            "03:21:29 | Evaluating task custom_train using datatype valid.\n",
            "03:21:29 | creating task(s): custom_train\n",
            " ~~ Loading from blenderbot_processed_data_train.txt ~~ \n",
            "03:21:41 | 20.1% complete (72 / 359), 0:00:12 elapsed, 0:00:48 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc   tpb   tps\n",
            "      .02778   .0631 504.5 249.8 5.941   72 .1852   .07376 1.927 136.3 67.51 6.869      .5917 640.8 317.3\n",
            "03:21:51 | 33.4% complete (120 / 359), 0:00:22 elapsed, 0:00:44 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "      .01667  .03999 970.9 437.6 5.408  120 .1727   .09361 2.021 126.1 56.83 7.543      .5765 1097 494.4\n",
            "03:22:03 | 46.8% complete (168 / 359), 0:00:33 elapsed, 0:00:38 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "       .0119   .0416  1410 586.6 4.991  168 .1701    .1168 2.028 127.9 53.18 7.601      .5754 1538 639.8\n",
            "03:22:13 | 56.8% complete (204 / 359), 0:00:43 elapsed, 0:00:33 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "     .009804  .04066  1543 597.3 4.645  204 .1624    .1252 2.056 122.8 47.54 7.813      .5661 1666 644.8\n",
            "03:22:26 | 69.4% complete (249 / 359), 0:00:56 elapsed, 0:00:25 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "     .008032  .04135  1582 586.8 4.398  249 .1539    .1317 2.109 116.9 43.36 8.238      .5625 1699 630.2\n",
            "03:22:38 | 79.7% complete (286 / 359), 0:01:08 elapsed, 0:00:17 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "     .006993   .0360  1706 622.8 4.175  286 .1492    .1408 2.109 114.1 41.63 8.242      .5579 1821 664.4\n",
            "03:22:48 | 89.1% complete (320 / 359), 0:01:19 elapsed, 0:00:10 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "      .00625  .03218  1803 683.3 4.042  320 .1380    .1054 2.216 102.6 38.87 9.172      .5431 1906 722.2\n",
            "03:22:59 | 98.3% complete (353 / 359), 0:01:29 elapsed, 0:00:02 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "     .005666  .02917  1665 762.1 3.941  353 .1335   .09283 2.185 84.12 38.51 8.894      .5436 1749 800.7\n",
            "03:23:01 | Finished evaluating tasks ['custom_train'] using datatype valid\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "     .005571  .02868  1621 779.5 3.923  359 .1312   .04546 2.194 79.02 37.99 8.972      .5416 1700 817.5\n",
            "03:23:01 | Saving model report to /content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/evaluations/baseline_custom_data_train.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.005571030640668524,\n",
              " 'bleu-4': 0.028679724729061096,\n",
              " 'ctpb': 1621.2727272727273,\n",
              " 'ctps': 779.5141892473275,\n",
              " 'exps': 3.9228090006300467,\n",
              " 'exs': 359,\n",
              " 'f1': 0.13124423364290394,\n",
              " 'gpu_mem': 0.04546157851304621,\n",
              " 'loss': 2.1940916979967744,\n",
              " 'ltpb': 79.02272727272727,\n",
              " 'ltps': 37.99417423504419,\n",
              " 'ppl': 8.971848207055896,\n",
              " 'token_acc': 0.541558815070463,\n",
              " 'tpb': 1700.2954545454545,\n",
              " 'tps': 817.5087111894543}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fv3-S4HurKth"
      },
      "source": [
        "Evaluate transfer learning model on custom dataset test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tm7cWh7vrQr1",
        "outputId": "e2d611ef-eb50-4f5d-d837-aae735f84d8d"
      },
      "source": [
        "EvalModel.main(\n",
        "    task='custom_test',\n",
        "    mf=\"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/from_pretrained/model\",\n",
        "    rf=\"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/evaluations/transfer_learning_custom_data_test.json\",\n",
        "    metrics=['ppl', 'bleu-4'],\n",
        "    skip_generation=False,\n",
        "    batchsize=12,\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "03:23:08 | \u001b[33mOverriding opt[\"datatype\"] to valid (previously: train)\u001b[0m\n",
            "03:23:08 | \u001b[33mOverriding opt[\"task\"] to custom_test (previously: custom_train)\u001b[0m\n",
            "03:23:08 | \u001b[33mOverriding opt[\"model_file\"] to /content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/from_pretrained/model (previously: from_pretrained/model)\u001b[0m\n",
            "03:23:08 | \u001b[33mOverriding opt[\"metrics\"] to ppl,bleu-4 (previously: default)\u001b[0m\n",
            "03:23:08 | \u001b[33mOverriding opt[\"skip_generation\"] to False (previously: True)\u001b[0m\n",
            "03:23:08 | Using CUDA\n",
            "03:23:08 | loading dictionary from /content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/from_pretrained/model.dict\n",
            "03:23:08 | num words = 54944\n",
            "03:23:09 | Total parameters: 87,508,992 (87,508,992 trainable)\n",
            "03:23:09 | Loading existing model params from /content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/from_pretrained/model\n",
            "03:23:12 | Opt:\n",
            "03:23:12 |     activation: gelu\n",
            "03:23:12 |     adafactor_eps: '[1e-30, 0.001]'\n",
            "03:23:12 |     adam_eps: 1e-08\n",
            "03:23:12 |     add_p1_after_newln: False\n",
            "03:23:12 |     aggregate_micro: False\n",
            "03:23:12 |     allow_missing_init_opts: False\n",
            "03:23:12 |     attention_dropout: 0.0\n",
            "03:23:12 |     batchsize: 12\n",
            "03:23:12 |     beam_block_full_context: True\n",
            "03:23:12 |     beam_block_list_filename: None\n",
            "03:23:12 |     beam_block_ngram: -1\n",
            "03:23:12 |     beam_context_block_ngram: -1\n",
            "03:23:12 |     beam_delay: 30\n",
            "03:23:12 |     beam_length_penalty: 0.65\n",
            "03:23:12 |     beam_min_length: 1\n",
            "03:23:12 |     beam_size: 1\n",
            "03:23:12 |     betas: '[0.9, 0.999]'\n",
            "03:23:12 |     bpe_add_prefix_space: None\n",
            "03:23:12 |     bpe_debug: False\n",
            "03:23:12 |     bpe_dropout: None\n",
            "03:23:12 |     bpe_merge: None\n",
            "03:23:12 |     bpe_vocab: None\n",
            "03:23:12 |     compute_tokenized_bleu: False\n",
            "03:23:12 |     datapath: \"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning\"\n",
            "03:23:12 |     datatype: valid\n",
            "03:23:12 |     delimiter: '\\n'\n",
            "03:23:12 |     dict_class: parlai.core.dict:DictionaryAgent\n",
            "03:23:12 |     dict_endtoken: __end__\n",
            "03:23:12 |     dict_file: \"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/from_pretrained/model.dict\"\n",
            "03:23:12 |     dict_include_test: False\n",
            "03:23:12 |     dict_include_valid: False\n",
            "03:23:12 |     dict_initpath: None\n",
            "03:23:12 |     dict_language: english\n",
            "03:23:12 |     dict_loaded: True\n",
            "03:23:12 |     dict_lower: True\n",
            "03:23:12 |     dict_max_ngram_size: -1\n",
            "03:23:12 |     dict_maxexs: -1\n",
            "03:23:12 |     dict_maxtokens: -1\n",
            "03:23:12 |     dict_minfreq: 0\n",
            "03:23:12 |     dict_nulltoken: __null__\n",
            "03:23:12 |     dict_starttoken: __start__\n",
            "03:23:12 |     dict_textfields: text,labels\n",
            "03:23:12 |     dict_tokenizer: bpe\n",
            "03:23:12 |     dict_unktoken: __unk__\n",
            "03:23:12 |     display_examples: False\n",
            "03:23:12 |     download_path: None\n",
            "03:23:12 |     dropout: 0.0\n",
            "03:23:12 |     dynamic_batching: full\n",
            "03:23:12 |     embedding_projection: random\n",
            "03:23:12 |     embedding_size: 512\n",
            "03:23:12 |     embedding_type: random\n",
            "03:23:12 |     embeddings_scale: True\n",
            "03:23:12 |     eval_batchsize: None\n",
            "03:23:12 |     eval_dynamic_batching: None\n",
            "03:23:12 |     evaltask: None\n",
            "03:23:12 |     ffn_size: 2048\n",
            "03:23:12 |     force_fp16_tokens: True\n",
            "03:23:12 |     fp16: True\n",
            "03:23:12 |     fp16_impl: mem_efficient\n",
            "03:23:12 |     gpu: -1\n",
            "03:23:12 |     gradient_clip: 0.1\n",
            "03:23:12 |     hide_labels: False\n",
            "03:23:12 |     history_add_global_end_token: None\n",
            "03:23:12 |     history_reversed: False\n",
            "03:23:12 |     history_size: -1\n",
            "03:23:12 |     image_cropsize: 224\n",
            "03:23:12 |     image_mode: raw\n",
            "03:23:12 |     image_size: 256\n",
            "03:23:12 |     inference: greedy\n",
            "03:23:12 |     init_model: \"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/models/blender/blender_90M/model\"\n",
            "03:23:12 |     init_opt: None\n",
            "03:23:12 |     interactive_mode: False\n",
            "03:23:12 |     invsqrt_lr_decay_gamma: -1\n",
            "03:23:12 |     label_truncate: 128\n",
            "03:23:12 |     learn_positional_embeddings: True\n",
            "03:23:12 |     learningrate: 1e-05\n",
            "03:23:12 |     log_every_n_secs: 10\n",
            "03:23:12 |     log_keep_fields: all\n",
            "03:23:12 |     loglevel: info\n",
            "03:23:12 |     lr_scheduler: reduceonplateau\n",
            "03:23:12 |     lr_scheduler_decay: 0.5\n",
            "03:23:12 |     lr_scheduler_patience: 3\n",
            "03:23:12 |     max_lr_steps: -1\n",
            "03:23:12 |     max_train_time: 1200.0\n",
            "03:23:12 |     metrics: ppl,bleu-4\n",
            "03:23:12 |     model: transformer/generator\n",
            "03:23:12 |     model_file: \"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/from_pretrained/model\"\n",
            "03:23:12 |     model_parallel: False\n",
            "03:23:12 |     momentum: 0\n",
            "03:23:12 |     multitask_weights: [1]\n",
            "03:23:12 |     mutators: None\n",
            "03:23:12 |     n_decoder_layers: -1\n",
            "03:23:12 |     n_encoder_layers: -1\n",
            "03:23:12 |     n_heads: 16\n",
            "03:23:12 |     n_layers: 8\n",
            "03:23:12 |     n_positions: 512\n",
            "03:23:12 |     n_segments: 0\n",
            "03:23:12 |     nesterov: True\n",
            "03:23:12 |     no_cuda: False\n",
            "03:23:12 |     num_epochs: -1\n",
            "03:23:12 |     num_examples: -1\n",
            "03:23:12 |     nus: [0.7]\n",
            "03:23:12 |     optimizer: mem_eff_adam\n",
            "03:23:12 |     output_scaling: 1.0\n",
            "03:23:12 |     override: '{\\'datatype\\': \\'valid\\', \\'task\\': \\'custom_test\\', \\'model_file\\': \"/content/drive/My Drive/Master\\'s Thesis/Blenderbot Transfer Learning/from_pretrained/model\", \\'report_filename\\': \"/content/drive/My Drive/Master\\'s Thesis/Blenderbot Transfer Learning/evaluations/transfer_learning_custom_data_test.json\", \\'metrics\\': \\'ppl,bleu-4\\', \\'skip_generation\\': False, \\'batchsize\\': 12}'\n",
            "03:23:12 |     parlai_home: /usr/local/lib/python3.7/dist-packages\n",
            "03:23:12 |     person_tokens: False\n",
            "03:23:12 |     rank_candidates: False\n",
            "03:23:12 |     relu_dropout: 0.0\n",
            "03:23:12 |     report_filename: \"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/evaluations/transfer_learning_custom_data_test.json\"\n",
            "03:23:12 |     save_after_valid: False\n",
            "03:23:12 |     save_every_n_secs: -1\n",
            "03:23:12 |     save_format: conversations\n",
            "03:23:12 |     share_word_embeddings: True\n",
            "03:23:12 |     short_final_eval: False\n",
            "03:23:12 |     skip_generation: False\n",
            "03:23:12 |     special_tok_lst: None\n",
            "03:23:12 |     split_lines: False\n",
            "03:23:12 |     starttime: Apr17_02-44\n",
            "03:23:12 |     task: custom_test\n",
            "03:23:12 |     temperature: 1.0\n",
            "03:23:12 |     tensorboard_log: False\n",
            "03:23:12 |     tensorboard_logdir: None\n",
            "03:23:12 |     text_truncate: 512\n",
            "03:23:12 |     topk: 10\n",
            "03:23:12 |     topp: 0.9\n",
            "03:23:12 |     truncate: -1\n",
            "03:23:12 |     update_freq: 1\n",
            "03:23:12 |     use_reply: label\n",
            "03:23:12 |     validation_cutoff: 1.0\n",
            "03:23:12 |     validation_every_n_epochs: 0.25\n",
            "03:23:12 |     validation_every_n_secs: -1\n",
            "03:23:12 |     validation_max_exs: -1\n",
            "03:23:12 |     validation_metric: ppl\n",
            "03:23:12 |     validation_metric_mode: None\n",
            "03:23:12 |     validation_patience: 10\n",
            "03:23:12 |     validation_share_agent: False\n",
            "03:23:12 |     variant: xlm\n",
            "03:23:12 |     verbose: False\n",
            "03:23:12 |     wandb_log: False\n",
            "03:23:12 |     wandb_name: None\n",
            "03:23:12 |     wandb_project: None\n",
            "03:23:12 |     warmup_rate: 0.0001\n",
            "03:23:12 |     warmup_updates: 100\n",
            "03:23:12 |     weight_decay: None\n",
            "03:23:12 |     world_logs: \n",
            "03:23:12 | Evaluating task custom_test using datatype valid.\n",
            "03:23:12 | creating task(s): custom_test\n",
            " ~~ Loading from blenderbot_processed_data_test.txt ~~ \n",
            "03:23:14 | Finished evaluating tasks ['custom_test'] using datatype valid\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc   tpb  tps\n",
            "      .06667   .1589 182.6  1028 24.12   30 .3007   .03679 1.286 58.29 328.1 3.619      .6961 240.9 1356\n",
            "03:23:14 | Saving model report to /content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/evaluations/transfer_learning_custom_data_test.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.06666666666666667,\n",
              " 'bleu-4': 0.15890172930836063,\n",
              " 'ctpb': 182.57142857142858,\n",
              " 'ctps': 1027.8508907636246,\n",
              " 'exps': 24.118899742650708,\n",
              " 'exs': 30,\n",
              " 'f1': 0.3006709197235514,\n",
              " 'gpu_mem': 0.036793586560416286,\n",
              " 'loss': 1.2861180305480957,\n",
              " 'ltpb': 58.285714285714285,\n",
              " 'ltps': 328.08508053755094,\n",
              " 'ppl': 3.618711526410578,\n",
              " 'token_acc': 0.696078431372549,\n",
              " 'tpb': 240.85714285714286,\n",
              " 'tps': 1356.0160430145465}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TooI-VqqrRJr"
      },
      "source": [
        "Evaluate baseline model on custom dataset test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ira4W3QqrVKO",
        "outputId": "cff69a91-53b7-4872-b4bb-dabff2307c62"
      },
      "source": [
        "EvalModel.main(\n",
        "    task='custom_test',\n",
        "    mf=\"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/models/blender/blender_90M/model\",\n",
        "    rf=\"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/evaluations/baseline_custom_data_test.json\",\n",
        "    metrics=['ppl', 'bleu-4'],\n",
        "    skip_generation=False,\n",
        "    batchsize=12,\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "03:23:20 | \u001b[33mOverriding opt[\"datatype\"] to valid (previously: train)\u001b[0m\n",
            "03:23:20 | \u001b[33mOverriding opt[\"task\"] to custom_test (previously: internal:blended_skill_talk,wizard_of_wikipedia,convai2,empathetic_dialogues)\u001b[0m\n",
            "03:23:20 | \u001b[33mOverriding opt[\"model_file\"] to /content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/models/blender/blender_90M/model (previously: /checkpoint/edinan/20200210/baseline_BST_retnref/lr=7.5e-06_attention-dropout=0.0_relu-dropout=0.0/model)\u001b[0m\n",
            "03:23:20 | \u001b[33mOverriding opt[\"metrics\"] to ppl,bleu-4 (previously: default)\u001b[0m\n",
            "03:23:20 | \u001b[33mOverriding opt[\"batchsize\"] to 12 (previously: 16)\u001b[0m\n",
            "03:23:20 | Using CUDA\n",
            "03:23:20 | loading dictionary from /content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/models/blender/blender_90M/model.dict\n",
            "03:23:20 | num words = 54944\n",
            "03:23:22 | Total parameters: 87,508,992 (87,508,992 trainable)\n",
            "03:23:22 | Loading existing model params from /content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/models/blender/blender_90M/model\n",
            "03:23:22 | Opt:\n",
            "03:23:22 |     activation: gelu\n",
            "03:23:22 |     adafactor_eps: '[1e-30, 0.001]'\n",
            "03:23:22 |     adam_eps: 1e-08\n",
            "03:23:22 |     add_p1_after_newln: False\n",
            "03:23:22 |     aggregate_micro: False\n",
            "03:23:22 |     allow_missing_init_opts: False\n",
            "03:23:22 |     attention_dropout: 0.0\n",
            "03:23:22 |     batchsize: 12\n",
            "03:23:22 |     beam_block_full_context: False\n",
            "03:23:22 |     beam_block_list_filename: None\n",
            "03:23:22 |     beam_block_ngram: 3\n",
            "03:23:22 |     beam_context_block_ngram: 3\n",
            "03:23:22 |     beam_delay: 30\n",
            "03:23:22 |     beam_length_penalty: 0.65\n",
            "03:23:22 |     beam_min_length: 20\n",
            "03:23:22 |     beam_size: 10\n",
            "03:23:22 |     betas: '[0.9, 0.999]'\n",
            "03:23:22 |     bpe_add_prefix_space: None\n",
            "03:23:22 |     bpe_debug: False\n",
            "03:23:22 |     bpe_dropout: None\n",
            "03:23:22 |     bpe_merge: None\n",
            "03:23:22 |     bpe_vocab: None\n",
            "03:23:22 |     compute_tokenized_bleu: False\n",
            "03:23:22 |     datapath: \"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning\"\n",
            "03:23:22 |     datatype: valid\n",
            "03:23:22 |     delimiter: '\\n'\n",
            "03:23:22 |     dict_class: parlai.core.dict:DictionaryAgent\n",
            "03:23:22 |     dict_endtoken: __end__\n",
            "03:23:22 |     dict_file: \"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/models/blender/blender_90M/model.dict\"\n",
            "03:23:22 |     dict_include_test: False\n",
            "03:23:22 |     dict_include_valid: False\n",
            "03:23:22 |     dict_initpath: None\n",
            "03:23:22 |     dict_language: english\n",
            "03:23:22 |     dict_loaded: True\n",
            "03:23:22 |     dict_lower: True\n",
            "03:23:22 |     dict_max_ngram_size: -1\n",
            "03:23:22 |     dict_maxexs: -1\n",
            "03:23:22 |     dict_maxtokens: -1\n",
            "03:23:22 |     dict_minfreq: 0\n",
            "03:23:22 |     dict_nulltoken: __null__\n",
            "03:23:22 |     dict_starttoken: __start__\n",
            "03:23:22 |     dict_textfields: text,labels\n",
            "03:23:22 |     dict_tokenizer: bpe\n",
            "03:23:22 |     dict_unktoken: __unk__\n",
            "03:23:22 |     display_examples: False\n",
            "03:23:22 |     download_path: None\n",
            "03:23:22 |     dropout: 0.1\n",
            "03:23:22 |     dynamic_batching: None\n",
            "03:23:22 |     embedding_projection: random\n",
            "03:23:22 |     embedding_size: 512\n",
            "03:23:22 |     embedding_type: random\n",
            "03:23:22 |     embeddings_scale: True\n",
            "03:23:22 |     eval_batchsize: None\n",
            "03:23:22 |     evaltask: None\n",
            "03:23:22 |     ffn_size: 2048\n",
            "03:23:22 |     force_fp16_tokens: True\n",
            "03:23:22 |     fp16: True\n",
            "03:23:22 |     fp16_impl: safe\n",
            "03:23:22 |     gpu: -1\n",
            "03:23:22 |     gradient_clip: 0.1\n",
            "03:23:22 |     hide_labels: False\n",
            "03:23:22 |     history_add_global_end_token: None\n",
            "03:23:22 |     history_reversed: False\n",
            "03:23:22 |     history_size: -1\n",
            "03:23:22 |     image_cropsize: 224\n",
            "03:23:22 |     image_mode: raw\n",
            "03:23:22 |     image_size: 256\n",
            "03:23:22 |     include_checked_sentence: True\n",
            "03:23:22 |     include_knowledge: True\n",
            "03:23:22 |     include_knowledge_separator: False\n",
            "03:23:22 |     inference: beam\n",
            "03:23:22 |     init_model: /checkpoint/parlai/zoo/new_reddit/newreddit_trained20190909_usedfordodeca/model\n",
            "03:23:22 |     init_opt: None\n",
            "03:23:22 |     interactive_mode: False\n",
            "03:23:22 |     invsqrt_lr_decay_gamma: -1\n",
            "03:23:22 |     label_truncate: 128\n",
            "03:23:22 |     label_type: response\n",
            "03:23:22 |     learn_positional_embeddings: True\n",
            "03:23:22 |     learningrate: 7.5e-06\n",
            "03:23:22 |     log_every_n_secs: 2\n",
            "03:23:22 |     log_keep_fields: all\n",
            "03:23:22 |     loglevel: info\n",
            "03:23:22 |     lr_scheduler: reduceonplateau\n",
            "03:23:22 |     lr_scheduler_decay: 0.5\n",
            "03:23:22 |     lr_scheduler_patience: 3\n",
            "03:23:22 |     max_lr_steps: -1\n",
            "03:23:22 |     max_train_time: -1\n",
            "03:23:22 |     metrics: ppl,bleu-4\n",
            "03:23:22 |     model: transformer/generator\n",
            "03:23:22 |     model_file: \"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/models/blender/blender_90M/model\"\n",
            "03:23:22 |     model_parallel: False\n",
            "03:23:22 |     momentum: 0\n",
            "03:23:22 |     multitask_weights: '[1.0, 3.0, 3.0, 3.0]'\n",
            "03:23:22 |     mutators: None\n",
            "03:23:22 |     n_decoder_layers: -1\n",
            "03:23:22 |     n_encoder_layers: -1\n",
            "03:23:22 |     n_heads: 16\n",
            "03:23:22 |     n_layers: 8\n",
            "03:23:22 |     n_positions: 512\n",
            "03:23:22 |     n_segments: 0\n",
            "03:23:22 |     nesterov: True\n",
            "03:23:22 |     no_cuda: False\n",
            "03:23:22 |     num_epochs: -1\n",
            "03:23:22 |     num_examples: -1\n",
            "03:23:22 |     num_topics: 5\n",
            "03:23:22 |     numthreads: 1\n",
            "03:23:22 |     nus: [0.7]\n",
            "03:23:22 |     optimizer: adamax\n",
            "03:23:22 |     output_scaling: 1.0\n",
            "03:23:22 |     override: '{\\'datatype\\': \\'valid\\', \\'task\\': \\'custom_test\\', \\'model_file\\': \"/content/drive/My Drive/Master\\'s Thesis/Blenderbot Transfer Learning/models/blender/blender_90M/model\", \\'report_filename\\': \"/content/drive/My Drive/Master\\'s Thesis/Blenderbot Transfer Learning/evaluations/baseline_custom_data_test.json\", \\'metrics\\': \\'ppl,bleu-4\\', \\'skip_generation\\': False, \\'batchsize\\': 12}'\n",
            "03:23:22 |     parlai_home: /private/home/edinan/ParlAI\n",
            "03:23:22 |     person_tokens: False\n",
            "03:23:22 |     rank_candidates: False\n",
            "03:23:22 |     relu_dropout: 0.0\n",
            "03:23:22 |     report_filename: \"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/evaluations/baseline_custom_data_test.json\"\n",
            "03:23:22 |     save_after_valid: True\n",
            "03:23:22 |     save_every_n_secs: 60.0\n",
            "03:23:22 |     save_format: conversations\n",
            "03:23:22 |     share_word_embeddings: True\n",
            "03:23:22 |     short_final_eval: False\n",
            "03:23:22 |     show_advanced_args: False\n",
            "03:23:22 |     skip_generation: False\n",
            "03:23:22 |     special_tok_lst: None\n",
            "03:23:22 |     split_lines: False\n",
            "03:23:22 |     starttime: Feb10_07-25\n",
            "03:23:22 |     task: custom_test\n",
            "03:23:22 |     temperature: 1.0\n",
            "03:23:22 |     tensorboard_log: False\n",
            "03:23:22 |     tensorboard_logdir: None\n",
            "03:23:22 |     text_truncate: 512\n",
            "03:23:22 |     topk: 10\n",
            "03:23:22 |     topp: 0.9\n",
            "03:23:22 |     train_experiencer_only: False\n",
            "03:23:22 |     truncate: -1\n",
            "03:23:22 |     update_freq: 1\n",
            "03:23:22 |     use_reply: label\n",
            "03:23:22 |     validation_cutoff: 1.0\n",
            "03:23:22 |     validation_every_n_epochs: 0.25\n",
            "03:23:22 |     validation_every_n_secs: -1\n",
            "03:23:22 |     validation_max_exs: 20000\n",
            "03:23:22 |     validation_metric: ppl\n",
            "03:23:22 |     validation_metric_mode: min\n",
            "03:23:22 |     validation_patience: 15\n",
            "03:23:22 |     validation_share_agent: False\n",
            "03:23:22 |     variant: xlm\n",
            "03:23:22 |     verbose: False\n",
            "03:23:22 |     warmup_rate: 0.0001\n",
            "03:23:22 |     warmup_updates: -1\n",
            "03:23:22 |     weight_decay: None\n",
            "03:23:22 |     world_logs: \n",
            "03:23:23 | Evaluating task custom_test using datatype valid.\n",
            "03:23:23 | creating task(s): custom_test\n",
            " ~~ Loading from blenderbot_processed_data_test.txt ~~ \n",
            "03:23:29 | Finished evaluating tasks ['custom_test'] using datatype valid\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc   tpb   tps\n",
            "      .06667   .2117 182.6   205 4.812   30 .3730   .03679 1.345 58.29 65.45 3.838      .6569 240.9 270.5\n",
            "03:23:29 | Saving model report to /content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/evaluations/baseline_custom_data_test.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.06666666666666667,\n",
              " 'bleu-4': 0.21165797050188426,\n",
              " 'ctpb': 182.57142857142858,\n",
              " 'ctps': 205.01066247949777,\n",
              " 'exps': 4.8122323265487505,\n",
              " 'exs': 30,\n",
              " 'f1': 0.37303853494776057,\n",
              " 'gpu_mem': 0.036793586560416286,\n",
              " 'loss': 1.345064689131344,\n",
              " 'ltpb': 58.285714285714285,\n",
              " 'ltps': 65.44860736087425,\n",
              " 'ppl': 3.838434837584164,\n",
              " 'token_acc': 0.6568627450980392,\n",
              " 'tpb': 240.85714285714286,\n",
              " 'tps': 270.4602103254076}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWASj82-BzBX"
      },
      "source": [
        "Evaluate transfer learning model on blended_skill_talk validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNSD0ZZK9N1Z",
        "outputId": "88cadced-60f6-461a-f9e9-86afacf3a400"
      },
      "source": [
        "EvalModel.main(\n",
        "    task='blended_skill_talk',\n",
        "    mf=\"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/from_pretrained/model\",\n",
        "    rf=\"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/evaluations/transfer_learning_blended_skill_valid.json\",\n",
        "    dt='valid',\n",
        "    metrics=['ppl', 'bleu-4'],\n",
        "    skip_generation=False,\n",
        "    batchsize=12,\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "03:23:47 | \u001b[33mOverriding opt[\"datatype\"] to valid (previously: train)\u001b[0m\n",
            "03:23:47 | \u001b[33mOverriding opt[\"task\"] to blended_skill_talk (previously: custom_train)\u001b[0m\n",
            "03:23:47 | \u001b[33mOverriding opt[\"model_file\"] to /content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/from_pretrained/model (previously: from_pretrained/model)\u001b[0m\n",
            "03:23:47 | \u001b[33mOverriding opt[\"metrics\"] to ppl,bleu-4 (previously: default)\u001b[0m\n",
            "03:23:47 | \u001b[33mOverriding opt[\"skip_generation\"] to False (previously: True)\u001b[0m\n",
            "03:23:47 | Using CUDA\n",
            "03:23:47 | loading dictionary from /content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/from_pretrained/model.dict\n",
            "03:23:47 | num words = 54944\n",
            "03:23:49 | Total parameters: 87,508,992 (87,508,992 trainable)\n",
            "03:23:49 | Loading existing model params from /content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/from_pretrained/model\n",
            "03:23:51 | Opt:\n",
            "03:23:51 |     activation: gelu\n",
            "03:23:51 |     adafactor_eps: '[1e-30, 0.001]'\n",
            "03:23:51 |     adam_eps: 1e-08\n",
            "03:23:51 |     add_p1_after_newln: False\n",
            "03:23:51 |     aggregate_micro: False\n",
            "03:23:51 |     allow_missing_init_opts: False\n",
            "03:23:51 |     attention_dropout: 0.0\n",
            "03:23:51 |     batchsize: 12\n",
            "03:23:51 |     beam_block_full_context: True\n",
            "03:23:51 |     beam_block_list_filename: None\n",
            "03:23:51 |     beam_block_ngram: -1\n",
            "03:23:51 |     beam_context_block_ngram: -1\n",
            "03:23:51 |     beam_delay: 30\n",
            "03:23:51 |     beam_length_penalty: 0.65\n",
            "03:23:51 |     beam_min_length: 1\n",
            "03:23:51 |     beam_size: 1\n",
            "03:23:51 |     betas: '[0.9, 0.999]'\n",
            "03:23:51 |     bpe_add_prefix_space: None\n",
            "03:23:51 |     bpe_debug: False\n",
            "03:23:51 |     bpe_dropout: None\n",
            "03:23:51 |     bpe_merge: None\n",
            "03:23:51 |     bpe_vocab: None\n",
            "03:23:51 |     compute_tokenized_bleu: False\n",
            "03:23:51 |     datapath: \"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning\"\n",
            "03:23:51 |     datatype: valid\n",
            "03:23:51 |     delimiter: '\\n'\n",
            "03:23:51 |     dict_class: parlai.core.dict:DictionaryAgent\n",
            "03:23:51 |     dict_endtoken: __end__\n",
            "03:23:51 |     dict_file: \"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/from_pretrained/model.dict\"\n",
            "03:23:51 |     dict_include_test: False\n",
            "03:23:51 |     dict_include_valid: False\n",
            "03:23:51 |     dict_initpath: None\n",
            "03:23:51 |     dict_language: english\n",
            "03:23:51 |     dict_loaded: True\n",
            "03:23:51 |     dict_lower: True\n",
            "03:23:51 |     dict_max_ngram_size: -1\n",
            "03:23:51 |     dict_maxexs: -1\n",
            "03:23:51 |     dict_maxtokens: -1\n",
            "03:23:51 |     dict_minfreq: 0\n",
            "03:23:51 |     dict_nulltoken: __null__\n",
            "03:23:51 |     dict_starttoken: __start__\n",
            "03:23:51 |     dict_textfields: text,labels\n",
            "03:23:51 |     dict_tokenizer: bpe\n",
            "03:23:51 |     dict_unktoken: __unk__\n",
            "03:23:51 |     display_examples: False\n",
            "03:23:51 |     download_path: None\n",
            "03:23:51 |     dropout: 0.0\n",
            "03:23:51 |     dynamic_batching: full\n",
            "03:23:51 |     embedding_projection: random\n",
            "03:23:51 |     embedding_size: 512\n",
            "03:23:51 |     embedding_type: random\n",
            "03:23:51 |     embeddings_scale: True\n",
            "03:23:51 |     eval_batchsize: None\n",
            "03:23:51 |     eval_dynamic_batching: None\n",
            "03:23:51 |     evaltask: None\n",
            "03:23:51 |     ffn_size: 2048\n",
            "03:23:51 |     force_fp16_tokens: True\n",
            "03:23:51 |     fp16: True\n",
            "03:23:51 |     fp16_impl: mem_efficient\n",
            "03:23:51 |     gpu: -1\n",
            "03:23:51 |     gradient_clip: 0.1\n",
            "03:23:51 |     hide_labels: False\n",
            "03:23:51 |     history_add_global_end_token: None\n",
            "03:23:51 |     history_reversed: False\n",
            "03:23:51 |     history_size: -1\n",
            "03:23:51 |     image_cropsize: 224\n",
            "03:23:51 |     image_mode: raw\n",
            "03:23:51 |     image_size: 256\n",
            "03:23:51 |     inference: greedy\n",
            "03:23:51 |     init_model: \"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/models/blender/blender_90M/model\"\n",
            "03:23:51 |     init_opt: None\n",
            "03:23:51 |     interactive_mode: False\n",
            "03:23:51 |     invsqrt_lr_decay_gamma: -1\n",
            "03:23:51 |     label_truncate: 128\n",
            "03:23:51 |     learn_positional_embeddings: True\n",
            "03:23:51 |     learningrate: 1e-05\n",
            "03:23:51 |     log_every_n_secs: 10\n",
            "03:23:51 |     log_keep_fields: all\n",
            "03:23:51 |     loglevel: info\n",
            "03:23:51 |     lr_scheduler: reduceonplateau\n",
            "03:23:51 |     lr_scheduler_decay: 0.5\n",
            "03:23:51 |     lr_scheduler_patience: 3\n",
            "03:23:51 |     max_lr_steps: -1\n",
            "03:23:51 |     max_train_time: 1200.0\n",
            "03:23:51 |     metrics: ppl,bleu-4\n",
            "03:23:51 |     model: transformer/generator\n",
            "03:23:51 |     model_file: \"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/from_pretrained/model\"\n",
            "03:23:51 |     model_parallel: False\n",
            "03:23:51 |     momentum: 0\n",
            "03:23:51 |     multitask_weights: [1]\n",
            "03:23:51 |     mutators: None\n",
            "03:23:51 |     n_decoder_layers: -1\n",
            "03:23:51 |     n_encoder_layers: -1\n",
            "03:23:51 |     n_heads: 16\n",
            "03:23:51 |     n_layers: 8\n",
            "03:23:51 |     n_positions: 512\n",
            "03:23:51 |     n_segments: 0\n",
            "03:23:51 |     nesterov: True\n",
            "03:23:51 |     no_cuda: False\n",
            "03:23:51 |     num_epochs: -1\n",
            "03:23:51 |     num_examples: -1\n",
            "03:23:51 |     nus: [0.7]\n",
            "03:23:51 |     optimizer: mem_eff_adam\n",
            "03:23:51 |     output_scaling: 1.0\n",
            "03:23:51 |     override: '{\\'datatype\\': \\'valid\\', \\'task\\': \\'blended_skill_talk\\', \\'model_file\\': \"/content/drive/My Drive/Master\\'s Thesis/Blenderbot Transfer Learning/from_pretrained/model\", \\'report_filename\\': \"/content/drive/My Drive/Master\\'s Thesis/Blenderbot Transfer Learning/evaluations/transfer_learning_blended_skill_valid.json\", \\'metrics\\': \\'ppl,bleu-4\\', \\'skip_generation\\': False, \\'batchsize\\': 12}'\n",
            "03:23:51 |     parlai_home: /usr/local/lib/python3.7/dist-packages\n",
            "03:23:51 |     person_tokens: False\n",
            "03:23:51 |     rank_candidates: False\n",
            "03:23:51 |     relu_dropout: 0.0\n",
            "03:23:51 |     report_filename: \"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/evaluations/transfer_learning_blended_skill_valid.json\"\n",
            "03:23:51 |     save_after_valid: False\n",
            "03:23:51 |     save_every_n_secs: -1\n",
            "03:23:51 |     save_format: conversations\n",
            "03:23:51 |     share_word_embeddings: True\n",
            "03:23:51 |     short_final_eval: False\n",
            "03:23:51 |     skip_generation: False\n",
            "03:23:51 |     special_tok_lst: None\n",
            "03:23:51 |     split_lines: False\n",
            "03:23:51 |     starttime: Apr17_02-44\n",
            "03:23:51 |     task: blended_skill_talk\n",
            "03:23:51 |     temperature: 1.0\n",
            "03:23:51 |     tensorboard_log: False\n",
            "03:23:51 |     tensorboard_logdir: None\n",
            "03:23:51 |     text_truncate: 512\n",
            "03:23:51 |     topk: 10\n",
            "03:23:51 |     topp: 0.9\n",
            "03:23:51 |     truncate: -1\n",
            "03:23:51 |     update_freq: 1\n",
            "03:23:51 |     use_reply: label\n",
            "03:23:51 |     validation_cutoff: 1.0\n",
            "03:23:51 |     validation_every_n_epochs: 0.25\n",
            "03:23:51 |     validation_every_n_secs: -1\n",
            "03:23:51 |     validation_max_exs: -1\n",
            "03:23:51 |     validation_metric: ppl\n",
            "03:23:51 |     validation_metric_mode: None\n",
            "03:23:51 |     validation_patience: 10\n",
            "03:23:51 |     validation_share_agent: False\n",
            "03:23:51 |     variant: xlm\n",
            "03:23:51 |     verbose: False\n",
            "03:23:51 |     wandb_log: False\n",
            "03:23:51 |     wandb_name: None\n",
            "03:23:51 |     wandb_project: None\n",
            "03:23:51 |     warmup_rate: 0.0001\n",
            "03:23:51 |     warmup_updates: 100\n",
            "03:23:51 |     weight_decay: None\n",
            "03:23:51 |     world_logs: \n",
            "03:23:52 | Evaluating task blended_skill_talk using datatype valid.\n",
            "03:23:52 | creating task(s): blended_skill_talk\n",
            "03:23:52 | Loading ParlAI text data: /content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/blended_skill_talk/valid.txt\n",
            "03:24:04 | 5.3% complete (300 / 5,651), 0:00:10 elapsed, 0:03:05 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "           0 .003355  1842  4454 29.01  300 .1767   .03788 2.625 214.8 519.4 13.81      .4319 2057 4973\n",
            "03:24:14 | 10.4% complete (588 / 5,651), 0:00:20 elapsed, 0:02:56 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "           0 .001957  1885  4535 28.87  588 .1706   .03695 2.641 216.1 519.9 14.03      .4307 2101 5055\n",
            "03:24:24 | 14.4% complete (816 / 5,651), 0:00:30 elapsed, 0:03:02 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "           0 .003381  1895  4195 26.56  816 .1700    .0416 2.626 212.9 471.1 13.82      .4304 2108 4666\n",
            "03:24:34 | 19.5% complete (1,104 / 5,651), 0:00:41 elapsed, 0:02:49 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "           0 .002836  1905  4274 26.92 1104 .1653   .03915 2.653 213.3 478.5 14.19      .4283 2118 4753\n",
            "03:24:44 | 23.6% complete (1,332 / 5,651), 0:00:51 elapsed, 0:02:46 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "           0 .002818  1939  4214 26.08 1332 .1602   .04164 2.682 218.6   475 14.61      .4264 2158 4689\n",
            "03:24:55 | 28.0% complete (1,584 / 5,651), 0:01:01 elapsed, 0:02:38 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "           0 .002722  1906  4100 25.81 1584 .1591   .03683  2.68 212.6 457.4 14.59      .4264 2119 4557\n",
            "03:25:05 | 32.9% complete (1,860 / 5,651), 0:01:11 elapsed, 0:02:26 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "           0 .003444  1923  4172 26.03 1860 .1634   .04227 2.676 215.3 466.9 14.53      .4274 2138 4639\n",
            "03:25:15 | 37.6% complete (2,124 / 5,651), 0:01:21 elapsed, 0:02:16 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "           0 .003726  1941  4207 26.01 2124 .1652   .04424 2.671 216.9 470.2 14.46      .4294 2158 4677\n",
            "03:25:25 | 41.8% complete (2,364 / 5,651), 0:01:31 elapsed, 0:02:08 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "           0 .003594  1948  4177 25.73 2364 .1657   .04291  2.67 218.1 467.6 14.44      .4298 2166 4644\n",
            "03:25:35 | 46.5% complete (2,628 / 5,651), 0:01:42 elapsed, 0:01:58 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "           0 .003853  1970  4219  25.7 2628 .1661   .04922 2.673 221.3 474.1 14.48      .4293 2191 4693\n",
            "03:25:46 | 51.2% complete (2,892 / 5,651), 0:01:52 elapsed, 0:01:47 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "           0 .004521  1968  4216 25.71 2892 .1674   .03926 2.665 221.7 474.9 14.37      .4305 2189 4691\n",
            "03:25:56 | 55.4% complete (3,132 / 5,651), 0:02:02 elapsed, 0:01:39 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "           0 .004606  1962  4180 25.56 3132 .1676   .04098 2.666 221.6   472 14.38      .4310 2184 4652\n",
            "03:26:06 | 60.1% complete (3,396 / 5,651), 0:02:12 elapsed, 0:01:28 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "           0 .004828  1968  4193 25.56 3396 .1678   .04171 2.661 223.3 475.7 14.31      .4313 2192 4668\n",
            "03:26:16 | 64.8% complete (3,660 / 5,651), 0:02:22 elapsed, 0:01:18 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "           0 .004639  1975  4213  25.6 3660 .1675   .04027 2.661 224.2 478.2 14.31      .4314 2199 4692\n",
            "03:26:27 | 69.9% complete (3,948 / 5,651), 0:02:33 elapsed, 0:01:06 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps  ppl  token_acc  tpb  tps\n",
            "           0 .004471  1974  4233 25.73 3948 .1669   .04227 2.667 224.3 480.8 14.4      .4310 2199 4714\n",
            "03:26:37 | 75.0% complete (4,236 / 5,651), 0:02:43 elapsed, 0:00:55 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "    .0002361  .00461  1972  4256 25.91 4236 .1662   .03913 2.677   223 481.4 14.55      .4298 2195 4738\n",
            "03:26:47 | 80.1% complete (4,524 / 5,651), 0:02:53 elapsed, 0:00:43 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "     .000221 .004693  1971  4277 26.03 4524 .1659   .04164 2.679 222.3 482.2 14.58      .4297 2194 4759\n",
            "03:26:57 | 84.3% complete (4,764 / 5,651), 0:03:03 elapsed, 0:00:34 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "    .0002099 .004546  1969  4249  25.9 4764 .1657   .03857 2.683 221.9 478.9 14.63      .4290 2191 4728\n",
            "03:27:07 | 89.4% complete (5,052 / 5,651), 0:03:14 elapsed, 0:00:23 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "    .0001979 .004554  1967  4264 26.02 5052 .1656   .04099 2.689 221.2 479.5 14.72      .4281 2188 4743\n",
            "03:27:18 | 94.7% complete (5,352 / 5,651), 0:03:24 elapsed, 0:00:11 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "    .0001868 .004855  1958  4269 26.17 5352 .1664   .03848 2.682 219.4 478.3 14.62      .4294 2177 4748\n",
            "03:27:28 | 99.9% complete (5,648 / 5,651), 0:03:34 elapsed, 0:00:00 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "    .0001771 .004735  1946  4279 26.31 5648 .1662   .03917 2.682 217.2 477.5 14.61      .4297 2163 4757\n",
            "03:27:28 | Finished evaluating tasks ['blended_skill_talk'] using datatype valid\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "     .000177 .004733  1943  4278  26.3 5651 .1661   .02482 2.682 216.8 477.2 14.61      .4298 2160 4755\n",
            "03:27:28 | Saving model report to /content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/evaluations/transfer_learning_blended_skill_valid.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.00017695983011856308,\n",
              " 'bleu-4': 0.004732747515860061,\n",
              " 'ctpb': 1943.4841437632135,\n",
              " 'ctps': 4278.053462520065,\n",
              " 'exps': 26.29836606165676,\n",
              " 'exs': 5651,\n",
              " 'f1': 0.16613615677245736,\n",
              " 'gpu_mem': 0.024824034874005196,\n",
              " 'loss': 2.681960397027542,\n",
              " 'ltpb': 216.7864693446089,\n",
              " 'ltps': 477.19648139160444,\n",
              " 'ppl': 14.61371391414582,\n",
              " 'token_acc': 0.42975424224692804,\n",
              " 'tpb': 2160.2706131078226,\n",
              " 'tps': 4755.250436209394}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3X6KMZ2B4EO"
      },
      "source": [
        "Evaluate baseline model on blended_skill_talk validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jGhGQXa9NvF",
        "outputId": "8c66f35e-1257-4d3b-d423-a8602d97cd4c"
      },
      "source": [
        "EvalModel.main(\n",
        "    task='blended_skill_talk',\n",
        "    mf=\"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/models/blender/blender_90M/model\",\n",
        "    rf=\"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/evaluations/baseline_blended_skill_valid.json\",\n",
        "    dt='valid',\n",
        "    metrics=['ppl', 'bleu-4'],\n",
        "    skip_generation=False,\n",
        "    batchsize=12,\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "03:27:34 | \u001b[33mOverriding opt[\"datatype\"] to valid (previously: train)\u001b[0m\n",
            "03:27:34 | \u001b[33mOverriding opt[\"task\"] to blended_skill_talk (previously: internal:blended_skill_talk,wizard_of_wikipedia,convai2,empathetic_dialogues)\u001b[0m\n",
            "03:27:34 | \u001b[33mOverriding opt[\"model_file\"] to /content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/models/blender/blender_90M/model (previously: /checkpoint/edinan/20200210/baseline_BST_retnref/lr=7.5e-06_attention-dropout=0.0_relu-dropout=0.0/model)\u001b[0m\n",
            "03:27:34 | \u001b[33mOverriding opt[\"metrics\"] to ppl,bleu-4 (previously: default)\u001b[0m\n",
            "03:27:34 | \u001b[33mOverriding opt[\"batchsize\"] to 12 (previously: 16)\u001b[0m\n",
            "03:27:34 | Using CUDA\n",
            "03:27:34 | loading dictionary from /content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/models/blender/blender_90M/model.dict\n",
            "03:27:34 | num words = 54944\n",
            "03:27:36 | Total parameters: 87,508,992 (87,508,992 trainable)\n",
            "03:27:36 | Loading existing model params from /content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/models/blender/blender_90M/model\n",
            "03:27:36 | Opt:\n",
            "03:27:36 |     activation: gelu\n",
            "03:27:36 |     adafactor_eps: '[1e-30, 0.001]'\n",
            "03:27:36 |     adam_eps: 1e-08\n",
            "03:27:36 |     add_p1_after_newln: False\n",
            "03:27:36 |     aggregate_micro: False\n",
            "03:27:36 |     allow_missing_init_opts: False\n",
            "03:27:36 |     attention_dropout: 0.0\n",
            "03:27:36 |     batchsize: 12\n",
            "03:27:36 |     beam_block_full_context: False\n",
            "03:27:36 |     beam_block_list_filename: None\n",
            "03:27:36 |     beam_block_ngram: 3\n",
            "03:27:36 |     beam_context_block_ngram: 3\n",
            "03:27:36 |     beam_delay: 30\n",
            "03:27:36 |     beam_length_penalty: 0.65\n",
            "03:27:36 |     beam_min_length: 20\n",
            "03:27:36 |     beam_size: 10\n",
            "03:27:36 |     betas: '[0.9, 0.999]'\n",
            "03:27:36 |     bpe_add_prefix_space: None\n",
            "03:27:36 |     bpe_debug: False\n",
            "03:27:36 |     bpe_dropout: None\n",
            "03:27:36 |     bpe_merge: None\n",
            "03:27:36 |     bpe_vocab: None\n",
            "03:27:36 |     compute_tokenized_bleu: False\n",
            "03:27:36 |     datapath: \"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning\"\n",
            "03:27:36 |     datatype: valid\n",
            "03:27:36 |     delimiter: '\\n'\n",
            "03:27:36 |     dict_class: parlai.core.dict:DictionaryAgent\n",
            "03:27:36 |     dict_endtoken: __end__\n",
            "03:27:36 |     dict_file: \"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/models/blender/blender_90M/model.dict\"\n",
            "03:27:36 |     dict_include_test: False\n",
            "03:27:36 |     dict_include_valid: False\n",
            "03:27:36 |     dict_initpath: None\n",
            "03:27:36 |     dict_language: english\n",
            "03:27:36 |     dict_loaded: True\n",
            "03:27:36 |     dict_lower: True\n",
            "03:27:36 |     dict_max_ngram_size: -1\n",
            "03:27:36 |     dict_maxexs: -1\n",
            "03:27:36 |     dict_maxtokens: -1\n",
            "03:27:36 |     dict_minfreq: 0\n",
            "03:27:36 |     dict_nulltoken: __null__\n",
            "03:27:36 |     dict_starttoken: __start__\n",
            "03:27:36 |     dict_textfields: text,labels\n",
            "03:27:36 |     dict_tokenizer: bpe\n",
            "03:27:36 |     dict_unktoken: __unk__\n",
            "03:27:36 |     display_examples: False\n",
            "03:27:36 |     download_path: None\n",
            "03:27:36 |     dropout: 0.1\n",
            "03:27:36 |     dynamic_batching: None\n",
            "03:27:36 |     embedding_projection: random\n",
            "03:27:36 |     embedding_size: 512\n",
            "03:27:36 |     embedding_type: random\n",
            "03:27:36 |     embeddings_scale: True\n",
            "03:27:36 |     eval_batchsize: None\n",
            "03:27:36 |     evaltask: None\n",
            "03:27:36 |     ffn_size: 2048\n",
            "03:27:36 |     force_fp16_tokens: True\n",
            "03:27:36 |     fp16: True\n",
            "03:27:36 |     fp16_impl: safe\n",
            "03:27:36 |     gpu: -1\n",
            "03:27:36 |     gradient_clip: 0.1\n",
            "03:27:36 |     hide_labels: False\n",
            "03:27:36 |     history_add_global_end_token: None\n",
            "03:27:36 |     history_reversed: False\n",
            "03:27:36 |     history_size: -1\n",
            "03:27:36 |     image_cropsize: 224\n",
            "03:27:36 |     image_mode: raw\n",
            "03:27:36 |     image_size: 256\n",
            "03:27:36 |     include_checked_sentence: True\n",
            "03:27:36 |     include_knowledge: True\n",
            "03:27:36 |     include_knowledge_separator: False\n",
            "03:27:36 |     inference: beam\n",
            "03:27:36 |     init_model: /checkpoint/parlai/zoo/new_reddit/newreddit_trained20190909_usedfordodeca/model\n",
            "03:27:36 |     init_opt: None\n",
            "03:27:36 |     interactive_mode: False\n",
            "03:27:36 |     invsqrt_lr_decay_gamma: -1\n",
            "03:27:36 |     label_truncate: 128\n",
            "03:27:36 |     label_type: response\n",
            "03:27:36 |     learn_positional_embeddings: True\n",
            "03:27:36 |     learningrate: 7.5e-06\n",
            "03:27:36 |     log_every_n_secs: 2\n",
            "03:27:36 |     log_keep_fields: all\n",
            "03:27:36 |     loglevel: info\n",
            "03:27:36 |     lr_scheduler: reduceonplateau\n",
            "03:27:36 |     lr_scheduler_decay: 0.5\n",
            "03:27:36 |     lr_scheduler_patience: 3\n",
            "03:27:36 |     max_lr_steps: -1\n",
            "03:27:36 |     max_train_time: -1\n",
            "03:27:36 |     metrics: ppl,bleu-4\n",
            "03:27:36 |     model: transformer/generator\n",
            "03:27:36 |     model_file: \"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/models/blender/blender_90M/model\"\n",
            "03:27:36 |     model_parallel: False\n",
            "03:27:36 |     momentum: 0\n",
            "03:27:36 |     multitask_weights: '[1.0, 3.0, 3.0, 3.0]'\n",
            "03:27:36 |     mutators: None\n",
            "03:27:36 |     n_decoder_layers: -1\n",
            "03:27:36 |     n_encoder_layers: -1\n",
            "03:27:36 |     n_heads: 16\n",
            "03:27:36 |     n_layers: 8\n",
            "03:27:36 |     n_positions: 512\n",
            "03:27:36 |     n_segments: 0\n",
            "03:27:36 |     nesterov: True\n",
            "03:27:36 |     no_cuda: False\n",
            "03:27:36 |     num_epochs: -1\n",
            "03:27:36 |     num_examples: -1\n",
            "03:27:36 |     num_topics: 5\n",
            "03:27:36 |     numthreads: 1\n",
            "03:27:36 |     nus: [0.7]\n",
            "03:27:36 |     optimizer: adamax\n",
            "03:27:36 |     output_scaling: 1.0\n",
            "03:27:36 |     override: '{\\'datatype\\': \\'valid\\', \\'task\\': \\'blended_skill_talk\\', \\'model_file\\': \"/content/drive/My Drive/Master\\'s Thesis/Blenderbot Transfer Learning/models/blender/blender_90M/model\", \\'report_filename\\': \"/content/drive/My Drive/Master\\'s Thesis/Blenderbot Transfer Learning/evaluations/baseline_blended_skill_valid.json\", \\'metrics\\': \\'ppl,bleu-4\\', \\'skip_generation\\': False, \\'batchsize\\': 12}'\n",
            "03:27:36 |     parlai_home: /private/home/edinan/ParlAI\n",
            "03:27:36 |     person_tokens: False\n",
            "03:27:36 |     rank_candidates: False\n",
            "03:27:36 |     relu_dropout: 0.0\n",
            "03:27:36 |     report_filename: \"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/evaluations/baseline_blended_skill_valid.json\"\n",
            "03:27:36 |     save_after_valid: True\n",
            "03:27:36 |     save_every_n_secs: 60.0\n",
            "03:27:36 |     save_format: conversations\n",
            "03:27:36 |     share_word_embeddings: True\n",
            "03:27:36 |     short_final_eval: False\n",
            "03:27:36 |     show_advanced_args: False\n",
            "03:27:36 |     skip_generation: False\n",
            "03:27:36 |     special_tok_lst: None\n",
            "03:27:36 |     split_lines: False\n",
            "03:27:36 |     starttime: Feb10_07-25\n",
            "03:27:36 |     task: blended_skill_talk\n",
            "03:27:36 |     temperature: 1.0\n",
            "03:27:36 |     tensorboard_log: False\n",
            "03:27:36 |     tensorboard_logdir: None\n",
            "03:27:36 |     text_truncate: 512\n",
            "03:27:36 |     topk: 10\n",
            "03:27:36 |     topp: 0.9\n",
            "03:27:36 |     train_experiencer_only: False\n",
            "03:27:36 |     truncate: -1\n",
            "03:27:36 |     update_freq: 1\n",
            "03:27:36 |     use_reply: label\n",
            "03:27:36 |     validation_cutoff: 1.0\n",
            "03:27:36 |     validation_every_n_epochs: 0.25\n",
            "03:27:36 |     validation_every_n_secs: -1\n",
            "03:27:36 |     validation_max_exs: 20000\n",
            "03:27:36 |     validation_metric: ppl\n",
            "03:27:36 |     validation_metric_mode: min\n",
            "03:27:36 |     validation_patience: 15\n",
            "03:27:36 |     validation_share_agent: False\n",
            "03:27:36 |     variant: xlm\n",
            "03:27:36 |     verbose: False\n",
            "03:27:36 |     warmup_rate: 0.0001\n",
            "03:27:36 |     warmup_updates: -1\n",
            "03:27:36 |     weight_decay: None\n",
            "03:27:36 |     world_logs: \n",
            "03:27:37 | Evaluating task blended_skill_talk using datatype valid.\n",
            "03:27:37 | creating task(s): blended_skill_talk\n",
            "03:27:37 | Loading ParlAI text data: /content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/blended_skill_talk/valid.txt\n",
            "03:27:50 | 1.1% complete (60 / 5,651), 0:00:12 elapsed, 0:19:26 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "           0  .01262  1623 649.1 4.799   60 .2163    .1030 2.608 197.2 78.86 13.58      .4371 1820  728\n",
            "03:28:01 | 1.9% complete (108 / 5,651), 0:00:23 elapsed, 0:20:27 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps  ppl  token_acc  tpb   tps\n",
            "           0  .01408  1648 620.5 4.519  108 .2080    .1114 2.674 200.2  75.4 14.5      .4301 1848 695.9\n",
            "03:28:13 | 2.8% complete (156 / 5,651), 0:00:35 elapsed, 0:21:02 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0  .01149  1760 638.6 4.354  156 .1951    .1226 2.627 200.7 72.82 13.83      .4335 1961 711.5\n",
            "03:28:25 | 3.6% complete (204 / 5,651), 0:00:47 elapsed, 0:21:07 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps  ppl  token_acc  tpb   tps\n",
            "           0  .01298  1798 644.1 4.299  204 .1962    .1087  2.66 210.5 75.41 14.3      .4301 2008 719.5\n",
            "03:28:37 | 4.5% complete (252 / 5,651), 0:00:59 elapsed, 0:21:10 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0   .0112  1785 632.8 4.254  252 .1941    .1161 2.645 212.8 75.43 14.09      .4307 1998 708.3\n",
            "03:28:49 | 5.3% complete (300 / 5,651), 0:01:11 elapsed, 0:21:15 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .009938  1842 644.3 4.197  300 .1888    .1169  2.62 214.8 75.14 13.73      .4342 2057 719.5\n",
            "03:29:01 | 6.2% complete (348 / 5,651), 0:01:23 elapsed, 0:21:11 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .008567  1852   644 4.174  348 .1825    .1140 2.611 213.1 74.11 13.61      .4336 2065 718.1\n",
            "03:29:13 | 7.0% complete (396 / 5,651), 0:01:35 elapsed, 0:21:04 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0  .00808  1855 642.6 4.157  396 .1830    .1097 2.625 215.3 74.59 13.81      .4329 2070 717.2\n",
            "03:29:25 | 7.9% complete (444 / 5,651), 0:01:47 elapsed, 0:21:00 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007207  1885 649.5 4.134  444 .1822    .1167 2.613 217.1  74.8 13.64      .4334 2103 724.3\n",
            "03:29:37 | 8.7% complete (492 / 5,651), 0:01:59 elapsed, 0:20:53 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006748  1883 646.4 4.119  492 .1799    .1110 2.618 218.2  74.9 13.71      .4339 2102 721.3\n",
            "03:29:49 | 9.6% complete (540 / 5,651), 0:02:11 elapsed, 0:20:49 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "           0 .006413  1878 640.6 4.094  540 .1799    .1192 2.628 218.1  74.4 13.85      .4340 2096  715\n",
            "03:30:02 | 10.4% complete (588 / 5,651), 0:02:24 elapsed, 0:20:45 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006347  1885 638.8 4.066  588 .1771    .1179 2.636 216.1 73.24 13.96      .4318 2101 712.1\n",
            "03:30:14 | 11.3% complete (636 / 5,651), 0:02:36 elapsed, 0:20:37 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006383  1882   636 4.055  636 .1781    .1146 2.623 213.1 72.01 13.77      .4336 2095 708.1\n",
            "03:30:27 | 12.1% complete (684 / 5,651), 0:02:49 elapsed, 0:20:33 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006235  1876 629.8 4.028  684 .1784    .1236 2.623 212.7  71.4 13.78      .4338 2089 701.2\n",
            "03:30:40 | 13.0% complete (732 / 5,651), 0:03:02 elapsed, 0:20:27 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .005827  1891 631.8 4.009  732 .1766    .1345 2.619 211.6 70.71 13.72      .4338 2103 702.5\n",
            "03:30:51 | 13.8% complete (780 / 5,651), 0:03:14 elapsed, 0:20:12 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps  ppl  token_acc  tpb   tps\n",
            "           0 .006039  1898 635.9  4.02  780 .1791    .1105 2.618 213.1 71.41 13.7      .4327 2111 707.3\n",
            "03:31:04 | 14.7% complete (828 / 5,651), 0:03:26 elapsed, 0:20:02 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006388  1894 633.2 4.012  828 .1793    .1204 2.619 212.4 71.03 13.73      .4310 2106 704.2\n",
            "03:31:16 | 15.5% complete (876 / 5,651), 0:03:38 elapsed, 0:19:53 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006419  1904 635.2 4.004  876 .1780    .1221 2.621 211.5 70.57 13.75      .4316 2115 705.8\n",
            "03:31:28 | 16.4% complete (924 / 5,651), 0:03:50 elapsed, 0:19:40 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006085  1903 635.5 4.007  924 .1765    .1124 2.615 211.9 70.75 13.67      .4334 2115 706.3\n",
            "03:31:39 | 17.2% complete (972 / 5,651), 0:04:02 elapsed, 0:19:26 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006351  1890 632.2 4.014  972 .1773    .1086 2.612 212.2 70.96 13.62      .4338 2102 703.2\n",
            "03:31:52 | 18.0% complete (1,020 / 5,651), 0:04:14 elapsed, 0:19:15 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps  ppl  token_acc  tpb   tps\n",
            "           0 .006053  1893 632.7  4.01 1020 .1752    .1167 2.624 211.2 70.58 13.8      .4313 2105 703.3\n",
            "03:32:04 | 18.9% complete (1,068 / 5,651), 0:04:27 elapsed, 0:19:06 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .005924  1899 632.9     4 1068 .1765    .1247  2.63 212.1  70.7 13.87      .4308 2111 703.6\n",
            "03:32:15 | 19.5% complete (1,104 / 5,651), 0:04:37 elapsed, 0:19:04 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0  .00587  1905 631.1 3.975 1104 .1750    .1213 2.648 213.3 70.65 14.12      .4285 2118 701.7\n",
            "03:32:26 | 20.2% complete (1,140 / 5,651), 0:04:48 elapsed, 0:19:01 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .005685  1916   631 3.953 1140 .1746    .1344 2.663 214.9 70.78 14.34      .4273 2131 701.8\n",
            "03:32:39 | 21.0% complete (1,188 / 5,651), 0:05:01 elapsed, 0:18:53 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "           0 .005822  1917 629.3  3.94 1188 .1730    .1251 2.673 215.5 70.75 14.48      .4269 2132  700\n",
            "03:32:49 | 21.7% complete (1,224 / 5,651), 0:05:12 elapsed, 0:18:49 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .005709  1928 629.9 3.921 1224 .1720    .1275 2.677 215.9 70.56 14.54      .4267 2144 700.5\n",
            "03:33:00 | 22.3% complete (1,260 / 5,651), 0:05:22 elapsed, 0:18:44 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .005915  1928 627.7 3.906 1260 .1720    .1310 2.675 216.6 70.51 14.51      .4274 2145 698.2\n",
            "03:33:10 | 22.9% complete (1,296 / 5,651), 0:05:33 elapsed, 0:18:39 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "           0 .005985  1938 628.4 3.891 1296 .1721    .1327 2.672 217.6 70.54 14.47      .4276 2156  699\n",
            "03:33:20 | 23.6% complete (1,332 / 5,651), 0:05:43 elapsed, 0:18:33 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .005923  1939 627.2 3.881 1332 .1715    .1272 2.677 218.6  70.7 14.54      .4267 2158 697.9\n",
            "03:33:33 | 24.4% complete (1,380 / 5,651), 0:05:55 elapsed, 0:18:22 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .005879  1934 624.7 3.877 1380 .1703    .1178 2.677 216.8 70.05 14.55      .4272 2151 694.8\n",
            "03:33:43 | 25.3% complete (1,428 / 5,651), 0:06:06 elapsed, 0:18:02 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "           0 .005682  1920 624.2 3.901 1428 .1696   .08718 2.676 214.5 69.75 14.53      .4269 2135  694\n",
            "03:33:54 | 26.1% complete (1,476 / 5,651), 0:06:16 elapsed, 0:17:46 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps  ppl  token_acc  tpb   tps\n",
            "           0 .005656  1910 623.7 3.918 1476 .1689   .09389 2.681 214.4 70.01 14.6      .4259 2125 693.7\n",
            "03:34:06 | 27.0% complete (1,524 / 5,651), 0:06:28 elapsed, 0:17:33 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .005966  1909 623.7  3.92 1524 .1696    .1092 2.677 214.1 69.93 14.54      .4256 2123 693.6\n",
            "03:34:17 | 27.8% complete (1,572 / 5,651), 0:06:39 elapsed, 0:17:18 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps  ppl  token_acc  tpb   tps\n",
            "           0  .00616  1907 624.7 3.931 1572 .1697    .1076 2.674 212.7 69.68 14.5      .4264 2120 694.4\n",
            "03:34:29 | 28.7% complete (1,620 / 5,651), 0:06:51 elapsed, 0:17:05 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006048  1907 625.1 3.934 1620 .1697    .1074  2.68 212.5 69.67 14.58      .4259 2119 694.7\n",
            "03:34:41 | 29.5% complete (1,668 / 5,651), 0:07:03 elapsed, 0:16:51 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006301  1904   625  3.94 1668 .1702    .1140 2.675 212.3 69.71 14.52      .4262 2116 694.7\n",
            "03:34:53 | 30.4% complete (1,716 / 5,651), 0:07:15 elapsed, 0:16:39 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006484  1907 626.1 3.939 1716 .1707    .1202 2.677 213.1 69.96 14.55      .4263 2120 696.1\n",
            "03:35:06 | 31.2% complete (1,764 / 5,651), 0:07:28 elapsed, 0:16:29 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006399  1912 626.1 3.931 1764 .1714    .1268 2.678 214.1 70.14 14.56      .4269 2126 696.3\n",
            "03:35:17 | 31.9% complete (1,800 / 5,651), 0:07:39 elapsed, 0:16:23 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006271  1920 626.9 3.918 1800 .1719    .1377 2.675 214.5 70.02 14.51      .4274 2135 696.9\n",
            "03:35:27 | 32.5% complete (1,836 / 5,651), 0:07:49 elapsed, 0:16:16 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006316  1923 626.6 3.909 1836 .1724    .1235 2.669 215.5 70.21 14.42      .4279 2139 696.8\n",
            "03:35:38 | 33.1% complete (1,872 / 5,651), 0:08:00 elapsed, 0:16:11 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps  ppl  token_acc  tpb   tps\n",
            "           0 .006194  1923 623.9 3.894 1872 .1721    .1426 2.674 215.4  69.9 14.5      .4274 2138 693.8\n",
            "03:35:48 | 33.8% complete (1,908 / 5,651), 0:08:10 elapsed, 0:16:03 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006077  1927 624.4 3.888 1908 .1719    .1275 2.676 215.3 69.75 14.52      .4276 2143 694.1\n",
            "03:36:01 | 34.6% complete (1,956 / 5,651), 0:08:23 elapsed, 0:15:51 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006019  1926 623.5 3.884 1956 .1717    .1363 2.673 215.2 69.66 14.49      .4278 2141 693.2\n",
            "03:36:14 | 35.5% complete (2,004 / 5,651), 0:08:36 elapsed, 0:15:40 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps  ppl  token_acc  tpb   tps\n",
            "           0 .006144  1927 623.3 3.881 2004 .1725    .1163 2.667 215.2 69.61 14.4      .4291 2142 692.9\n",
            "03:36:26 | 36.3% complete (2,052 / 5,651), 0:08:49 elapsed, 0:15:28 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0  .00608  1933 624.7 3.878 2052 .1722    .1198  2.67 216.2 69.87 14.44      .4289 2149 694.6\n",
            "03:36:37 | 36.9% complete (2,088 / 5,651), 0:08:59 elapsed, 0:15:20 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006108  1934 623.9 3.871 2088 .1728    .1312 2.669 216.6 69.85 14.43      .4290 2151 693.7\n",
            "03:36:48 | 37.6% complete (2,124 / 5,651), 0:09:10 elapsed, 0:15:14 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "           0 .006004  1941 624.3  3.86 2124 .1730    .1391 2.667 216.9 69.76 14.39      .4295 2158  694\n",
            "03:37:00 | 38.4% complete (2,172 / 5,651), 0:09:23 elapsed, 0:15:02 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .005959  1942 624.3 3.858 2172 .1734    .1179 2.665 217.2 69.82 14.36      .4298 2159 694.2\n",
            "03:37:10 | 39.1% complete (2,208 / 5,651), 0:09:33 elapsed, 0:14:54 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .005937  1944 623.9 3.852 2208 .1732    .1234 2.665 217.2 69.72 14.36      .4292 2161 693.7\n",
            "03:37:24 | 39.9% complete (2,256 / 5,651), 0:09:46 elapsed, 0:14:42 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "           0 .006059  1943 623.2 3.848 2256 .1738    .1329 2.662 217.8 69.85 14.33      .4303 2161  693\n",
            "03:37:34 | 40.6% complete (2,292 / 5,651), 0:09:56 elapsed, 0:14:35 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .005963  1943   622 3.841 2292 .1735    .1391 2.664 217.5 69.62 14.35      .4296 2161 691.6\n",
            "03:37:46 | 41.4% complete (2,340 / 5,651), 0:10:09 elapsed, 0:14:22 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .005944  1949   624 3.842 2340 .1735    .1269 2.667   218 69.81 14.39      .4293 2167 693.8\n",
            "03:37:59 | 42.3% complete (2,388 / 5,651), 0:10:21 elapsed, 0:14:09 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .005983  1948 623.5 3.842 2388 .1738    .1156 2.668 218.7    70 14.41      .4291 2166 693.5\n",
            "03:38:10 | 42.9% complete (2,424 / 5,651), 0:10:32 elapsed, 0:14:02 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0  .00597  1951   623 3.831 2424 .1741    .1419 2.668 219.6  70.1 14.41      .4289 2171 693.1\n",
            "03:38:21 | 43.5% complete (2,460 / 5,651), 0:10:43 elapsed, 0:13:55 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps  ppl  token_acc  tpb   tps\n",
            "           0 .006063  1958 623.6 3.821 2460 .1745    .1544 2.667 220.4 70.17 14.4      .4290 2179 693.7\n",
            "03:38:34 | 44.4% complete (2,508 / 5,651), 0:10:56 elapsed, 0:13:43 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006368  1961 624.3  3.82 2508 .1750    .1151 2.666 220.9 70.33 14.38      .4297 2182 694.6\n",
            "03:38:44 | 45.0% complete (2,544 / 5,651), 0:11:07 elapsed, 0:13:35 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006278  1969 625.8 3.814 2544 .1747    .1338 2.668   221 70.23 14.41      .4298 2190 696.1\n",
            "03:38:58 | 45.9% complete (2,592 / 5,651), 0:11:20 elapsed, 0:13:23 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006162  1970 625.4  3.81 2592 .1746    .1385 2.668 221.3 70.28 14.41      .4298 2191 695.7\n",
            "03:39:10 | 46.7% complete (2,640 / 5,651), 0:11:33 elapsed, 0:13:10 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006118  1970 625.2 3.809 2640 .1748    .1292 2.668 221.3 70.25 14.41      .4293 2191 695.5\n",
            "03:39:23 | 47.6% complete (2,688 / 5,651), 0:11:45 elapsed, 0:12:58 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "           0 .006115  1968 624.7 3.809 2688 .1748    .1233 2.667 221.5  70.3 14.39      .4290 2189  695\n",
            "03:39:33 | 48.2% complete (2,724 / 5,651), 0:11:55 elapsed, 0:12:49 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006142  1969 624.4 3.806 2724 .1751    .1248 2.665   222 70.43 14.37      .4294 2191 694.8\n",
            "03:39:46 | 49.1% complete (2,772 / 5,651), 0:12:08 elapsed, 0:12:36 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "           0  .00616  1966 623.7 3.806 2772 .1752    .1247 2.663 221.8 70.35 14.35      .4298 2188  694\n",
            "03:39:58 | 49.9% complete (2,820 / 5,651), 0:12:20 elapsed, 0:12:23 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006235  1965 623.7 3.808 2820 .1749    .1125 2.663 221.3 70.22 14.34      .4299 2187 693.9\n",
            "03:40:10 | 50.8% complete (2,868 / 5,651), 0:12:32 elapsed, 0:12:11 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps  ppl  token_acc  tpb   tps\n",
            "           0 .006194  1967 624.5 3.809 2868 .1755    .1160  2.66 221.5  70.3 14.3      .4305 2189 694.8\n",
            "03:40:21 | 51.4% complete (2,904 / 5,651), 0:12:43 elapsed, 0:12:02 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps  ppl  token_acc  tpb   tps\n",
            "           0  .00617  1968 623.6 3.803 2904 .1754    .1274  2.66 221.7 70.28 14.3      .4305 2189 693.9\n",
            "03:40:33 | 52.2% complete (2,952 / 5,651), 0:12:55 elapsed, 0:11:49 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006234  1970 624.7 3.806 2952 .1757    .1114 2.659 221.8 70.34 14.28      .4309 2191 695.1\n",
            "03:40:46 | 53.1% complete (3,000 / 5,651), 0:13:08 elapsed, 0:11:37 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps  ppl  token_acc  tpb   tps\n",
            "           0 .006209  1969   624 3.803 3000 .1754    .1236 2.661 221.8 70.29 14.3      .4306 2191 694.3\n",
            "03:40:59 | 53.9% complete (3,048 / 5,651), 0:13:21 elapsed, 0:11:24 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006282  1968 623.6 3.803 3048 .1754    .1306 2.661 221.6 70.23 14.31      .4306 2189 693.8\n",
            "03:41:11 | 54.8% complete (3,096 / 5,651), 0:13:34 elapsed, 0:11:12 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006605  1965 622.9 3.803 3096 .1758    .1158 2.663 221.6 70.25 14.34      .4306 2187 693.1\n",
            "03:41:24 | 55.6% complete (3,144 / 5,651), 0:13:46 elapsed, 0:10:59 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps  ppl  token_acc  tpb   tps\n",
            "           0 .006504  1962 621.9 3.804 3144 .1757    .1231  2.66 221.6 70.26 14.3      .4309 2183 692.1\n",
            "03:41:36 | 56.5% complete (3,192 / 5,651), 0:13:58 elapsed, 0:10:46 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006647  1961 622.1 3.808 3192 .1759    .1085 2.661 221.8 70.37 14.31      .4308 2183 692.5\n",
            "03:41:46 | 57.1% complete (3,228 / 5,651), 0:14:08 elapsed, 0:10:37 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006664  1961 621.5 3.803 3228 .1761    .1328 2.658 222.1 70.38 14.27      .4312 2183 691.9\n",
            "03:41:59 | 58.0% complete (3,276 / 5,651), 0:14:22 elapsed, 0:10:25 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006739  1964   622   3.8 3276 .1766    .1228 2.655 222.2 70.37 14.22      .4314 2187 692.4\n",
            "03:42:10 | 58.6% complete (3,312 / 5,651), 0:14:32 elapsed, 0:10:16 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006715  1967 622.1 3.795 3312 .1768    .1352 2.654 222.6  70.4 14.21      .4316 2190 692.5\n",
            "03:42:21 | 59.2% complete (3,348 / 5,651), 0:14:44 elapsed, 0:10:08 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006694  1970 621.8 3.786 3348 .1768    .1320 2.656 223.1 70.39 14.24      .4314 2194 692.1\n",
            "03:42:34 | 60.1% complete (3,396 / 5,651), 0:14:56 elapsed, 0:09:56 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006749  1968 621.1 3.787 3396 .1767    .1244 2.656 223.3 70.47 14.23      .4316 2192 691.5\n",
            "03:42:47 | 60.9% complete (3,444 / 5,651), 0:15:09 elapsed, 0:09:43 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006805  1969 620.9 3.785 3444 .1768    .1140 2.657 223.5 70.47 14.25      .4315 2192 691.4\n",
            "03:42:58 | 61.6% complete (3,480 / 5,651), 0:15:20 elapsed, 0:09:34 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006734  1970 620.7  3.78 3480 .1764    .1250 2.657   224 70.58 14.25      .4315 2194 691.2\n",
            "03:43:11 | 62.4% complete (3,528 / 5,651), 0:15:33 elapsed, 0:09:22 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "           0 .006643  1973 621.3 3.779 3528 .1763    .1151 2.657 224.2 70.62 14.25      .4315 2197  692\n",
            "03:43:24 | 63.3% complete (3,576 / 5,651), 0:15:46 elapsed, 0:09:09 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006554  1975   622 3.779 3576 .1764    .1299 2.656 224.4 70.66 14.24      .4315 2200 692.6\n",
            "03:43:36 | 64.1% complete (3,624 / 5,651), 0:15:59 elapsed, 0:08:56 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006877  1975   622 3.779 3624 .1770    .1165 2.655 224.3 70.62 14.23      .4315 2199 692.6\n",
            "03:43:49 | 65.0% complete (3,672 / 5,651), 0:16:11 elapsed, 0:08:44 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006826  1975 621.9 3.779 3672 .1771    .1169 2.655 224.1 70.57 14.22      .4317 2199 692.5\n",
            "03:44:01 | 65.8% complete (3,720 / 5,651), 0:16:23 elapsed, 0:08:31 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006795  1973   622 3.782 3720 .1768    .1049 2.655 224.1 70.64 14.23      .4316 2198 692.7\n",
            "03:44:14 | 66.7% complete (3,768 / 5,651), 0:16:36 elapsed, 0:08:18 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006793  1973 621.5  3.78 3768 .1768    .1130 2.655   224 70.57 14.23      .4315 2197 692.1\n",
            "03:44:26 | 67.5% complete (3,816 / 5,651), 0:16:49 elapsed, 0:08:05 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006708  1968 620.3 3.782 3816 .1767    .1097 2.656 223.5 70.43 14.25      .4313 2192 690.8\n",
            "03:44:38 | 68.4% complete (3,864 / 5,651), 0:17:01 elapsed, 0:07:52 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006764  1969   621 3.784 3864 .1768    .1115 2.656 223.5 70.47 14.24      .4314 2193 691.5\n",
            "03:44:52 | 69.2% complete (3,912 / 5,651), 0:17:14 elapsed, 0:07:40 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006719  1973 621.6 3.781 3912 .1769    .1307  2.66 223.8 70.53 14.29      .4311 2197 692.1\n",
            "03:45:03 | 69.9% complete (3,948 / 5,651), 0:17:25 elapsed, 0:07:31 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "           0 .006658  1974 621.4 3.777 3948 .1768    .1353 2.662 224.3 70.58 14.32      .4310 2199  692\n",
            "03:45:15 | 70.7% complete (3,996 / 5,651), 0:17:37 elapsed, 0:07:18 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006578  1976 622.1 3.777 3996 .1766    .1248 2.665 224.4 70.63 14.37      .4306 2201 692.7\n",
            "03:45:27 | 71.6% complete (4,044 / 5,651), 0:17:50 elapsed, 0:07:05 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0   .0065  1973 621.5 3.779 4044 .1764    .1202 2.668 223.8  70.5 14.41      .4302 2197 691.9\n",
            "03:45:40 | 72.4% complete (4,092 / 5,651), 0:18:02 elapsed, 0:06:52 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006609  1972 621.2  3.78 4092 .1765    .1144 2.672 223.6 70.43 14.47      .4296 2196 691.6\n",
            "03:45:52 | 73.3% complete (4,140 / 5,651), 0:18:15 elapsed, 0:06:40 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006644  1972 621.1  3.78 4140 .1766    .1138 2.671 223.6 70.43 14.45      .4297 2195 691.6\n",
            "03:46:04 | 74.1% complete (4,188 / 5,651), 0:18:27 elapsed, 0:06:27 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006611  1970 621.1 3.783 4188 .1764    .1119 2.669 223.3  70.4 14.42      .4305 2194 691.5\n",
            "03:46:16 | 75.0% complete (4,236 / 5,651), 0:18:39 elapsed, 0:06:14 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006644  1972 621.9 3.785 4236 .1762    .1077 2.672   223 70.35 14.47      .4300 2195 692.3\n",
            "03:46:29 | 75.8% complete (4,284 / 5,651), 0:18:52 elapsed, 0:06:01 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps  ppl  token_acc  tpb  tps\n",
            "           0 .006737  1971 621.7 3.784 4284 .1761    .1337 2.674 222.8 70.26 14.5      .4298 2194  692\n",
            "03:46:41 | 76.7% complete (4,332 / 5,651), 0:19:04 elapsed, 0:05:48 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "           0 .006842  1971 621.8 3.786 4332 .1763    .1181 2.676 222.7 70.27 14.52      .4301 2193  692\n",
            "03:46:54 | 77.5% complete (4,380 / 5,651), 0:19:16 elapsed, 0:05:36 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps  ppl  token_acc  tpb   tps\n",
            "           0 .006907  1973 622.5 3.786 4380 .1764    .1166 2.674 222.9 70.31 14.5      .4302 2196 692.8\n",
            "03:47:06 | 78.4% complete (4,428 / 5,651), 0:19:28 elapsed, 0:05:23 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006928  1971 622.4 3.789 4428 .1765    .1144 2.673 222.6 70.28 14.49      .4303 2194 692.7\n",
            "03:47:18 | 79.2% complete (4,476 / 5,651), 0:19:40 elapsed, 0:05:10 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007007  1970 622.5 3.791 4476 .1766    .1186 2.673 222.4 70.26 14.49      .4301 2193 692.8\n",
            "03:47:30 | 80.1% complete (4,524 / 5,651), 0:19:53 elapsed, 0:04:57 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps  ppl  token_acc  tpb   tps\n",
            "           0 .006958  1971   623 3.792 4524 .1766    .1226 2.674 222.3 70.24 14.5      .4298 2194 693.2\n",
            "03:47:40 | 80.7% complete (4,560 / 5,651), 0:20:03 elapsed, 0:04:48 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006946  1969 621.9  3.79 4560 .1768    .1225 2.675 222.4 70.24 14.52      .4298 2191 692.1\n",
            "03:47:53 | 81.5% complete (4,608 / 5,651), 0:20:15 elapsed, 0:04:35 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "           0 .006874  1969 621.7  3.79 4608 .1768    .1165 2.677 222.3 70.22 14.54      .4295 2191  692\n",
            "03:48:05 | 82.4% complete (4,656 / 5,651), 0:20:27 elapsed, 0:04:22 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006803  1968 622.1 3.793 4656 .1769    .1048 2.676 222.3 70.26 14.53      .4297 2190 692.3\n",
            "03:48:18 | 83.2% complete (4,704 / 5,651), 0:20:40 elapsed, 0:04:10 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006806  1969 622.3 3.792 4704 .1766    .1230 2.677 222.1 70.19 14.54      .4294 2191 692.5\n",
            "03:48:30 | 84.1% complete (4,752 / 5,651), 0:20:52 elapsed, 0:03:57 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006737  1969 622.5 3.794 4752 .1763    .1211 2.678   222 70.18 14.55      .4292 2191 692.7\n",
            "03:48:42 | 84.9% complete (4,800 / 5,651), 0:21:04 elapsed, 0:03:44 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006762  1969 622.7 3.795 4800 .1765    .1148 2.679 221.8 70.15 14.57      .4290 2191 692.9\n",
            "03:48:54 | 85.8% complete (4,848 / 5,651), 0:21:16 elapsed, 0:03:32 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006695  1968 622.6 3.797 4848 .1764    .1085  2.68 221.9 70.21 14.59      .4287 2190 692.8\n",
            "03:49:08 | 86.6% complete (4,896 / 5,651), 0:21:30 elapsed, 0:03:19 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006774  1969 622.6 3.794 4896 .1763    .1227 2.681 221.8 70.13 14.59      .4285 2191 692.7\n",
            "03:49:20 | 87.5% complete (4,944 / 5,651), 0:21:43 elapsed, 0:03:06 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006709  1969 622.4 3.794 4944 .1761    .1279 2.684 221.5 70.02 14.64      .4282 2190 692.4\n",
            "03:49:32 | 88.3% complete (4,992 / 5,651), 0:21:55 elapsed, 0:02:54 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006695  1969 622.7 3.796 4992 .1760    .1067 2.685 221.3    70 14.65      .4279 2190 692.7\n",
            "03:49:45 | 89.2% complete (5,040 / 5,651), 0:22:07 elapsed, 0:02:41 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006726  1968 622.4 3.796 5040 .1758    .1323 2.684 221.2 69.96 14.65      .4279 2189 692.4\n",
            "03:49:57 | 90.0% complete (5,088 / 5,651), 0:22:19 elapsed, 0:02:28 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006722  1967 622.5 3.798 5088 .1758    .1133 2.683 220.9 69.91 14.62      .4283 2188 692.4\n",
            "03:50:10 | 90.9% complete (5,136 / 5,651), 0:22:32 elapsed, 0:02:16 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006733  1965 621.9 3.798 5136 .1757    .1251 2.682 220.5  69.8 14.61      .4285 2185 691.7\n",
            "03:50:22 | 91.7% complete (5,184 / 5,651), 0:22:45 elapsed, 0:02:03 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0  .00682  1963 621.2 3.798 5184 .1758    .1099  2.68 220.1 69.67 14.59      .4288 2183 690.9\n",
            "03:50:34 | 92.6% complete (5,232 / 5,651), 0:22:57 elapsed, 0:01:50 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "           0 .006901  1963 621.3 3.799 5232 .1762    .1130 2.678 219.9 69.62 14.56      .4290 2183  691\n",
            "03:50:46 | 93.4% complete (5,280 / 5,651), 0:23:08 elapsed, 0:01:38 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006872  1961 621.2 3.801 5280 .1760    .1116 2.678 219.7 69.61 14.56      .4292 2181 690.8\n",
            "03:50:58 | 94.3% complete (5,328 / 5,651), 0:23:20 elapsed, 0:01:25 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006897  1958 620.9 3.805 5328 .1761    .1047 2.677 219.3 69.55 14.54      .4293 2178 690.5\n",
            "03:51:08 | 94.9% complete (5,364 / 5,651), 0:23:30 elapsed, 0:01:15 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "           0 .007104  1958 620.5 3.803 5364 .1763    .1220 2.677 219.4 69.51 14.54      .4294 2177  690\n",
            "03:51:20 | 95.8% complete (5,412 / 5,651), 0:23:42 elapsed, 0:01:03 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007119  1956 620.1 3.803 5412 .1763    .1250 2.677 219.1 69.44 14.55      .4295 2176 689.5\n",
            "03:51:32 | 96.6% complete (5,460 / 5,651), 0:23:54 elapsed, 0:00:50 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007089  1955 620.1 3.805 5460 .1762    .1236 2.678 218.8 69.38 14.55      .4295 2174 689.4\n",
            "03:51:44 | 97.5% complete (5,508 / 5,651), 0:24:06 elapsed, 0:00:38 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007055  1954   620 3.808 5508 .1762    .1161 2.678 218.5 69.34 14.55      .4296 2173 689.4\n",
            "03:51:55 | 98.3% complete (5,556 / 5,651), 0:24:17 elapsed, 0:00:25 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0  .00711  1952 619.8 3.811 5556 .1762    .1085 2.678 218.2 69.28 14.55      .4297 2170 689.1\n",
            "03:52:07 | 99.2% complete (5,604 / 5,651), 0:24:29 elapsed, 0:00:12 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007049  1951 620.2 3.814 5604 .1758    .1010 2.678   218 69.28 14.56      .4296 2169 689.5\n",
            "03:52:17 | 99.9% complete (5,648 / 5,651), 0:24:40 elapsed, 0:00:01 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006994  1946 620.6 3.816 5648 .1756   .09593 2.677 217.2 69.25 14.54      .4296 2163 689.8\n",
            "03:52:18 | Finished evaluating tasks ['blended_skill_talk'] using datatype valid\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "           0 .006991  1943 620.7 3.816 5651 .1756   .04216 2.677 216.8 69.24 14.54      .4296 2160  690\n",
            "03:52:18 | Saving model report to /content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/evaluations/baseline_blended_skill_valid.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.0,\n",
              " 'bleu-4': 0.0069907070350363355,\n",
              " 'ctpb': 1943.4841437632135,\n",
              " 'ctps': 620.7142234700699,\n",
              " 'exps': 3.815704809284349,\n",
              " 'exs': 5651,\n",
              " 'f1': 0.1756352344317606,\n",
              " 'gpu_mem': 0.04216118214232532,\n",
              " 'loss': 2.676690221039761,\n",
              " 'ltpb': 216.7864693446089,\n",
              " 'ltps': 69.23773390921347,\n",
              " 'ppl': 14.53689966009314,\n",
              " 'token_acc': 0.4296274624536766,\n",
              " 'tpb': 2160.2706131078226,\n",
              " 'tps': 689.9519634120127}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "am4ch594EIPr"
      },
      "source": [
        "Evaluate transfer learning model on blended_skill_talk testing dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_ixZE4M1cwc",
        "outputId": "5ea0704c-75f5-4c09-9909-37b818423cf8"
      },
      "source": [
        "EvalModel.main(\n",
        "    task='blended_skill_talk',\n",
        "    mf=\"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/from_pretrained/model\",\n",
        "    rf=\"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/evaluations/transfer_learning_blended_skill_test.json\",\n",
        "    dt='test',\n",
        "    metrics=['ppl', 'bleu-4'],\n",
        "    skip_generation=False,\n",
        "    batchsize=12,\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "03:52:24 | \u001b[33mOverriding opt[\"datatype\"] to test (previously: train)\u001b[0m\n",
            "03:52:24 | \u001b[33mOverriding opt[\"task\"] to blended_skill_talk (previously: custom_train)\u001b[0m\n",
            "03:52:24 | \u001b[33mOverriding opt[\"model_file\"] to /content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/from_pretrained/model (previously: from_pretrained/model)\u001b[0m\n",
            "03:52:24 | \u001b[33mOverriding opt[\"metrics\"] to ppl,bleu-4 (previously: default)\u001b[0m\n",
            "03:52:24 | \u001b[33mOverriding opt[\"skip_generation\"] to False (previously: True)\u001b[0m\n",
            "03:52:24 | Using CUDA\n",
            "03:52:24 | loading dictionary from /content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/from_pretrained/model.dict\n",
            "03:52:24 | num words = 54944\n",
            "03:52:25 | Total parameters: 87,508,992 (87,508,992 trainable)\n",
            "03:52:25 | Loading existing model params from /content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/from_pretrained/model\n",
            "03:52:28 | Opt:\n",
            "03:52:28 |     activation: gelu\n",
            "03:52:28 |     adafactor_eps: '[1e-30, 0.001]'\n",
            "03:52:28 |     adam_eps: 1e-08\n",
            "03:52:28 |     add_p1_after_newln: False\n",
            "03:52:28 |     aggregate_micro: False\n",
            "03:52:28 |     allow_missing_init_opts: False\n",
            "03:52:28 |     attention_dropout: 0.0\n",
            "03:52:28 |     batchsize: 12\n",
            "03:52:28 |     beam_block_full_context: True\n",
            "03:52:28 |     beam_block_list_filename: None\n",
            "03:52:28 |     beam_block_ngram: -1\n",
            "03:52:28 |     beam_context_block_ngram: -1\n",
            "03:52:28 |     beam_delay: 30\n",
            "03:52:28 |     beam_length_penalty: 0.65\n",
            "03:52:28 |     beam_min_length: 1\n",
            "03:52:28 |     beam_size: 1\n",
            "03:52:28 |     betas: '[0.9, 0.999]'\n",
            "03:52:28 |     bpe_add_prefix_space: None\n",
            "03:52:28 |     bpe_debug: False\n",
            "03:52:28 |     bpe_dropout: None\n",
            "03:52:28 |     bpe_merge: None\n",
            "03:52:28 |     bpe_vocab: None\n",
            "03:52:28 |     compute_tokenized_bleu: False\n",
            "03:52:28 |     datapath: \"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning\"\n",
            "03:52:28 |     datatype: test\n",
            "03:52:28 |     delimiter: '\\n'\n",
            "03:52:28 |     dict_class: parlai.core.dict:DictionaryAgent\n",
            "03:52:28 |     dict_endtoken: __end__\n",
            "03:52:28 |     dict_file: \"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/from_pretrained/model.dict\"\n",
            "03:52:28 |     dict_include_test: False\n",
            "03:52:28 |     dict_include_valid: False\n",
            "03:52:28 |     dict_initpath: None\n",
            "03:52:28 |     dict_language: english\n",
            "03:52:28 |     dict_loaded: True\n",
            "03:52:28 |     dict_lower: True\n",
            "03:52:28 |     dict_max_ngram_size: -1\n",
            "03:52:28 |     dict_maxexs: -1\n",
            "03:52:28 |     dict_maxtokens: -1\n",
            "03:52:28 |     dict_minfreq: 0\n",
            "03:52:28 |     dict_nulltoken: __null__\n",
            "03:52:28 |     dict_starttoken: __start__\n",
            "03:52:28 |     dict_textfields: text,labels\n",
            "03:52:28 |     dict_tokenizer: bpe\n",
            "03:52:28 |     dict_unktoken: __unk__\n",
            "03:52:28 |     display_examples: False\n",
            "03:52:28 |     download_path: None\n",
            "03:52:28 |     dropout: 0.0\n",
            "03:52:28 |     dynamic_batching: full\n",
            "03:52:28 |     embedding_projection: random\n",
            "03:52:28 |     embedding_size: 512\n",
            "03:52:28 |     embedding_type: random\n",
            "03:52:28 |     embeddings_scale: True\n",
            "03:52:28 |     eval_batchsize: None\n",
            "03:52:28 |     eval_dynamic_batching: None\n",
            "03:52:28 |     evaltask: None\n",
            "03:52:28 |     ffn_size: 2048\n",
            "03:52:28 |     force_fp16_tokens: True\n",
            "03:52:28 |     fp16: True\n",
            "03:52:28 |     fp16_impl: mem_efficient\n",
            "03:52:28 |     gpu: -1\n",
            "03:52:28 |     gradient_clip: 0.1\n",
            "03:52:28 |     hide_labels: False\n",
            "03:52:28 |     history_add_global_end_token: None\n",
            "03:52:28 |     history_reversed: False\n",
            "03:52:28 |     history_size: -1\n",
            "03:52:28 |     image_cropsize: 224\n",
            "03:52:28 |     image_mode: raw\n",
            "03:52:28 |     image_size: 256\n",
            "03:52:28 |     inference: greedy\n",
            "03:52:28 |     init_model: \"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/models/blender/blender_90M/model\"\n",
            "03:52:28 |     init_opt: None\n",
            "03:52:28 |     interactive_mode: False\n",
            "03:52:28 |     invsqrt_lr_decay_gamma: -1\n",
            "03:52:28 |     label_truncate: 128\n",
            "03:52:28 |     learn_positional_embeddings: True\n",
            "03:52:28 |     learningrate: 1e-05\n",
            "03:52:28 |     log_every_n_secs: 10\n",
            "03:52:28 |     log_keep_fields: all\n",
            "03:52:28 |     loglevel: info\n",
            "03:52:28 |     lr_scheduler: reduceonplateau\n",
            "03:52:28 |     lr_scheduler_decay: 0.5\n",
            "03:52:28 |     lr_scheduler_patience: 3\n",
            "03:52:28 |     max_lr_steps: -1\n",
            "03:52:28 |     max_train_time: 1200.0\n",
            "03:52:28 |     metrics: ppl,bleu-4\n",
            "03:52:28 |     model: transformer/generator\n",
            "03:52:28 |     model_file: \"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/from_pretrained/model\"\n",
            "03:52:28 |     model_parallel: False\n",
            "03:52:28 |     momentum: 0\n",
            "03:52:28 |     multitask_weights: [1]\n",
            "03:52:28 |     mutators: None\n",
            "03:52:28 |     n_decoder_layers: -1\n",
            "03:52:28 |     n_encoder_layers: -1\n",
            "03:52:28 |     n_heads: 16\n",
            "03:52:28 |     n_layers: 8\n",
            "03:52:28 |     n_positions: 512\n",
            "03:52:28 |     n_segments: 0\n",
            "03:52:28 |     nesterov: True\n",
            "03:52:28 |     no_cuda: False\n",
            "03:52:28 |     num_epochs: -1\n",
            "03:52:28 |     num_examples: -1\n",
            "03:52:28 |     nus: [0.7]\n",
            "03:52:28 |     optimizer: mem_eff_adam\n",
            "03:52:28 |     output_scaling: 1.0\n",
            "03:52:28 |     override: '{\\'datatype\\': \\'test\\', \\'task\\': \\'blended_skill_talk\\', \\'model_file\\': \"/content/drive/My Drive/Master\\'s Thesis/Blenderbot Transfer Learning/from_pretrained/model\", \\'report_filename\\': \"/content/drive/My Drive/Master\\'s Thesis/Blenderbot Transfer Learning/evaluations/transfer_learning_blended_skill_test.json\", \\'metrics\\': \\'ppl,bleu-4\\', \\'skip_generation\\': False, \\'batchsize\\': 12}'\n",
            "03:52:28 |     parlai_home: /usr/local/lib/python3.7/dist-packages\n",
            "03:52:28 |     person_tokens: False\n",
            "03:52:28 |     rank_candidates: False\n",
            "03:52:28 |     relu_dropout: 0.0\n",
            "03:52:28 |     report_filename: \"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/evaluations/transfer_learning_blended_skill_test.json\"\n",
            "03:52:28 |     save_after_valid: False\n",
            "03:52:28 |     save_every_n_secs: -1\n",
            "03:52:28 |     save_format: conversations\n",
            "03:52:28 |     share_word_embeddings: True\n",
            "03:52:28 |     short_final_eval: False\n",
            "03:52:28 |     skip_generation: False\n",
            "03:52:28 |     special_tok_lst: None\n",
            "03:52:28 |     split_lines: False\n",
            "03:52:28 |     starttime: Apr17_02-44\n",
            "03:52:28 |     task: blended_skill_talk\n",
            "03:52:28 |     temperature: 1.0\n",
            "03:52:28 |     tensorboard_log: False\n",
            "03:52:28 |     tensorboard_logdir: None\n",
            "03:52:28 |     text_truncate: 512\n",
            "03:52:28 |     topk: 10\n",
            "03:52:28 |     topp: 0.9\n",
            "03:52:28 |     truncate: -1\n",
            "03:52:28 |     update_freq: 1\n",
            "03:52:28 |     use_reply: label\n",
            "03:52:28 |     validation_cutoff: 1.0\n",
            "03:52:28 |     validation_every_n_epochs: 0.25\n",
            "03:52:28 |     validation_every_n_secs: -1\n",
            "03:52:28 |     validation_max_exs: -1\n",
            "03:52:28 |     validation_metric: ppl\n",
            "03:52:28 |     validation_metric_mode: None\n",
            "03:52:28 |     validation_patience: 10\n",
            "03:52:28 |     validation_share_agent: False\n",
            "03:52:28 |     variant: xlm\n",
            "03:52:28 |     verbose: False\n",
            "03:52:28 |     wandb_log: False\n",
            "03:52:28 |     wandb_name: None\n",
            "03:52:28 |     wandb_project: None\n",
            "03:52:28 |     warmup_rate: 0.0001\n",
            "03:52:28 |     warmup_updates: 100\n",
            "03:52:28 |     weight_decay: None\n",
            "03:52:28 |     world_logs: \n",
            "03:52:28 | Evaluating task blended_skill_talk using datatype test.\n",
            "03:52:28 | creating task(s): blended_skill_talk\n",
            "03:52:28 | Loading ParlAI text data: /content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/blended_skill_talk/test.txt\n",
            "03:52:41 | 4.8% complete (264 / 5,482), 0:00:10 elapsed, 0:03:25 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "           0 .003782  1854  3935 25.47  264 .1627   .03917 2.593 215.1 456.6 13.37      .4397 2069 4391\n",
            "03:52:51 | 9.6% complete (528 / 5,482), 0:00:20 elapsed, 0:03:16 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "           0 .004503  1923  4062 25.35  528 .1725   .04428 2.641   219 462.7 14.02      .4380 2142 4525\n",
            "03:53:01 | 14.7% complete (804 / 5,482), 0:00:30 elapsed, 0:03:00 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "           0 .004128  1918  4166 26.06  804 .1727   .03849  2.62 217.1 471.5 13.74      .4377 2136 4638\n",
            "03:53:12 | 19.3% complete (1,056 / 5,482), 0:00:41 elapsed, 0:02:53 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "           0 .004122  1952  4174 25.67 1056 .1731   .04942 2.643 222.9 476.8 14.05      .4349 2175 4651\n",
            "03:53:22 | 23.4% complete (1,284 / 5,482), 0:00:51 elapsed, 0:02:48 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "    .0007788 .004793  1996  4155 24.98 1284 .1766   .04161 2.646   231 480.8 14.09      .4349 2227 4635\n",
            "03:53:32 | 27.8% complete (1,524 / 5,482), 0:01:01 elapsed, 0:02:40 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "     .001312 .005105  1996  4105 24.68 1524 .1780   .04635 2.643 232.6 478.2 14.06      .4348 2229 4583\n",
            "03:53:42 | 32.0% complete (1,752 / 5,482), 0:01:11 elapsed, 0:02:33 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps  ppl  token_acc  tpb  tps\n",
            "     .001142 .005235  2009  4086  24.4 1752 .1753   .04035 2.674 235.1 478.1 14.5      .4318 2244 4564\n",
            "03:53:53 | 37.2% complete (2,040 / 5,482), 0:01:22 elapsed, 0:02:18 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "    .0009804 .005787  2003  4150 24.86 2040 .1724   .04227 2.701 232.2 481.1 14.89      .4296 2235 4631\n",
            "03:54:03 | 42.2% complete (2,316 / 5,482), 0:01:32 elapsed, 0:02:06 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "    .0008636 .005977  2004  4194 25.11 2316 .1732   .04099 2.702 231.1 483.6 14.91      .4307 2235 4678\n",
            "03:54:13 | 47.3% complete (2,592 / 5,482), 0:01:42 elapsed, 0:01:54 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "    .0007716   .0057  2004  4224 25.29 2592 .1737   .03917 2.704 229.5 483.7 14.94      .4307 2234 4707\n",
            "03:54:23 | 52.1% complete (2,856 / 5,482), 0:01:52 elapsed, 0:01:44 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps  ppl  token_acc  tpb  tps\n",
            "    .0007003 .005534  2001  4226 25.35 2856 .1730   .04425 2.701 230.1   486 14.9      .4301 2231 4712\n",
            "03:54:34 | 57.1% complete (3,132 / 5,482), 0:02:03 elapsed, 0:01:32 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "    .0006386 .005991  1994  4228 25.45 3132 .1738   .05031 2.699 228.9 485.4 14.86      .4294 2223 4713\n",
            "03:54:44 | 62.2% complete (3,408 / 5,482), 0:02:13 elapsed, 0:01:21 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "    .0005869 .005926  1988  4232 25.54 3408 .1719   .04293 2.698 227.5 484.3 14.86      .4297 2216 4717\n",
            "03:54:54 | 66.8% complete (3,660 / 5,482), 0:02:23 elapsed, 0:01:12 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "    .0005464 .005753  1997  4235 25.45 3660 .1703   .04102 2.709 228.2 483.8 15.01      .4291 2225 4719\n",
            "03:55:05 | 72.0% complete (3,948 / 5,482), 0:02:34 elapsed, 0:01:00 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "    .0007599 .005913  1986  4240 25.62 3948 .1699   .03911 2.703 226.3 483.2 14.93      .4293 2212 4723\n",
            "03:55:15 | 77.3% complete (4,236 / 5,482), 0:02:44 elapsed, 0:00:48 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "    .0007082 .005792  1985  4259 25.75 4236 .1702   .03978 2.695 226.2 485.4 14.81      .4307 2211 4745\n",
            "03:55:25 | 82.1% complete (4,500 / 5,482), 0:02:54 elapsed, 0:00:38 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "    .0006667 .005689  1981  4255 25.78 4500 .1702   .04499 2.689 225.6 484.7 14.72      .4315 2206 4740\n",
            "03:55:35 | 86.9% complete (4,764 / 5,482), 0:03:04 elapsed, 0:00:28 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "    .0008396 .005912  1981  4254 25.77 4764 .1702    .0423 2.685   226 485.2 14.65      .4324 2207 4739\n",
            "03:55:46 | 91.7% complete (5,028 / 5,482), 0:03:15 elapsed, 0:00:18 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "    .0007955 .005977  1982  4256 25.77 5028 .1708   .04104 2.677 226.4 486.1 14.54      .4337 2208 4742\n",
            "03:55:56 | 97.0% complete (5,316 / 5,482), 0:03:25 elapsed, 0:00:06 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "    .0009406 .006375  1978  4266 25.89 5316 .1715    .0404 2.676 226.5 488.6 14.53      .4340 2204 4755\n",
            "03:56:04 | Finished evaluating tasks ['blended_skill_talk'] using datatype test\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "    .0009121 .006367  1966  4235 25.67 5482 .1721   .03646 2.675   225 484.7 14.51      .4343 2191 4720\n",
            "03:56:04 | Saving model report to /content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/evaluations/transfer_learning_blended_skill_test.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.0009120758847136082,\n",
              " 'bleu-4': 0.006367056258040418,\n",
              " 'ctpb': 1966.1304347826087,\n",
              " 'ctps': 4235.314546728674,\n",
              " 'exps': 25.671661528197657,\n",
              " 'exs': 5482,\n",
              " 'f1': 0.1720665707279386,\n",
              " 'gpu_mem': 0.0364619634569566,\n",
              " 'loss': 2.6750425752623777,\n",
              " 'ltpb': 225.0086956521739,\n",
              " 'ltps': 484.69942009638197,\n",
              " 'ppl': 14.512967719846165,\n",
              " 'token_acc': 0.43431171742154895,\n",
              " 'tpb': 2191.1391304347826,\n",
              " 'tps': 4720.0142193027095}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSDYON2jEOTJ"
      },
      "source": [
        "Evaluate baseline model on blended_skill_talk testing dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faa6maFOEQsT",
        "outputId": "088cf641-12a3-4f3c-e4f1-4e52edccc21f"
      },
      "source": [
        "EvalModel.main(\n",
        "    task='blended_skill_talk',\n",
        "    mf=\"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/models/blender/blender_90M/model\",\n",
        "    rf=\"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/evaluations/baseline_blended_skill_test.json\",\n",
        "    dt='test',\n",
        "    metrics=['ppl', 'bleu-4'],\n",
        "    skip_generation=False,\n",
        "    batchsize=12,\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "04:31:07 | \u001b[33mOverriding opt[\"datatype\"] to test (previously: train)\u001b[0m\n",
            "04:31:07 | \u001b[33mOverriding opt[\"task\"] to blended_skill_talk (previously: internal:blended_skill_talk,wizard_of_wikipedia,convai2,empathetic_dialogues)\u001b[0m\n",
            "04:31:07 | \u001b[33mOverriding opt[\"model_file\"] to /content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/models/blender/blender_90M/model (previously: /checkpoint/edinan/20200210/baseline_BST_retnref/lr=7.5e-06_attention-dropout=0.0_relu-dropout=0.0/model)\u001b[0m\n",
            "04:31:07 | \u001b[33mOverriding opt[\"metrics\"] to ppl,bleu-4 (previously: default)\u001b[0m\n",
            "04:31:07 | \u001b[33mOverriding opt[\"batchsize\"] to 12 (previously: 16)\u001b[0m\n",
            "04:31:07 | \u001b[33mLoading model with `--beam-block-full-context false`\u001b[0m\n",
            "04:31:07 | Using CUDA\n",
            "04:31:07 | loading dictionary from /content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/models/blender/blender_90M/model.dict\n",
            "04:31:08 | num words = 54944\n",
            "04:31:10 | Total parameters: 87,508,992 (87,508,992 trainable)\n",
            "04:31:10 | Loading existing model params from /content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/models/blender/blender_90M/model\n",
            "04:31:12 | Opt:\n",
            "04:31:12 |     activation: gelu\n",
            "04:31:12 |     adafactor_eps: '[1e-30, 0.001]'\n",
            "04:31:12 |     adam_eps: 1e-08\n",
            "04:31:12 |     add_p1_after_newln: False\n",
            "04:31:12 |     aggregate_micro: False\n",
            "04:31:12 |     allow_missing_init_opts: False\n",
            "04:31:12 |     attention_dropout: 0.0\n",
            "04:31:12 |     batchsize: 12\n",
            "04:31:12 |     beam_block_full_context: False\n",
            "04:31:12 |     beam_block_list_filename: None\n",
            "04:31:12 |     beam_block_ngram: 3\n",
            "04:31:12 |     beam_context_block_ngram: 3\n",
            "04:31:12 |     beam_delay: 30\n",
            "04:31:12 |     beam_length_penalty: 0.65\n",
            "04:31:12 |     beam_min_length: 20\n",
            "04:31:12 |     beam_size: 10\n",
            "04:31:12 |     betas: '[0.9, 0.999]'\n",
            "04:31:12 |     bpe_add_prefix_space: None\n",
            "04:31:12 |     bpe_debug: False\n",
            "04:31:12 |     bpe_dropout: None\n",
            "04:31:12 |     bpe_merge: None\n",
            "04:31:12 |     bpe_vocab: None\n",
            "04:31:12 |     compute_tokenized_bleu: False\n",
            "04:31:12 |     datapath: \"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning\"\n",
            "04:31:12 |     datatype: test\n",
            "04:31:12 |     delimiter: '\\n'\n",
            "04:31:12 |     dict_class: parlai.core.dict:DictionaryAgent\n",
            "04:31:12 |     dict_endtoken: __end__\n",
            "04:31:12 |     dict_file: \"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/models/blender/blender_90M/model.dict\"\n",
            "04:31:12 |     dict_include_test: False\n",
            "04:31:12 |     dict_include_valid: False\n",
            "04:31:12 |     dict_initpath: None\n",
            "04:31:12 |     dict_language: english\n",
            "04:31:12 |     dict_loaded: True\n",
            "04:31:12 |     dict_lower: True\n",
            "04:31:12 |     dict_max_ngram_size: -1\n",
            "04:31:12 |     dict_maxexs: -1\n",
            "04:31:12 |     dict_maxtokens: -1\n",
            "04:31:12 |     dict_minfreq: 0\n",
            "04:31:12 |     dict_nulltoken: __null__\n",
            "04:31:12 |     dict_starttoken: __start__\n",
            "04:31:12 |     dict_textfields: text,labels\n",
            "04:31:12 |     dict_tokenizer: bpe\n",
            "04:31:12 |     dict_unktoken: __unk__\n",
            "04:31:12 |     display_examples: False\n",
            "04:31:12 |     download_path: None\n",
            "04:31:12 |     dropout: 0.1\n",
            "04:31:12 |     dynamic_batching: None\n",
            "04:31:12 |     embedding_projection: random\n",
            "04:31:12 |     embedding_size: 512\n",
            "04:31:12 |     embedding_type: random\n",
            "04:31:12 |     embeddings_scale: True\n",
            "04:31:12 |     eval_batchsize: None\n",
            "04:31:12 |     evaltask: None\n",
            "04:31:12 |     ffn_size: 2048\n",
            "04:31:12 |     force_fp16_tokens: True\n",
            "04:31:12 |     fp16: True\n",
            "04:31:12 |     fp16_impl: safe\n",
            "04:31:12 |     gpu: -1\n",
            "04:31:12 |     gradient_clip: 0.1\n",
            "04:31:12 |     hide_labels: False\n",
            "04:31:12 |     history_add_global_end_token: None\n",
            "04:31:12 |     history_reversed: False\n",
            "04:31:12 |     history_size: -1\n",
            "04:31:12 |     image_cropsize: 224\n",
            "04:31:12 |     image_mode: raw\n",
            "04:31:12 |     image_size: 256\n",
            "04:31:12 |     include_checked_sentence: True\n",
            "04:31:12 |     include_knowledge: True\n",
            "04:31:12 |     include_knowledge_separator: False\n",
            "04:31:12 |     inference: beam\n",
            "04:31:12 |     init_model: /checkpoint/parlai/zoo/new_reddit/newreddit_trained20190909_usedfordodeca/model\n",
            "04:31:12 |     init_opt: None\n",
            "04:31:12 |     interactive_mode: False\n",
            "04:31:12 |     invsqrt_lr_decay_gamma: -1\n",
            "04:31:12 |     label_truncate: 128\n",
            "04:31:12 |     label_type: response\n",
            "04:31:12 |     learn_positional_embeddings: True\n",
            "04:31:12 |     learningrate: 7.5e-06\n",
            "04:31:12 |     log_every_n_secs: 2\n",
            "04:31:12 |     log_keep_fields: all\n",
            "04:31:12 |     loglevel: info\n",
            "04:31:12 |     lr_scheduler: reduceonplateau\n",
            "04:31:12 |     lr_scheduler_decay: 0.5\n",
            "04:31:12 |     lr_scheduler_patience: 3\n",
            "04:31:12 |     max_lr_steps: -1\n",
            "04:31:12 |     max_train_time: -1\n",
            "04:31:12 |     metrics: ppl,bleu-4\n",
            "04:31:12 |     model: transformer/generator\n",
            "04:31:12 |     model_file: \"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/models/blender/blender_90M/model\"\n",
            "04:31:12 |     model_parallel: False\n",
            "04:31:12 |     momentum: 0\n",
            "04:31:12 |     multitask_weights: '[1.0, 3.0, 3.0, 3.0]'\n",
            "04:31:12 |     mutators: None\n",
            "04:31:12 |     n_decoder_layers: -1\n",
            "04:31:12 |     n_encoder_layers: -1\n",
            "04:31:12 |     n_heads: 16\n",
            "04:31:12 |     n_layers: 8\n",
            "04:31:12 |     n_positions: 512\n",
            "04:31:12 |     n_segments: 0\n",
            "04:31:12 |     nesterov: True\n",
            "04:31:12 |     no_cuda: False\n",
            "04:31:12 |     num_epochs: -1\n",
            "04:31:12 |     num_examples: -1\n",
            "04:31:12 |     num_topics: 5\n",
            "04:31:12 |     numthreads: 1\n",
            "04:31:12 |     nus: [0.7]\n",
            "04:31:12 |     optimizer: adamax\n",
            "04:31:12 |     output_scaling: 1.0\n",
            "04:31:12 |     override: '{\\'datatype\\': \\'test\\', \\'task\\': \\'blended_skill_talk\\', \\'model_file\\': \"/content/drive/My Drive/Master\\'s Thesis/Blenderbot Transfer Learning/models/blender/blender_90M/model\", \\'report_filename\\': \"/content/drive/My Drive/Master\\'s Thesis/Blenderbot Transfer Learning/evaluations/baseline_blended_skill_test.json\", \\'metrics\\': \\'ppl,bleu-4\\', \\'skip_generation\\': False, \\'batchsize\\': 12}'\n",
            "04:31:12 |     parlai_home: /private/home/edinan/ParlAI\n",
            "04:31:12 |     person_tokens: False\n",
            "04:31:12 |     rank_candidates: False\n",
            "04:31:12 |     relu_dropout: 0.0\n",
            "04:31:12 |     report_filename: \"/content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/evaluations/baseline_blended_skill_test.json\"\n",
            "04:31:12 |     save_after_valid: True\n",
            "04:31:12 |     save_every_n_secs: 60.0\n",
            "04:31:12 |     save_format: conversations\n",
            "04:31:12 |     share_word_embeddings: True\n",
            "04:31:12 |     short_final_eval: False\n",
            "04:31:12 |     show_advanced_args: False\n",
            "04:31:12 |     skip_generation: False\n",
            "04:31:12 |     special_tok_lst: None\n",
            "04:31:12 |     split_lines: False\n",
            "04:31:12 |     starttime: Feb10_07-25\n",
            "04:31:12 |     task: blended_skill_talk\n",
            "04:31:12 |     temperature: 1.0\n",
            "04:31:12 |     tensorboard_log: False\n",
            "04:31:12 |     tensorboard_logdir: None\n",
            "04:31:12 |     text_truncate: 512\n",
            "04:31:12 |     topk: 10\n",
            "04:31:12 |     topp: 0.9\n",
            "04:31:12 |     train_experiencer_only: False\n",
            "04:31:12 |     truncate: -1\n",
            "04:31:12 |     update_freq: 1\n",
            "04:31:12 |     use_reply: label\n",
            "04:31:12 |     validation_cutoff: 1.0\n",
            "04:31:12 |     validation_every_n_epochs: 0.25\n",
            "04:31:12 |     validation_every_n_secs: -1\n",
            "04:31:12 |     validation_max_exs: 20000\n",
            "04:31:12 |     validation_metric: ppl\n",
            "04:31:12 |     validation_metric_mode: min\n",
            "04:31:12 |     validation_patience: 15\n",
            "04:31:12 |     validation_share_agent: False\n",
            "04:31:12 |     variant: xlm\n",
            "04:31:12 |     verbose: False\n",
            "04:31:12 |     warmup_rate: 0.0001\n",
            "04:31:12 |     warmup_updates: -1\n",
            "04:31:12 |     weight_decay: None\n",
            "04:31:12 |     world_logs: \n",
            "04:31:12 | Evaluating task blended_skill_talk using datatype test.\n",
            "04:31:12 | creating task(s): blended_skill_talk\n",
            "04:31:13 | Loading ParlAI text data: /content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/blended_skill_talk/test.txt\n",
            "04:31:24 | 0.9% complete (48 / 5,482), 0:00:10 elapsed, 0:19:10 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0  .01204  1502 593.3 4.738   48 .1817   .09122 2.663 234.5  92.6 14.34      .4328 1737 685.9\n",
            "04:31:36 | 1.8% complete (96 / 5,482), 0:00:21 elapsed, 0:20:34 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006021  1774 646.2 4.371   96 .1699    .1146 2.725 223.6 81.45 15.25      .4243 1998 727.6\n",
            "04:31:47 | 2.6% complete (144 / 5,482), 0:00:33 elapsed, 0:20:34 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0  .00548  1895 683.5 4.328  144 .1793   .09747 2.658 214.3 77.31 14.27      .4277 2109 760.8\n",
            "04:32:00 | 3.5% complete (192 / 5,482), 0:00:45 elapsed, 0:20:53 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006968  1825 642.5 4.225  192 .1856    .1069 2.571 208.9 73.53 13.08      .4384 2034 716.1\n",
            "04:32:12 | 4.4% complete (240 / 5,482), 0:00:57 elapsed, 0:21:01 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006167  1868 647.3 4.157  240 .1783    .1052 2.583 212.3 73.57 13.24      .4389 2081 720.9\n",
            "04:32:23 | 5.3% complete (288 / 5,482), 0:01:08 elapsed, 0:20:39 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .005712  1913 668.2 4.193  288 .1788   .09293 2.584 216.7  75.7 13.25      .4365 2129 743.9\n",
            "04:32:36 | 6.1% complete (336 / 5,482), 0:01:21 elapsed, 0:20:47 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .005905  1911 657.5 4.128  336 .1760    .1143 2.626 216.7 74.54 13.81      .4327 2128 732.1\n",
            "04:32:47 | 6.8% complete (372 / 5,482), 0:01:32 elapsed, 0:21:12 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .005949  1935 647.7 4.017  372 .1734    .1335 2.616 215.1 72.02 13.68      .4354 2150 719.7\n",
            "04:32:57 | 7.4% complete (408 / 5,482), 0:01:43 elapsed, 0:21:22 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .005986  1931 637.1 3.959  408 .1729    .1168 2.617   220 72.57 13.69      .4372 2151 709.6\n",
            "04:33:10 | 8.3% complete (456 / 5,482), 0:01:56 elapsed, 0:21:19 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007049  1944 636.6  3.93  456 .1735    .1200 2.619 219.9    72 13.72      .4401 2164 708.6\n",
            "04:33:22 | 9.2% complete (504 / 5,482), 0:02:08 elapsed, 0:21:05 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007035  1930 633.3 3.937  504 .1743    .1032 2.638   220 72.19 13.99      .4379 2150 705.5\n",
            "04:33:35 | 10.1% complete (552 / 5,482), 0:02:20 elapsed, 0:20:54 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007086  1919 628.9 3.933  552 .1729    .1045 2.633 217.6 71.31 13.92      .4372 2136 700.2\n",
            "04:33:46 | 10.9% complete (600 / 5,482), 0:02:32 elapsed, 0:20:39 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007617  1902 624.3  3.94  600 .1739    .1048 2.624 216.9 71.21 13.79      .4372 2118 695.5\n",
            "04:33:59 | 11.8% complete (648 / 5,482), 0:02:44 elapsed, 0:20:27 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007463  1893 621.6 3.941  648 .1736    .1040 2.626 214.8 70.54 13.81      .4366 2108 692.1\n",
            "04:34:11 | 12.7% complete (696 / 5,482), 0:02:56 elapsed, 0:20:14 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006949  1894 622.6 3.944  696 .1733    .1043 2.619 214.6 70.53 13.73      .4362 2109 693.1\n",
            "04:34:23 | 13.6% complete (744 / 5,482), 0:03:09 elapsed, 0:20:04 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0  .00669  1910 626.2 3.934  744 .1739    .1006 2.617 215.4 70.61 13.69      .4368 2125 696.8\n",
            "04:34:36 | 14.4% complete (792 / 5,482), 0:03:22 elapsed, 0:19:58 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006587  1912   624 3.915  792 .1747    .1099 2.615   217 70.81 13.66      .4373 2130 694.8\n",
            "04:34:49 | 15.3% complete (840 / 5,482), 0:03:35 elapsed, 0:19:50 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006436  1922 624.9 3.901  840 .1757    .1149  2.63 216.8 70.48 13.87      .4371 2139 695.3\n",
            "04:35:00 | 16.0% complete (876 / 5,482), 0:03:45 elapsed, 0:19:47 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006351  1929 623.9 3.882  876 .1758    .1027 2.637 217.6 70.41 13.97      .4356 2146 694.3\n",
            "04:35:10 | 16.6% complete (912 / 5,482), 0:03:56 elapsed, 0:19:44 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006472  1943 624.7 3.859  912 .1762    .1226 2.637 218.3  70.2 13.97      .4351 2161 694.9\n",
            "04:35:22 | 17.5% complete (960 / 5,482), 0:04:08 elapsed, 0:19:29 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007294  1941 625.8 3.869  960 .1778    .1016  2.63 219.2 70.69 13.87      .4370 2160 696.5\n",
            "04:35:32 | 18.2% complete (996 / 5,482), 0:04:18 elapsed, 0:19:23 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps  ppl  token_acc  tpb   tps\n",
            "           0 .007654  1943 624.5 3.857  996 .1790    .1081 2.639 220.9    71   14      .4354 2164 695.5\n",
            "04:35:43 | 18.8% complete (1,032 / 5,482), 0:04:29 elapsed, 0:19:21 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0  .00753  1953 623.8 3.832 1032 .1790    .1313 2.643 222.6 71.08 14.05      .4346 2176 694.9\n",
            "04:35:54 | 19.5% complete (1,068 / 5,482), 0:04:39 elapsed, 0:19:15 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007418  1948 620.2 3.821 1068 .1785    .1462 2.633 222.9 70.98 13.92      .4356 2171 691.2\n",
            "04:36:07 | 20.4% complete (1,116 / 5,482), 0:04:52 elapsed, 0:19:06 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007436  1957 621.5 3.811 1116 .1794    .1096 2.623 223.7 71.04 13.77      .4363 2181 692.6\n",
            "04:36:17 | 21.0% complete (1,152 / 5,482), 0:05:02 elapsed, 0:18:58 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007203  1964 622.4 3.804 1152 .1793    .1149 2.623 225.9 71.61 13.78      .4361 2190 694.1\n",
            "04:36:27 | 21.7% complete (1,188 / 5,482), 0:05:13 elapsed, 0:18:53 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007327  1978 624.9 3.792 1188 .1803    .1208 2.624 228.3 72.13 13.79      .4362 2206 697.1\n",
            "04:36:41 | 22.5% complete (1,236 / 5,482), 0:05:26 elapsed, 0:18:42 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007169  1989 627.1 3.784 1236 .1811    .1092 2.634 229.9 72.49 13.93      .4359 2219 699.6\n",
            "04:36:51 | 23.2% complete (1,272 / 5,482), 0:05:37 elapsed, 0:18:36 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0  .00724  1998 628.1 3.773 1272 .1807    .1243 2.638 230.5 72.47 13.99      .4351 2228 700.5\n",
            "04:37:04 | 24.1% complete (1,320 / 5,482), 0:05:50 elapsed, 0:18:24 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006977  1996 627.1 3.771 1320 .1814    .1087  2.64 230.4  72.4 14.01      .4354 2226 699.5\n",
            "04:37:16 | 25.0% complete (1,368 / 5,482), 0:06:02 elapsed, 0:18:10 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006866  1989 625.9 3.776 1368 .1821    .1064 2.641 231.5 72.85 14.03      .4356 2221 698.7\n",
            "04:37:30 | 25.8% complete (1,416 / 5,482), 0:06:16 elapsed, 0:18:00 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007223  2000 627.2 3.764 1416 .1825    .1253  2.64   233 73.08 14.01      .4357 2233 700.3\n",
            "04:37:41 | 26.5% complete (1,452 / 5,482), 0:06:26 elapsed, 0:17:53 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0   .0075  1996 624.8 3.755 1452 .1834    .1382 2.641 233.2 72.96 14.02      .4357 2230 697.7\n",
            "04:37:54 | 27.4% complete (1,500 / 5,482), 0:06:39 elapsed, 0:17:41 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007445  2000 625.8 3.755 1500 .1829    .1142 2.638 232.9 72.88 13.98      .4357 2233 698.7\n",
            "04:38:05 | 28.2% complete (1,548 / 5,482), 0:06:51 elapsed, 0:17:25 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007542  1992 625.1 3.765 1548 .1826   .09583 2.638 232.7 73.01 13.99      .4358 2225 698.1\n",
            "04:38:18 | 29.1% complete (1,596 / 5,482), 0:07:03 elapsed, 0:17:12 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0  .00741  1992   625 3.766 1596 .1816   .09986 2.641 232.3 72.91 14.03      .4353 2224 697.9\n",
            "04:38:28 | 29.8% complete (1,632 / 5,482), 0:07:13 elapsed, 0:17:04 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "           0  .00738  1997 625.9 3.761 1632 .1812    .1158 2.641   233 73.02 14.03      .4351 2230  699\n",
            "04:38:41 | 30.6% complete (1,680 / 5,482), 0:07:27 elapsed, 0:16:52 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007169  2001 626.4 3.756 1680 .1804    .1129 2.653 234.5  73.4 14.19      .4336 2236 699.8\n",
            "04:38:52 | 31.3% complete (1,716 / 5,482), 0:07:37 elapsed, 0:16:44 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007019  2007 627.1  3.75 1716 .1798    .1192 2.661 234.5  73.3 14.31      .4332 2241 700.4\n",
            "04:39:04 | 32.2% complete (1,764 / 5,482), 0:07:50 elapsed, 0:16:31 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006913  2012 629.1 3.753 1764 .1790    .1140 2.668 235.2 73.55 14.41      .4325 2247 702.7\n",
            "04:39:17 | 33.1% complete (1,812 / 5,482), 0:08:02 elapsed, 0:16:17 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps  ppl  token_acc  tpb   tps\n",
            "           0 .006897  2007 628.1 3.756 1812 .1792    .1253 2.674 234.8 73.49 14.5      .4319 2242 701.6\n",
            "04:39:30 | 33.9% complete (1,860 / 5,482), 0:08:15 elapsed, 0:16:05 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007027  2011 628.8 3.753 1860 .1786    .1191 2.676 233.7  73.1 14.53      .4320 2245 701.9\n",
            "04:39:42 | 34.8% complete (1,908 / 5,482), 0:08:27 elapsed, 0:15:52 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007149  2006   628 3.756 1908 .1782    .1038 2.685 233.6 73.13 14.65      .4316 2240 701.2\n",
            "04:39:54 | 35.7% complete (1,956 / 5,482), 0:08:40 elapsed, 0:15:38 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007171  2003 627.4  3.76 1956 .1777    .1156 2.689 232.9 72.96 14.71      .4306 2235 700.4\n",
            "04:40:07 | 36.6% complete (2,004 / 5,482), 0:08:52 elapsed, 0:15:25 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006999  2006 628.8 3.761 2004 .1766    .1021 2.694 231.8 72.65 14.79      .4299 2238 701.5\n",
            "04:40:19 | 37.4% complete (2,052 / 5,482), 0:09:05 elapsed, 0:15:11 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006835  2005 628.9 3.765 2052 .1768    .1103 2.696 232.4  72.9 14.82      .4299 2237 701.8\n",
            "04:40:29 | 38.1% complete (2,088 / 5,482), 0:09:15 elapsed, 0:15:02 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps  ppl  token_acc  tpb   tps\n",
            "           0 .006892  2006 628.8 3.762 2088 .1772    .1232 2.694 232.6 72.91 14.8      .4303 2238 701.7\n",
            "04:40:42 | 39.0% complete (2,136 / 5,482), 0:09:28 elapsed, 0:14:50 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006902  2010 629.6 3.759 2136 .1773    .1107 2.694 232.3 72.77 14.79      .4305 2242 702.4\n",
            "04:40:55 | 39.8% complete (2,184 / 5,482), 0:09:40 elapsed, 0:14:37 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps  ppl  token_acc  tpb   tps\n",
            "           0 .007134  2008 628.9 3.759 2184 .1781    .1144 2.694 232.4 72.81 14.8      .4308 2240 701.7\n",
            "04:41:07 | 40.7% complete (2,232 / 5,482), 0:09:52 elapsed, 0:14:23 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps  ppl  token_acc  tpb   tps\n",
            "           0  .00712  2008 629.9 3.765 2232 .1780    .1012 2.695 232.1 72.82 14.8      .4308 2240 702.7\n",
            "04:41:20 | 41.6% complete (2,280 / 5,482), 0:10:06 elapsed, 0:14:11 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007055  2012 630.8 3.762 2280 .1782    .1181 2.696 231.6  72.6 14.82      .4309 2244 703.4\n",
            "04:41:31 | 42.5% complete (2,328 / 5,482), 0:10:16 elapsed, 0:13:56 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007103  2003 629.9 3.774 2328 .1784    .1009 2.695 230.9 72.63 14.81      .4310 2234 702.6\n",
            "04:41:43 | 43.3% complete (2,376 / 5,482), 0:10:28 elapsed, 0:13:42 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0  .00696  2002 630.4 3.778 2376 .1792    .1050  2.69 230.4 72.53 14.74      .4320 2233 702.9\n",
            "04:41:55 | 44.2% complete (2,424 / 5,482), 0:10:41 elapsed, 0:13:29 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006946  2004 631.3 3.781 2424 .1790   .09981  2.69 230.2 72.52 14.73      .4323 2234 703.8\n",
            "04:42:08 | 45.1% complete (2,472 / 5,482), 0:10:53 elapsed, 0:13:16 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006886  1999 630.2 3.783 2472 .1790    .1093 2.691 229.5 72.34 14.75      .4322 2229 702.5\n",
            "04:42:21 | 46.0% complete (2,520 / 5,482), 0:11:06 elapsed, 0:13:03 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps  ppl  token_acc  tpb   tps\n",
            "           0  .00685  2001 630.7 3.782 2520 .1788    .1081 2.694 229.4 72.29 14.8      .4317 2231 702.9\n",
            "04:42:33 | 46.8% complete (2,568 / 5,482), 0:11:19 elapsed, 0:12:51 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "           0  .00705  2002 630.7 3.781 2568 .1791    .1055 2.696 229.4 72.28 14.81      .4315 2231  703\n",
            "04:42:44 | 47.5% complete (2,604 / 5,482), 0:11:29 elapsed, 0:12:42 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007023  2003 630.6 3.777 2604 .1788    .1168 2.698 229.4  72.2 14.85      .4312 2233 702.8\n",
            "04:42:57 | 48.4% complete (2,652 / 5,482), 0:11:42 elapsed, 0:12:30 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006937  2003 629.9 3.774 2652 .1786    .1078 2.702   230 72.34 14.91      .4303 2233 702.2\n",
            "04:43:10 | 49.3% complete (2,700 / 5,482), 0:11:56 elapsed, 0:12:18 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps  ppl  token_acc  tpb   tps\n",
            "           0 .006814  2003 629.4 3.771 2700 .1787    .1085 2.701 230.5 72.42 14.9      .4298 2234 701.8\n",
            "04:43:21 | 49.9% complete (2,736 / 5,482), 0:12:07 elapsed, 0:12:10 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006937  2005 628.8 3.763 2736 .1788    .1306 2.702 230.2 72.19 14.91      .4297 2236 700.9\n",
            "04:43:34 | 50.8% complete (2,784 / 5,482), 0:12:20 elapsed, 0:11:57 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006869  2002 627.6 3.761 2784 .1794    .1161 2.695 230.2 72.16 14.81      .4306 2233 699.8\n",
            "04:43:44 | 51.4% complete (2,820 / 5,482), 0:12:30 elapsed, 0:11:48 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006781  2002 627.2 3.759 2820 .1795    .1074 2.695 230.1 72.08 14.81      .4305 2232 699.3\n",
            "04:43:56 | 52.3% complete (2,868 / 5,482), 0:12:42 elapsed, 0:11:35 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006924  2003   628 3.762 2868 .1795    .1074 2.695 230.2 72.18 14.81      .4302 2233 700.2\n",
            "04:44:09 | 53.2% complete (2,916 / 5,482), 0:12:54 elapsed, 0:11:22 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007032  1999 627.1 3.764 2916 .1794    .1126 2.696 229.9 72.11 14.82      .4299 2229 699.2\n",
            "04:44:22 | 54.1% complete (2,964 / 5,482), 0:13:08 elapsed, 0:11:09 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007025  2000   627 3.761 2964 .1793    .1226 2.695 229.6 71.96 14.81      .4300 2230 698.9\n",
            "04:44:35 | 54.9% complete (3,012 / 5,482), 0:13:20 elapsed, 0:10:57 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006964  1999 626.6 3.761 3012 .1789    .1075 2.697 229.6 71.96 14.83      .4294 2229 698.6\n",
            "04:44:46 | 55.6% complete (3,048 / 5,482), 0:13:32 elapsed, 0:10:49 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .006932  1998 624.8 3.753 3048 .1787    .1350 2.695 229.2  71.7 14.81      .4294 2227 696.5\n",
            "04:45:00 | 56.5% complete (3,096 / 5,482), 0:13:45 elapsed, 0:10:36 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0  .00705  1996 623.9 3.751 3096 .1789    .1490 2.693 229.1  71.6 14.78      .4297 2225 695.5\n",
            "04:45:10 | 57.1% complete (3,132 / 5,482), 0:13:55 elapsed, 0:10:27 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0  .00715  1994 622.9 3.749 3132 .1796    .1168 2.692 228.9 71.52 14.77      .4297 2223 694.4\n",
            "04:45:24 | 58.0% complete (3,180 / 5,482), 0:14:09 elapsed, 0:10:15 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0  .00744  1995 622.4 3.743 3180 .1798    .1296 2.692 228.7 71.35 14.76      .4301 2224 693.8\n",
            "04:45:35 | 58.9% complete (3,228 / 5,482), 0:14:21 elapsed, 0:10:01 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007435  1992 622.1 3.748 3228 .1795   .09462 2.693 228.8 71.46 14.78      .4300 2220 693.6\n",
            "04:45:49 | 59.8% complete (3,276 / 5,482), 0:14:34 elapsed, 0:09:49 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007461  1990 621.4 3.746 3276 .1793    .1168 2.693 228.9 71.47 14.78      .4302 2219 692.8\n",
            "04:46:02 | 60.6% complete (3,324 / 5,482), 0:14:47 elapsed, 0:09:36 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007463  1992 621.6 3.745 3324 .1788    .1077 2.694 228.3 71.27 14.79      .4300 2220 692.9\n",
            "04:46:12 | 61.3% complete (3,360 / 5,482), 0:14:57 elapsed, 0:09:27 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007439  1989 620.5 3.743 3360 .1788    .1046 2.693   228 71.13 14.77      .4302 2217 691.6\n",
            "04:46:23 | 62.2% complete (3,408 / 5,482), 0:15:09 elapsed, 0:09:13 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007335  1988 621.1 3.748 3408 .1785    .1045 2.692 227.5 71.07 14.76      .4299 2216 692.1\n",
            "04:46:35 | 63.0% complete (3,456 / 5,482), 0:15:21 elapsed, 0:09:00 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007323  1988 621.6 3.752 3456 .1781   .09697 2.692 227.3 71.08 14.77      .4299 2215 692.7\n",
            "04:46:46 | 63.7% complete (3,492 / 5,482), 0:15:31 elapsed, 0:08:51 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0   .0073  1991 621.7 3.748 3492 .1778    .1203 2.694 227.4 71.02 14.79      .4299 2218 692.7\n",
            "04:46:57 | 64.4% complete (3,528 / 5,482), 0:15:42 elapsed, 0:08:42 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007225  1993 621.3 3.741 3528 .1775    .1226 2.701 227.6 70.98 14.89      .4295 2220 692.3\n",
            "04:47:08 | 65.0% complete (3,564 / 5,482), 0:15:53 elapsed, 0:08:33 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007198  1996 621.7 3.737 3564 .1776    .1234   2.7 227.6 70.89 14.88      .4296 2224 692.6\n",
            "04:47:21 | 65.9% complete (3,612 / 5,482), 0:16:07 elapsed, 0:08:21 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps  ppl  token_acc  tpb   tps\n",
            "           0 .007246  1997 621.6 3.735 3612 .1773    .1228 2.702 227.8 70.91 14.9      .4297 2225 692.5\n",
            "04:47:32 | 66.5% complete (3,648 / 5,482), 0:16:17 elapsed, 0:08:11 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007174  1997 621.2 3.733 3648 .1770    .1085 2.703   228 70.93 14.92      .4294 2225 692.1\n",
            "04:47:42 | 67.2% complete (3,684 / 5,482), 0:16:27 elapsed, 0:08:02 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007309  1998 621.2 3.731 3684 .1770    .1115 2.705 228.5 71.05 14.95      .4292 2227 692.3\n",
            "04:47:55 | 68.1% complete (3,732 / 5,482), 0:16:40 elapsed, 0:07:49 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps  ppl  token_acc  tpb   tps\n",
            "           0 .007269  2001 621.9  3.73 3732 .1767    .1112 2.708 228.5 71.03   15      .4286 2229 692.9\n",
            "04:48:07 | 69.0% complete (3,780 / 5,482), 0:16:52 elapsed, 0:07:36 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007337  2000   622 3.732 3780 .1771    .1162 2.707 228.4 71.03 14.98      .4286 2228 693.1\n",
            "04:48:19 | 69.8% complete (3,828 / 5,482), 0:17:05 elapsed, 0:07:23 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007329  1998 621.6 3.734 3828 .1769    .1075 2.705 227.9 70.92 14.96      .4286 2226 692.5\n",
            "04:48:30 | 70.7% complete (3,876 / 5,482), 0:17:15 elapsed, 0:07:09 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "           0 .007391  1992 621.2 3.741 3876 .1772   .08816 2.702 227.2 70.83 14.91      .4289 2220  692\n",
            "04:48:42 | 71.6% complete (3,924 / 5,482), 0:17:27 elapsed, 0:06:56 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "           0 .007503  1988 620.3 3.745 3924 .1769    .1067 2.699 226.5 70.69 14.87      .4293 2214  691\n",
            "04:48:54 | 72.5% complete (3,972 / 5,482), 0:17:40 elapsed, 0:06:43 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007588  1988 620.7 3.746 3972 .1775   .09758 2.697 226.2 70.61 14.83      .4297 2214 691.3\n",
            "04:49:07 | 73.3% complete (4,020 / 5,482), 0:17:52 elapsed, 0:06:30 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007667  1985 619.9 3.747 4020 .1776    .1164 2.693 226.2 70.63 14.77      .4303 2212 690.5\n",
            "04:49:20 | 74.2% complete (4,068 / 5,482), 0:18:05 elapsed, 0:06:17 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "           0 .007641  1987 620.4 3.746 4068 .1775    .1080 2.691 226.2  70.6 14.75      .4305 2214  691\n",
            "04:49:31 | 74.9% complete (4,104 / 5,482), 0:18:16 elapsed, 0:06:08 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007574  1987 619.5 3.742 4104 .1776    .1165 2.691 226.5 70.64 14.74      .4305 2213 690.2\n",
            "04:49:44 | 75.7% complete (4,152 / 5,482), 0:18:30 elapsed, 0:05:56 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0  .00767  1988 619.8 3.741 4152 .1777    .1120 2.692 226.5  70.6 14.76      .4303 2215 690.4\n",
            "04:49:57 | 76.6% complete (4,200 / 5,482), 0:18:42 elapsed, 0:05:43 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007619  1988 619.9 3.742 4200 .1777    .1132  2.69 226.4 70.59 14.74      .4307 2214 690.5\n",
            "04:50:09 | 77.5% complete (4,248 / 5,482), 0:18:54 elapsed, 0:05:30 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007533  1985 619.6 3.745 4248 .1775    .1006 2.689 226.1 70.57 14.72      .4309 2212 690.1\n",
            "04:50:21 | 78.4% complete (4,296 / 5,482), 0:19:06 elapsed, 0:05:17 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007485  1984 619.3 3.746 4296 .1775    .1200 2.687 225.9  70.5 14.68      .4314 2210 689.8\n",
            "04:50:34 | 79.2% complete (4,344 / 5,482), 0:19:19 elapsed, 0:05:04 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007458  1982 618.9 3.747 4344 .1777    .1036 2.687 225.9 70.51 14.69      .4314 2208 689.4\n",
            "04:50:46 | 80.1% complete (4,392 / 5,482), 0:19:31 elapsed, 0:04:51 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007469  1979 618.3 3.749 4392 .1777    .1105 2.687 225.8 70.56 14.69      .4314 2205 688.9\n",
            "04:50:58 | 81.0% complete (4,440 / 5,482), 0:19:44 elapsed, 0:04:38 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007455  1979 618.3 3.749 4440 .1778    .1116 2.685 225.6  70.5 14.65      .4318 2205 688.8\n",
            "04:51:09 | 81.6% complete (4,476 / 5,482), 0:19:55 elapsed, 0:04:29 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007395  1980   618 3.745 4476 .1777    .1203 2.685 225.4 70.35 14.66      .4317 2205 688.3\n",
            "04:51:20 | 82.3% complete (4,512 / 5,482), 0:20:05 elapsed, 0:04:19 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "           0 .007459  1981 617.7 3.742 4512 .1779    .1340 2.683 225.5 70.33 14.63      .4318 2206  688\n",
            "04:51:30 | 83.0% complete (4,548 / 5,482), 0:20:16 elapsed, 0:04:10 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "           0 .007519  1982 617.7  3.74 4548 .1778    .1168 2.682 225.7 70.33 14.61      .4321 2207  688\n",
            "04:51:42 | 83.8% complete (4,596 / 5,482), 0:20:27 elapsed, 0:03:57 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007588  1978 617.1 3.743 4596 .1781   .09815 2.679 225.7  70.4 14.57      .4323 2204 687.5\n",
            "04:51:52 | 84.5% complete (4,632 / 5,482), 0:20:38 elapsed, 0:03:47 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps  ppl  token_acc  tpb   tps\n",
            "           0  .00753  1980 617.3 3.742 4632 .1781    .1126 2.681 225.6 70.34 14.6      .4321 2205 687.6\n",
            "04:52:02 | 85.2% complete (4,668 / 5,482), 0:20:48 elapsed, 0:03:38 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007471  1980   617  3.74 4668 .1778    .1234 2.682 225.5 70.28 14.62      .4320 2205 687.3\n",
            "04:52:12 | 85.8% complete (4,704 / 5,482), 0:20:58 elapsed, 0:03:28 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0  .00745  1980 616.9 3.739 4704 .1780    .1076 2.682 225.6  70.3 14.62      .4320 2206 687.2\n",
            "04:52:24 | 86.5% complete (4,740 / 5,482), 0:21:09 elapsed, 0:03:19 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007545  1981 616.5 3.734 4740 .1782    .1277  2.68 225.9 70.29 14.58      .4324 2207 686.7\n",
            "04:52:34 | 87.1% complete (4,776 / 5,482), 0:21:20 elapsed, 0:03:09 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007595  1981 615.9 3.731 4776 .1784    .1116 2.678 225.9 70.25 14.56      .4328 2207 686.1\n",
            "04:52:47 | 88.0% complete (4,824 / 5,482), 0:21:32 elapsed, 0:02:56 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007639  1981 615.9 3.731 4824 .1785    .1077 2.677 226.1  70.3 14.54      .4330 2207 686.2\n",
            "04:52:58 | 88.7% complete (4,860 / 5,482), 0:21:43 elapsed, 0:02:47 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007582  1981 615.3 3.727 4860 .1786    .1173 2.676 226.3 70.29 14.53      .4331 2207 685.6\n",
            "04:53:09 | 89.3% complete (4,896 / 5,482), 0:21:54 elapsed, 0:02:37 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007641  1981 614.9 3.725 4896 .1785   .09957 2.676 226.2 70.21 14.53      .4330 2207 685.1\n",
            "04:53:19 | 90.0% complete (4,932 / 5,482), 0:22:05 elapsed, 0:02:28 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007615  1983 615.1 3.722 4932 .1785    .1240 2.677 226.1 70.14 14.55      .4330 2209 685.3\n",
            "04:53:32 | 90.8% complete (4,980 / 5,482), 0:22:17 elapsed, 0:02:15 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007542  1981 614.7 3.723 4980 .1783    .1091 2.676 226.3 70.22 14.53      .4332 2208 684.9\n",
            "04:53:45 | 91.7% complete (5,028 / 5,482), 0:22:30 elapsed, 0:02:02 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007532  1982 614.7 3.722 5028 .1785    .1161 2.671 226.4 70.22 14.46      .4338 2208 684.9\n",
            "04:53:58 | 92.6% complete (5,076 / 5,482), 0:22:43 elapsed, 0:01:49 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0  .00754  1980 614.3 3.723 5076 .1787    .1120  2.67 226.2 70.18 14.43      .4339 2207 684.5\n",
            "04:54:10 | 93.5% complete (5,124 / 5,482), 0:22:55 elapsed, 0:01:36 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007651  1979 614.3 3.724 5124 .1789    .1055 2.669 226.4 70.25 14.42      .4339 2206 684.5\n",
            "04:54:23 | 94.3% complete (5,172 / 5,482), 0:23:09 elapsed, 0:01:23 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007717  1979   614 3.724 5172 .1792    .1078 2.669 226.4 70.25 14.42      .4341 2205 684.3\n",
            "04:54:35 | 95.2% complete (5,220 / 5,482), 0:23:20 elapsed, 0:01:10 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0  .00767  1977   614 3.727 5220 .1791   .09515 2.669 226.3 70.29 14.43      .4341 2203 684.3\n",
            "04:54:47 | 96.1% complete (5,268 / 5,482), 0:23:33 elapsed, 0:00:57 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007642  1976 613.8 3.728 5268 .1791    .1154  2.67 226.4 70.32 14.44      .4339 2202 684.1\n",
            "04:54:57 | 96.8% complete (5,304 / 5,482), 0:23:43 elapsed, 0:00:48 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007638  1978 614.2 3.727 5304 .1791    .1108  2.67 226.5 70.34 14.44      .4340 2204 684.5\n",
            "04:55:10 | 97.6% complete (5,352 / 5,482), 0:23:56 elapsed, 0:00:35 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "           0 .007665  1976 613.6 3.727 5352 .1791    .1182  2.67 226.6 70.39 14.43      .4342 2202  684\n",
            "04:55:20 | 98.3% complete (5,388 / 5,482), 0:24:06 elapsed, 0:00:25 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007658  1976 613.6 3.726 5388 .1792    .1071 2.669 226.6 70.34 14.43      .4342 2203 683.9\n",
            "04:55:33 | 99.2% complete (5,436 / 5,482), 0:24:18 elapsed, 0:00:12 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007768  1976 613.6 3.727 5436 .1795   .09996 2.668 226.6 70.36 14.42      .4342 2202 683.9\n",
            "04:55:44 | 99.9% complete (5,475 / 5,482), 0:24:29 elapsed, 0:00:02 eta\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb   tps\n",
            "           0 .007766  1976 614.4 3.726 5475 .1796    .1012 2.669 226.3 70.37 14.43      .4342 2202 684.7\n",
            "04:55:46 | Finished evaluating tasks ['blended_skill_talk'] using datatype test\n",
            "    accuracy  bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  ltpb  ltps   ppl  token_acc  tpb  tps\n",
            "           0 .007784  1966 614.6 3.725 5482 .1796   .04807 2.669   225 70.34 14.43      .4342 2191  685\n",
            "04:55:46 | Saving model report to /content/drive/My Drive/Master's Thesis/Blenderbot Transfer Learning/evaluations/baseline_blended_skill_test.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.0,\n",
              " 'bleu-4': 0.007783785776317626,\n",
              " 'ctpb': 1966.1304347826087,\n",
              " 'ctps': 614.6325052921886,\n",
              " 'exps': 3.725497739696367,\n",
              " 'exs': 5482,\n",
              " 'f1': 0.17958965701886398,\n",
              " 'gpu_mem': 0.04807478278719039,\n",
              " 'loss': 2.669271978379346,\n",
              " 'ltpb': 225.0086956521739,\n",
              " 'ltps': 70.34001816678736,\n",
              " 'ppl': 14.429460408804076,\n",
              " 'token_acc': 0.4342344257226774,\n",
              " 'tpb': 2191.1391304347826,\n",
              " 'tps': 684.972529212242}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3YeZLjCE3iO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}